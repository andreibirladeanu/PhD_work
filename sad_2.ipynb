{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/andrei-macpro/.cache/torch/hub/pyannote_pyannote-audio_master\n"
     ]
    }
   ],
   "source": [
    "import pyannote.core\n",
    "from pydub import AudioSegment\n",
    "file = {'uri':'1043_meal', 'audio':'/Users/andrei-macpro/Documents/Data/Audio/sad_demonstration/speech.wav'}\n",
    "import torch\n",
    "# speech activity detection model trained on AMI training set\n",
    "sad = torch.hub.load('pyannote/pyannote-audio', 'sad_ami')\n",
    "# obtain raw SAD scores (as `pyannote.core.SlidingWindowFeature` instance)\n",
    "sad_scores = sad(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyannote.audio.utils.signal import Binarize\n",
    "binarize = Binarize(offset=0.52, onset=0.52, log_scale=True, \n",
    "                    min_duration_off=0.1, min_duration_on=0.1)\n",
    "\n",
    "# speech regions (as `pyannote.core.Timeline` instance)\n",
    "speech = binarize.apply(sad_scores, dimension=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps_speech=dict(speech)\n",
    "timestamps_silence = dict(speech.gaps())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_times_speech=[x*1000 for x in list(timestamps_speech.keys())]\n",
    "end_times_speech=[x*1000 for x in list(timestamps_speech.values())]\n",
    "start_times_silence=[x*1000 for x in list(timestamps_silence.keys())]\n",
    "end_times_silence=[x*1000 for x in list(timestamps_silence.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_segments=[file[start_time:end_time] for start_time,end_time in zip(start_times_speech, end_times_speech)]\n",
    "silence_segments=[file[start_time:end_time] for start_time,end_time in zip(start_times_silence, end_times_silence)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=AudioSegment.from_wav('/Users/andrei-macpro/Documents/Data/Audio/sad_demonstration/speech.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='/Users/andrei-macpro/Documents/Data/Audio/non-speech2.wav'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(speech_segments).export('/Users/andrei-macpro/Documents/Data/Audio/speech2.wav', format=\"wav\")\n",
    "sum(silence_segments).export('/Users/andrei-macpro/Documents/Data/Audio/non-speech2.wav', format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
