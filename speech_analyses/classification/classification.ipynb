{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from pipelinehelper import PipelineHelper\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/andrei-macpro/Documents/Data/classification/speech')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('classification.xlsx', engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('Proportion speech child', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[:,1:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,1:11].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = data['Subject_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([0 if x=='no_rad' else 1 for x in data.iloc[:,-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm, tree\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "best_estimators = []\n",
    "\n",
    "#accuracies = []\n",
    "\n",
    "\n",
    "results = []\n",
    "predictions = []\n",
    "#X,y, groups = shuffle(X,y,data.index ,random_state=42)\n",
    "X_shuffled, y_shuffled, groups_shuffled = shuffle(X,y,groups ,random_state=42)\n",
    "cv = GroupKFold(n_splits=5)\n",
    "pipe = Pipeline([\n",
    "    ('scaler',StandardScaler()), \n",
    "    ('classifier', PipelineHelper([\n",
    "        ('svm', SVC(class_weight='balanced')), \n",
    "        ('lr', LogisticRegression(class_weight='balanced')),\n",
    "        ('tree', tree.DecisionTreeClassifier(class_weight='balanced')),\n",
    "        ('forest', RandomForestClassifier(class_weight='balanced')),\n",
    "        ('linear', LinearDiscriminantAnalysis()),\n",
    "        ('qudratic', QuadraticDiscriminantAnalysis()),\n",
    "        ('naive', GaussianNB())\n",
    "    ])),\n",
    "    ])\n",
    "params = {\n",
    "    'classifier__selected_model':pipe.named_steps['classifier'].generate({\n",
    "          'svm__kernel': ['linear','rbf'],'svm__C':[0.001, 0.01, 0.1, 1, 10, 100], 'svm__gamma':[0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'lr__penalty':['l1','l2'], 'lr__solver':['liblinear'],\n",
    "                        'lr__C':np.logspace(-4,4,20)\n",
    "        \n",
    "    })\n",
    "}\n",
    "search = GridSearchCV(pipe, params, scoring = ['accuracy','balanced_accuracy','f1', 'precision','recall'],refit='balanced_accuracy', cv =cv, n_jobs=-1)\n",
    "\n",
    "search.fit(X_shuffled, y_shuffled, groups = groups_shuffled)\n",
    "print(search.best_score_)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grid_search = pd.DataFrame(search.cv_results_)\n",
    "df_grid_search = df_grid_search.set_index('params')[['rank_test_accuracy', 'mean_test_accuracy', 'mean_test_f1','mean_test_precision', 'mean_test_recall']]\n",
    "df_grid_search.sort_values(by = 'mean_test_accuracy', ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "X_shuffled, y_shuffled, groups_shuffled = shuffle(X,y,groups ,random_state=42)\n",
    "\n",
    "scoring = ['accuracy', 'recall','precision', 'f1']\n",
    "scaler = preprocessing.StandardScaler()\n",
    "clf = SVC(C= 100,gamma=0.001,kernel='linear', class_weight='balanced')\n",
    "pipe = Pipeline(steps=[(\"scaler\", scaler), (\"classifier\", clf)])\n",
    "cv = LeaveOneGroupOut()\n",
    "scores = cross_validate(pipe, X_shuffled, y_shuffled,groups=groups_shuffled, cv=cv, scoring=scoring, return_estimator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores['test_f1'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_importances = [x.named_steps['classifier'].coef_[0] for x in  scores['estimator']]\n",
    "np.mean(f_importances,axis=0)\n",
    "features = pd.Series(np.mean(f_importances, axis=0), index=data.iloc[:,1:11].columns)\n",
    "figure = features.abs().nlargest(13).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets do group k fold\n",
    "group_kfold = GroupKFold(n_splits=6)\n",
    "for train_index, test_index in group_kfold.split(X, y, groups):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    print(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores2 = cross_val_score(model, X, y, scoring='accuracy', cv=group_kfold, n_jobs=-1, groups=groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: %.3f (%.3f)' % (mean(scores2), std(scores2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "for train_index, test_index in group_kfold.split(X, y=y, groups=groups):\n",
    "    print(np.unique(y[test_index], return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=list()\n",
    "for train_index, test_index in group_kfold.split(X, y=y, groups=groups):\n",
    "    labels.append(y[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=list()\n",
    "for train_index, test_index in group_kfold.split(X, y=y, groups=groups):\n",
    "    model.fit(X[train_index], y[train_index])\n",
    "    temp_list = model.predict(X[test_index])\n",
    "    predictions.append(temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=0\n",
    "for x,y in zip(predictions,labels):\n",
    "    for prediction, label in zip(x,y):\n",
    "        if int(prediction)==int(label):\n",
    "            accuracy +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy/len(X)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positives=0\n",
    "false_positives=0\n",
    "false_negatives=0\n",
    "for x,y in zip(predictions,test_indexes):\n",
    "    for prediction, label in zip(x,y):\n",
    "        if int(prediction)==int(label)==1:\n",
    "            true_positives +=1\n",
    "            \n",
    "for x,y in zip(predictions,test_indexes):\n",
    "    for prediction, label in zip(x,y):\n",
    "        if int(prediction)==1 and int(label)==0:\n",
    "            false_positives +=1\n",
    "\n",
    "for x,y in zip(predictions,test_indexes):\n",
    "    for prediction, label in zip(x,y):\n",
    "        if int(prediction)==0 and int(label)==1:\n",
    "            false_negatives +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = true_positives/true_positives+false_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in group_kfold.split(X, y, groups):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try with a data pre-processing\n",
    "X = data.iloc[:,1:12].to_numpy()\n",
    "y = np.array([0 if x=='no_rad' else 1 for x in data.iloc[:,-1]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "print(scaler.fit(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scaler.mean_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaler.fit_transform(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X_shuffled, y_shuffled, groups_shuffled = shuffle(X, y, groups, random_state=0)\n",
    "group_k_fold = GroupKFold(n_splits=6)\n",
    "splits = group_k_fold.split(X_shuffled, y_shuffled, groups_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in splits:\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    print(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(kernel='linear')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([0 if x=='no_rad' else 1 for x in data.iloc[:,-1]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores2 = cross_val_score(model, X, y, scoring='accuracy', cv=group_k_fold, n_jobs=-1, groups=groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: %.3f (%.3f)' % (mean(scores2), std(scores2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in group_kfold.split(X_shuffled, y_shuffled, groups_shuffled):\n",
    "    print(np.unique(y_shuffled[test_index], return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=list()\n",
    "for train_index, test_index in group_kfold.split(X_shuffled, y=y_shuffled, groups=groups):\n",
    "    labels.append(y[test_index])\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=list()\n",
    "for train_index, test_index in group_kfold.split(X_shuffled, y=y_shuffled, groups=groups):\n",
    "    model.fit(X[train_index], y[train_index])\n",
    "    temp_list = model.predict(X[test_index])\n",
    "    predictions.append(temp_list)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=0\n",
    "for x,y in zip(predictions,labels):\n",
    "    for prediction, label in zip(x,y):\n",
    "        if int(prediction)==int(label):\n",
    "            accuracy +=1\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy/len(X)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_kfold = GroupKFold(n_splits=6)\n",
    "for train_index, test_index in group_kfold.split(X, y, groups):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    print(X_train, X_test, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
