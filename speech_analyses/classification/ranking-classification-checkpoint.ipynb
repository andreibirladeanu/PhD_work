{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/andreibirladeanu/Documents/Data/Classification/speech')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('classification.xlsx', engine='openpyxl')\n",
    "X = data.iloc[:,2:12].to_numpy()\n",
    "y = np.array([0 if x=='no_rad' else 1 for x in data.iloc[:,-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[:,2:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = np.array(data['Subject_ID'])\n",
    "#X_shuffled, y_shuffled, groups_shuffled = shuffle(X, y, groups, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate accuracy and coefficients \n",
    "accuracies_combined= []\n",
    "final_coef =[]\n",
    "recall_all = []\n",
    "precision_all=[]\n",
    "for i in range(10):\n",
    "    X_shuffle, y_shuffle, groups_shuffle = shuffle(X, y, groups, random_state=i)\n",
    "    kf = GroupKFold(n_splits=5)\n",
    "    coefficients = []\n",
    "    accuracies = []\n",
    "    recalls = []\n",
    "    precisions=[]\n",
    "    for train_index, test_index in kf.split(X_shuffle,y_shuffle, groups_shuffle):\n",
    "\n",
    "            # scale training and test data based on statistics of only training data\n",
    "        scaler = StandardScaler()\n",
    "        X_train_, X_test_ = X_shuffle[train_index], X_shuffle[test_index]\n",
    "        y_train_, y_test_ = y_shuffle[train_index], y_shuffle[test_index]\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train_)\n",
    "            # normalize data\n",
    "        X_train_, X_test_ = scaler.transform(X_train_), scaler.transform(X_test_)\n",
    "        model = SVC(kernel='linear', probability=True)\n",
    "        model.fit(X_train_, y_train_)\n",
    "        print(model.predict(X_test_))\n",
    "\n",
    "        accuracy = accuracy_score(y_test_, model.predict(X_test_))\n",
    "        accuracies.append(accuracy)\n",
    "        recall = recall_score(y_test_, model.predict(X_test_))\n",
    "        precision = precision_score(y_test_, model.predict(X_test_))\n",
    "        recalls.append(recall)\n",
    "        precisions.append(precision)\n",
    "        print(f\"Accuracy {accuracy:3f}\")\n",
    "        print(model.coef_)\n",
    "        coefficients.append(model.coef_)\n",
    "    accuracies_combined.append(mean(accuracies))\n",
    "    recall_all.append(mean(recalls))\n",
    "    precision_all.append(mean(precisions))\n",
    "    final_coef.append(mean(coefficients, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_shuffle, y_shuffle, groups_shuffle = shuffle(X, y, groups, random_state=1)\n",
    "kf = GroupKFold(n_splits=5)\n",
    "coefficients = []\n",
    "accuracies = []\n",
    "coefficients = []\n",
    "distances = []\n",
    "s_id=[]\n",
    "labels = []\n",
    "preds=[]\n",
    "for train_index, test_index in kf.split(X_shuffle,y_shuffle, groups_shuffle):\n",
    "\n",
    "            # scale training and test data based on statistics of only training data\n",
    "        scaler = StandardScaler()\n",
    "        X_train_, X_test_ = X_shuffle[train_index], X_shuffle[test_index]\n",
    "        y_train_, y_test_ = y_shuffle[train_index], y_shuffle[test_index]\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train_)\n",
    "            # normalize data\n",
    "        X_train_, X_test_ = scaler.transform(X_train_), scaler.transform(X_test_)\n",
    "        model = SVC(kernel='linear', probability=True)\n",
    "        model.fit(X_train_, y_train_)\n",
    "        prediction = model.predict(X_test_)\n",
    "        preds.append(prediction)\n",
    "        y = model.decision_function(X_test_)\n",
    "        i_d = groups_shuffle[test_index]\n",
    "        s_id.append(i_d)\n",
    "        labels.append(y_test_)\n",
    "        w_norm = np.linalg.norm(model.coef_)\n",
    "        dist = y / w_norm\n",
    "        distances.append(dist)\n",
    "        accuracy = accuracy_score(y_test_, model.predict(X_test_))\n",
    "        accuracies.append(accuracy)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = svc.decision_function(x)\n",
    "w_norm = np.linalg.norm(svc.coef_)\n",
    "dist = y / w_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, distances, s_id, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=0\n",
    "tuple_index_pred = list()\n",
    "while k<5:\n",
    "    for x, y,z, w in zip(labels[k], distances[k], s_id[k], preds[k]):\n",
    "        tuple_index_pred.append((x,y,z,w))\n",
    "    k = k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(list(zip([x[0] for x in tuple_index_pred],[x[1] for x in tuple_index_pred],\n",
    "                                [x[2] for x in tuple_index_pred],\n",
    "                                [x[3] for x in tuple_index_pred])), columns = ['label', 'distance', 'id', 'pred'])\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['distance']=final_df.distance.abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.sort_values(by='distance', ascending=False).groupby('id').head(5)\n",
    "# 80% correct by recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.groupby('id')['distance'].sum().nlargest(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.groupby('id')['distance'].sum().abs().nlargest(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.groupby('id')['distance'].sum().nsmallest(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.set_index('id')\n",
    "final_df.loc[[1108]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.loc[[1131]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "12/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "7/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now for meal only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('features.xlsx', sheet_name=\"Meal\", engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_id = np.array(data[\"Subject_ID\"])\n",
    "X = data.iloc[:,1:11].to_numpy()\n",
    "y = np.array([0 if x=='no_rad' else 1 for x in data.iloc[:,-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate accuracy and coefficients \n",
    "accuracies_meal = []\n",
    "final_coef =[]\n",
    "final_pred=[]\n",
    "final_dist=[]\n",
    "final_labels=[]\n",
    "final_id = []\n",
    "\n",
    "for i in range(10):\n",
    "    kf = KFold(n_splits=5, random_state=i, shuffle=True)\n",
    "    coefficients_play = []\n",
    "    accuracies = []\n",
    "    preds=[]\n",
    "    distances=[]\n",
    "    labels=[]\n",
    "    s_id=[]\n",
    "    for train_index, test_index in kf.split(X):\n",
    "\n",
    "            # scale training and test data based on statistics of only training data\n",
    "        scaler = StandardScaler()\n",
    "        X_train_, X_test_ = X[train_index], X[test_index]\n",
    "        y_train_, y_test_ = y[train_index], y[test_index]\n",
    "        s_id_train, s_id_test = subject_id[train_index], subject_id[test_index]\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train_)\n",
    "            # normalize data\n",
    "        X_train_, X_test_ = scaler.transform(X_train_), scaler.transform(X_test_)\n",
    "        model = SVC(kernel='linear')\n",
    "        model.fit(X_train_, y_train_)\n",
    "        accuracy = accuracy_score(y_test_, model.predict(X_test_))\n",
    "        accuracies.append(accuracy)\n",
    "        labels.append(y_test_)\n",
    "        y1 = model.decision_function(X_test_)\n",
    "        coefficients_play.append(model.coef_)\n",
    "        w_norm = np.linalg.norm(model.coef_)\n",
    "        dist = y1 / w_norm\n",
    "        distances.append(dist)\n",
    "        preds.append(model.predict(X_test_))\n",
    "        s_id.append(subject_id[test_index])\n",
    "        \n",
    "    accuracies_meal.append(mean(accuracies))\n",
    "    final_pred.append(preds)\n",
    "    final_dist.append(distances)\n",
    "    final_labels.append(labels)\n",
    "    final_id.append(s_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for x in final_pred:\n",
    "    for k in x:\n",
    "        for i in k:\n",
    "            predictions.append(i)\n",
    "        \n",
    "distances = []\n",
    "for x in final_dist:\n",
    "    for k in x:\n",
    "        for i in k:\n",
    "            distances.append(i)\n",
    "            \n",
    "labels = []\n",
    "for x in final_labels:\n",
    "    for k in x:\n",
    "        for i in k:\n",
    "            labels.append(i)\n",
    "\n",
    "ids= []\n",
    "for x in final_id:\n",
    "    for k in x:\n",
    "        for i in k:\n",
    "            ids.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(list(zip(predictions, distances, labels, ids)), columns = ['prediction', 'distance', 'label', 'id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.groupby('id').distance.mean().abs().sort_values(ascending=False), final_df.groupby('id').prediction.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.groupby('id').distance.mean().abs().sort_values(ascending=False).head(10)\n",
    "# 80% accuracy in the first 10 from play (averaged across 10 iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.groupby('id').prediction.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now for play \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
