{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first for meal\n",
    "import os\n",
    "import json\n",
    "import pyannote.core\n",
    "from pyannote.core import Timeline, Segment\n",
    "import statistics\n",
    "from pydub import AudioSegment\n",
    "import pandas as pd\n",
    "os.chdir('/Users/andrei-macpro/Documents/Data/Audio/overlapping_speech/overlapping_speech_play')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes as input a list of file-names and outputs a list of pyannote timelines \n",
    "path = '/Users/andrei-macpro/Documents/Data/Audio/overlapping_speech/overlapping_speech_play'\n",
    "json_files = [pos_json for pos_json in sorted(os.listdir(path)) if pos_json[0] !=\".\"]\n",
    "def get_timelines(json_files):\n",
    "    list_json=list()\n",
    "    list_timelines=list()\n",
    "    for filename in json_files: # loop that imports all json data into separate dictionaries\n",
    "        with open(filename) as json_file:\n",
    "            data = json.load(json_file)\n",
    "            list_json.append(data)\n",
    "    for file, segments in zip(json_files, list_json): # loop to iterate through the files and create a new timeline for each of them \n",
    "        timeline=Timeline()\n",
    "        list_timelines.append(timeline.from_json(segments))\n",
    "    return list_timelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_timelines=get_timelines(json_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/andrei-macpro/Documents/Data/Audio/only_speech/only_speech2/only_speech2_play'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_files = [file for file in sorted(os.listdir(path))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/andrei-macpro/Documents/Data/Audio/only_speech/only_speech2/only_speech2_play')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "du"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# because the timelines for non-Overlapping speech are fucked up (meaning that they don't include the segments\n",
    "# from time 0 to the first non-overlapped segment and the segment from the last non-overlapped one to the end of the recording)\n",
    "# I needed to add these to the timelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_timelines=list()\n",
    "for timeline, file_pydub in zip(list_timelines, pydub_files_meal):\n",
    "    if len(timeline)>0:\n",
    "        for segment in range(len(timeline)): \n",
    "            if segment ==0:\n",
    "                beginning=Segment(start=0, end=timeline[segment].start)\n",
    "            elif segment==len(timeline)-1:\n",
    "                end = Segment(start = timeline[segment].end  , end = file_pydub.duration_seconds)\n",
    "        no_os=Timeline()\n",
    "        for segment in timeline.gaps():\n",
    "            no_os.add(segment)\n",
    "        no_os.add(beginning)\n",
    "        no_os.add(end)\n",
    "        new_timelines.append(no_os)\n",
    "    else:\n",
    "        new_timelines.append(Segment(start=0, end=file_pydub.duration_seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_noos_timelines(default_timelines, pydub_files):\n",
    "    new_timelines=list()  \n",
    "    for timeline, file_pydub in zip(default_timelines, pydub_files):\n",
    "        if len(timeline)>0: # need this because some OS timelines are empty and it's gonna cause mayhem\n",
    "            for segment in range(len(timeline)): #need to get the first segment like this otherwise out of index error\n",
    "                if segment ==0:\n",
    "                    global beginning\n",
    "                    beginning=Segment(start=0, end=timeline[segment].start)\n",
    "                if segment==len(timeline)-1:  # same for last segment\n",
    "                    global end\n",
    "                    end = Segment(start = timeline[segment].end  , end = file_pydub.duration_seconds)\n",
    "            no_os=Timeline() \n",
    "            for segment in timeline.gaps(): #we're getting the no-overlapping speech segments here and adding start and end\n",
    "                no_os.add(segment)\n",
    "            no_os.add(beginning)\n",
    "            no_os.add(end)\n",
    "            new_timelines.append(no_os)\n",
    "        else:\n",
    "            no_os=Timeline() \n",
    "            no_os.add(Segment(start=0, end=file_pydub.duration_seconds))\n",
    "            new_timelines.append(no_os)\n",
    "    return(new_timelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_os_meal = create_noos_timelines(list_timelines, pydub_files_meal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/andrei-macpro/Documents/Data/Audio/overlapping_speech/no_os_play')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files(timestamps, pydub_files, file_names):\n",
    "    #timestamps = list containing timeline for every single file\n",
    "    #pydub files = the original files in pydub format \n",
    "    list_pydub=list()\n",
    "    speech=list()\n",
    "    for timeline, pydub_file in zip(timestamps, pydub_files):\n",
    "        speech=list()\n",
    "        for key, value in dict(timeline).items():\n",
    "            speech.append(pydub_file[key*1000:value*1000])\n",
    "        list_pydub.append(speech)\n",
    "    for file_name, audio in zip(file_names, list_pydub):\n",
    "        #if audio==\n",
    "        sum(audio).export(file_name, format='wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_files(no_os_meal, pydub_files_meal, raw_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ok so now we'll calculate the percent overlapping speech for play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_timelines_os_play = list_timelines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/andrei-macpro/Documents/Data/Audio/only_speech/only_speech2/timestamps_play')\n",
    "path = '/Users/andrei-macpro/Documents/Data/Audio/only_speech/only_speech2/timestamps_play'\n",
    "json_files = [pos_json for pos_json in sorted(os.listdir(path)) if pos_json[0] !=\".\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_timelines_speech_play=get_timelines(json_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_timelines[0].gaps().duration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entire duration of this speech file is 426 seconds \n",
    "# gaps seems to be 405 seconds and OS seems to be 8 seconds so 413 s in total so doesn't include start and end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion_os_play = [(os.duration()/timeline.duration())*100 for os, timeline in zip(list_timelines_os_play, \n",
    "                                                                                      list_timelines_speech_play)]\n",
    "avg_duration_os_play = [timeline.duration()/len(timeline) if len(timeline)!=0 else 0 for timeline in list_timelines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_duration_os_play=list()\n",
    "for timeline in list_timelines:\n",
    "    segment_duration=list()\n",
    "    if len(timeline)>1:\n",
    "        for segment in timeline:\n",
    "            segment_duration.append(segment.duration)\n",
    "        #print(segment_duration)\n",
    "        std_duration_os_play.append(statistics.stdev(segment_duration))\n",
    "    elif len(timeline)==1:\n",
    "        std_duration_os_play.append(timeline.duration())\n",
    "    else:\n",
    "        std_duration_os_play.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# would it not be better to do no of os_intervals per min? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/andrei-macpro/Documents/Data/Audio/only_speech/only_speech2/timestamps_meal')\n",
    "path = '/Users/andrei-macpro/Documents/Data/Audio/only_speech/only_speech2/timestamps_meal'\n",
    "json_files = [pos_json for pos_json in sorted(os.listdir(path)) if pos_json[0] !=\".\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_timelines_speech_meal=get_timelines(json_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/andrei-macpro/Documents/Data/Audio/overlapping_speech/overlapping_speech_meal')\n",
    "path = '//Users/andrei-macpro/Documents/Data/Audio/overlapping_speech/overlapping_speech_meal'\n",
    "json_files = [pos_json for pos_json in sorted(os.listdir(path)) if pos_json[0] !=\".\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_timelines_os_meal = get_timelines(json_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion_os_meal = [(os.duration()/timeline.duration())*100 for os, timeline in zip(list_timelines_os_meal, \n",
    "                                                                                      list_timelines_speech_meal)]\n",
    "avg_duration_os_meal = [timeline.duration()/len(timeline) if len(timeline)!=0 else 0 for timeline in list_timelines_os_meal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_duration_os_meal=list()\n",
    "for timeline in list_timelines_os_meal:\n",
    "    segment_duration=list()\n",
    "    if len(timeline)>1:\n",
    "        for segment in timeline:\n",
    "            segment_duration.append(segment.duration)\n",
    "        #print(segment_duration)\n",
    "        std_duration_os_meal.append(statistics.stdev(segment_duration))\n",
    "    elif len(timeline)==1:\n",
    "        std_duration_os_meal.append(timeline.duration())\n",
    "    else:\n",
    "        std_duration_os_meal.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_participants=sorted([int(i[:4]) for i in os.listdir(\".\") if i[0] !=\".\" ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(proportion_os_meal, avg_duration_os_meal, std_duration_os_meal,proportion_os_play, avg_duration_os_play, std_duration_os_play)),\n",
    "                  columns=['Overlapping speech meal', 'Avg OS meal', 'Std OS meal', 'Overlapping speech play', 'Avg OS play', 'Std OS play'],\n",
    "                  index=index_participants)\n",
    "df.index.name='Subject_ID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/andrei-macpro/Documents/Data/Results/os_results/features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('overlapping_speech_features.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
