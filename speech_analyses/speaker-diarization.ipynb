{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186fc32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777a2550",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyannote.audio import Pipeline\n",
    "pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2176b6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/andreibirladeanu/Documents/Data/Audio/sad_demonstration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6d72e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pipeline(\"speech.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4ad6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "available_models = [m.modelId for m in HfApi().list_models(filter=\"pyannote-audio-model\")]\n",
    "available_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ae7c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = \"/Users/andreibirladeanu/Documents/Data/Audio/sad_demonstration\"\n",
    "AUDIO_FILE = f\"{ROOT_DIR}/speech.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa573cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyannote.audio import Model\n",
    "model = Model.from_pretrained(\"pyannote/segmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1611af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyannote.audio import Inference\n",
    "inference = Inference(model, step=2.5)\n",
    "output = inference(AUDIO_FILE)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bf7519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "waveform, sample_rate = torchaudio.load(AUDIO_FILE)\n",
    "\n",
    "print(f\"{type(waveform)=}\")\n",
    "print(f\"{waveform.shape=}\")\n",
    "print(f\"{waveform.dtype=}\")\n",
    "\n",
    "audio_in_memory = {\"waveform\": waveform, \"sample_rate\": sample_rate}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e620874",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = inference(audio_in_memory)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22316563",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef7c6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyannote.audio.tasks import Segmentation\n",
    "seg = Segmentation(protocol, duration=2., batch_size=32, num_workers=4)\n",
    "model = SimpleSegmentationModel(task=seg)\n",
    "trainer = pl.Trainer(max_epochs=1)\n",
    "_ = trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47f749d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for speaker in output:\n",
    "    print(speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e8a812",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6e0a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install simple_diarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffc0307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dde4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_diarizer.diarizer import Diarizer\n",
    "from simple_diarizer.utils import combined_waveplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5391bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "diar = Diarizer(\n",
    "                  embed_model='ecapa', # 'xvec' and 'ecapa' supported\n",
    "                  cluster_method='sc' # 'ahc' and 'sc' supported\n",
    "               )\n",
    "\n",
    "segments = diar.diarize('speech.wav', num_speakers=2)\n",
    "\n",
    "signal, fs = sf.read('speech.wav')\n",
    "combined_waveplot(signal, fs, segments)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e00959",
   "metadata": {},
   "outputs": [],
   "source": [
    "segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e0ceb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_waveplot(signal, fs, segments, figsize=(10,3), tick_interval=60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378062a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(segments[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530f57d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for segment in segments:\n",
    "     for items in segment.items():\n",
    "        print(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb94af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
