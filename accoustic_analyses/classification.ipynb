{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/andrei-macpro/Documents/Data/classification/accoustics')\n",
    "data = pd.read_excel('features_child_meal.xlsx', engine='openpyxl', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,1:46].to_numpy()\n",
    "y = np.array([0 if x=='no_rad' else 1 for x in data.iloc[:,-1]])\n",
    "groups = data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = GroupKFold(n_splits=5)\n",
    "accuracies= []\n",
    "predictions = []\n",
    "indexes =[]\n",
    "ys = []\n",
    "for train_index, test_index in kf.split(X,y, groups):\n",
    "\n",
    "            # scale training and test data based on statistics of only training data\n",
    "    scaler = StandardScaler()\n",
    "    X_train_, X_test_ = X[train_index], X[test_index]\n",
    "    y_train_, y_test_ = y[train_index], y[test_index]\n",
    "    print(\"Train :\", train_index, \"Test :\", test_index)\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train_)\n",
    "        # normalize data\n",
    "    X_train_, X_test_ = scaler.transform(X_train_), scaler.transform(X_test_)\n",
    "    model = LogisticRegression(class_weight='balanced')\n",
    "    model.fit(X_train_, y_train_)\n",
    "    print(model.predict(X_test_))\n",
    "    predictions.append(model.predict(X_test_))\n",
    "   # accuracies.append(accuracy_score(y_test_, model.predict(X_test_)))\n",
    "    print(groups[test_index])\n",
    "    indexes.append(groups[test_index])\n",
    "    ys.append(y_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip([val for sublist in predictions for val in sublist], [val for sublist in indexes for val in sublist],\n",
    "                          [val for sublist in ys for val in sublist])), columns = ['prediction', 's_id', 'lbl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['s_id']).agg(lambda x:x.value_counts().index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "gss = GroupShuffleSplit(n_splits=1, train_size=48, random_state=42)\n",
    "gss.get_n_splits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_states = 10\n",
    "predictions = []\n",
    "indexes =[]\n",
    "ys = []\n",
    "for i in range(random_states):\n",
    "    gss = GroupShuffleSplit(n_splits=1, train_size=48, random_state=i)\n",
    "   \n",
    "    for train_idx, test_idx in gss.split(X, y, groups):\n",
    "        X_train_, X_test_ = X[train_idx], X[test_idx]\n",
    "        y_train_, y_test_ = y[train_idx], y[test_idx]\n",
    "        print(\"Train :\", train_idx, \"Test :\", test_idx)\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train_)\n",
    "        X_train_, X_test_ = scaler.transform(X_train_), scaler.transform(X_test_)\n",
    "        model = LogisticRegression(class_weight='balanced')\n",
    "        model.fit(X_train_, y_train_)\n",
    "        print(model.predict(X_test_))\n",
    "        predictions.append(model.predict(X_test_))\n",
    "        indexes.append(groups[test_idx])\n",
    "        ys.append(y_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip([val for sublist in predictions for val in sublist], [val for sublist in indexes for val in sublist],\n",
    "                          [val for sublist in ys for val in sublist])), columns = ['prediction', 's_id', 'lbl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['s_id']).agg(lambda x:x.value_counts().index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "indexes =[]\n",
    "ys = []\n",
    "for train_idx, test_idx in gss.split(X, y, groups):\n",
    "    X_train_, X_test_ = X[train_idx], X[test_idx]\n",
    "    y_train_, y_test_ = y[train_idx], y[test_idx]\n",
    "    print(\"Train :\", train_idx, \"Test :\", test_idx)\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train_)\n",
    "    X_train_, X_test_ = scaler.transform(X_train_), scaler.transform(X_test_)\n",
    "    model = LogisticRegression(class_weight='balanced')\n",
    "    model.fit(X_train_, y_train_)\n",
    "    print(model.predict(X_test_))\n",
    "    predictions.append(model.predict(X_test_))\n",
    "    indexes.append(groups[test_idx])\n",
    "    ys.append(y_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip([val for sublist in predictions for val in sublist], [val for sublist in indexes for val in sublist],\n",
    "                          [val for sublist in ys for val in sublist])), columns = ['prediction', 's_id', 'lbl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = GroupKFold(n_splits=5)\n",
    "accuracies= []\n",
    "predictions = []\n",
    "indexes =[]\n",
    "ys = []\n",
    "for train_index, test_index in kf.split(X,y, groups):\n",
    "\n",
    "            # scale training and test data based on statistics of only training data\n",
    "    scaler = StandardScaler()\n",
    "    X_train_, X_test_ = X[train_index], X[test_index]\n",
    "    y_train_, y_test_ = y[train_index], y[test_index]\n",
    "    print(\"Train :\", train_index, \"Test :\", test_index)\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train_)\n",
    "        # normalize data\n",
    "    X_train_, X_test_ = scaler.transform(X_train_), scaler.transform(X_test_)\n",
    "    model = MLPClassifier(max_iter=1000).fit(X_train_, y_train_)\n",
    "    print(model.predict(X_test_))\n",
    "    predictions.append(model.predict(X_test_))\n",
    "   # accuracies.append(accuracy_score(y_test_, model.predict(X_test_)))\n",
    "    print(groups[test_index])\n",
    "    indexes.append(groups[test_index])\n",
    "    ys.append(y_test_)\n",
    "\n",
    "df = pd.DataFrame(list(zip([val for sublist in predictions for val in sublist], [val for sublist in indexes for val in sublist],\n",
    "                          [val for sublist in ys for val in sublist])), columns = ['prediction', 's_id', 'lbl'])\n",
    "pd.set_option('display.max_rows', None)\n",
    "df.groupby(['s_id']).agg(lambda x:x.value_counts().index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip([val for sublist in predictions for val in sublist], [val for sublist in indexes for val in sublist],\n",
    "                          [val for sublist in ys for val in sublist])), columns = ['prediction', 's_id', 'lbl'])\n",
    "pd.set_option('display.max_rows', None)\n",
    "df.groupby(['s_id']).agg(lambda x:x.value_counts().index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    #GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    LogisticRegression(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_res = []\n",
    "for classifier in classifiers:\n",
    "    kf = GroupKFold(n_splits=5)\n",
    "    accuracies= []\n",
    "    predictions = []\n",
    "    indexes =[]\n",
    "    ys = []\n",
    "    for train_index, test_index in kf.split(X,y, groups):\n",
    "\n",
    "                # scale training and test data based on statistics of only training data\n",
    "        scaler = StandardScaler()\n",
    "        X_train_, X_test_ = X[train_index], X[test_index]\n",
    "        y_train_, y_test_ = y[train_index], y[test_index]\n",
    "        print(\"Train :\", train_index, \"Test :\", test_index)\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train_)\n",
    "            # normalize data\n",
    "        X_train_, X_test_ = scaler.transform(X_train_), scaler.transform(X_test_)\n",
    "        model = classifier.fit(X_train_, y_train_)\n",
    "        #print(model.predict(X_test_))\n",
    "        predictions.append(model.predict(X_test_))\n",
    "       # accuracies.append(accuracy_score(y_test_, model.predict(X_test_)))\n",
    "        #print(groups[test_index])\n",
    "        indexes.append(groups[test_index])\n",
    "        ys.append(y_test_)\n",
    "\n",
    "    df = pd.DataFrame(list(zip([val for sublist in predictions for val in sublist], [val for sublist in indexes for val in sublist],\n",
    "                              [val for sublist in ys for val in sublist])), columns = ['prediction', 's_id', 'lbl'])\n",
    "    final_res.append(df.groupby(['s_id']).agg(lambda x:x.value_counts().index[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_res[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
