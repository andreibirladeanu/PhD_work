{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import permutation_test_score\n",
    "from sklearn.model_selection import StratifiedGroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/andrei-macpro/Documents/Data/classification/accoustics/extraction_4.0')\n",
    "data = pd.read_excel('play_cg_prosody.xlsx',index_col=0)\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,:-1].to_numpy()\n",
    "y = np.array([0 if x=='no_rad' else 1 for x in data.iloc[:,-1]])\n",
    "groups = data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = GroupKFold(n_splits=5)\n",
    "accuracies= []\n",
    "predictions = []\n",
    "indexes =[]\n",
    "ys = []\n",
    "X_shuffled, y_shuffled, groups_shuffled = shuffle(X,y, groups,random_state=42)\n",
    "for train_index, test_index in kf.split(X_shuffled, y_shuffled, groups_shuffled):\n",
    "\n",
    "            # scale training and test data based on statistics of only training data\n",
    "    scaler = StandardScaler()\n",
    "    X_train_, X_test_ = X[train_index], X[test_index]\n",
    "    y_train_, y_test_ = y[train_index], y[test_index]\n",
    "    print(\"Train :\", train_index, \"Test :\", test_index)\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train_)\n",
    "        # normalize data\n",
    "    X_train_, X_test_ = scaler.transform(X_train_), scaler.transform(X_test_)\n",
    "    model = LogisticRegression(C=1.623776739188721, class_weight='balanced',\n",
    "                                     penalty='l2', solver='liblinear')\n",
    "    model.fit(X_train_, y_train_)\n",
    "    print(model.predict(X_test_))\n",
    "    predictions.append(model.predict(X_test_))\n",
    "    accuracies.append(accuracy_score(y_test_, model.predict(X_test_)))\n",
    "    indexes.append(groups[test_index])\n",
    "    ys.append(y_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.where(y==1)[0]), len(np.where(y==0)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "best_params_l2 = []\n",
    "best_scores=[]\n",
    "X_shuffled, y_shuffled, groups_shuffled = shuffle(X,y, groups ,random_state=42)\n",
    "importance = []\n",
    "for train, test in kf.split(X_shuffled, y_shuffled, groups_shuffled):\n",
    "\n",
    "    X_train, X_test, y_train, y_test,groups_shuffled_train, groups_shuffled_test = X_shuffled[train], X_shuffled[test], y_shuffled[train], y_shuffled[test], groups_shuffled[train], groups_shuffled[test]\n",
    "\n",
    "    pipe = Pipeline([('scaler', preprocessing.StandardScaler()),\n",
    "                                 ('clf', LogisticRegression(class_weight='balanced'))])\n",
    "   \n",
    "    C = [0.0001]\n",
    "    penalty = ['l2']\n",
    "    solver = ['liblinear']\n",
    "    param_grid = [{'clf__solver': solver,\n",
    "                  'clf__C': C,\n",
    "                  'clf__penalty': penalty}]\n",
    "    scoring = 'accuracy'\n",
    "\n",
    "    gs = GridSearchCV(estimator=pipe, param_grid = param_grid, scoring = scoring,refit=True)\n",
    "    gs.fit(X_train, y_train)\n",
    "    importance.append(gs.best_estimator_.named_steps['clf'].coef_[0])\n",
    "    print(gs.best_estimator_.named_steps['clf'].coef_[0])\n",
    "    best_score = gs.best_score_\n",
    "    print (\"Fold: {} {:.4f}\".format(scoring, best_score))\n",
    "    print(gs.best_estimator_.named_steps['clf'].predict_proba(X_train))\n",
    "    best_params_l2.append(gs.best_params_)\n",
    "    best_scores.append(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_l2, best_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run pca on dataset to get the most important features \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=5)\n",
    "principalcomponentst = pca.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "principalcomponentst.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip([val for sublist in predictions for val in sublist], [val for sublist in indexes for val in sublist],\n",
    "                          [val for sublist in ys for val in sublist])), columns = ['prediction', 's_id', 'lbl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['s_id']).agg(lambda x:x.value_counts().index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['s_id']).agg(lambda x:x.value_counts().index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "indexes =[]\n",
    "ys = []\n",
    "for train_idx, test_idx in gss.split(X, y, groups):\n",
    "    X_train_, X_test_ = X[train_idx], X[test_idx]\n",
    "    y_train_, y_test_ = y[train_idx], y[test_idx]\n",
    "    print(\"Train :\", train_idx, \"Test :\", test_idx)\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train_)\n",
    "    X_train_, X_test_ = scaler.transform(X_train_), scaler.transform(X_test_)\n",
    "    model = LogisticRegression(class_weight='balanced')\n",
    "    model.fit(X_train_, y_train_)\n",
    "    print(model.predict(X_test_))\n",
    "    predictions.append(model.predict(X_test_))\n",
    "    indexes.append(groups[test_idx])\n",
    "    ys.append(y_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip([val for sublist in predictions for val in sublist], [val for sublist in indexes for val in sublist],\n",
    "                          [val for sublist in ys for val in sublist])), columns = ['prediction', 's_id', 'lbl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip([val for sublist in predictions for val in sublist], [val for sublist in indexes for val in sublist],\n",
    "                          [val for sublist in ys for val in sublist])), columns = ['prediction', 's_id', 'lbl'])\n",
    "pd.set_option('display.max_rows', None)\n",
    "df.groupby(['s_id']).agg(lambda x:x.value_counts().index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    #GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    LogisticRegression(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_res = []\n",
    "for classifier in classifiers:\n",
    "    kf = GroupKFold(n_splits=5)\n",
    "    accuracies= []\n",
    "    predictions = []\n",
    "    indexes =[]\n",
    "    ys = []\n",
    "    for train_index, test_index in kf.split(X,y, groups):\n",
    "\n",
    "                # scale training and test data based on statistics of only training data\n",
    "        scaler = StandardScaler()\n",
    "        X_train_, X_test_ = X[train_index], X[test_index]\n",
    "        y_train_, y_test_ = y[train_index], y[test_index]\n",
    "        print(\"Train :\", train_index, \"Test :\", test_index)\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train_)\n",
    "            # normalize data\n",
    "        X_train_, X_test_ = scaler.transform(X_train_), scaler.transform(X_test_)\n",
    "        model = classifier.fit(X_train_, y_train_)\n",
    "        #print(model.predict(X_test_))\n",
    "        predictions.append(model.predict(X_test_))\n",
    "       # accuracies.append(accuracy_score(y_test_, model.predict(X_test_)))\n",
    "        #print(groups[test_index])\n",
    "        indexes.append(groups[test_index])\n",
    "        ys.append(y_test_)\n",
    "\n",
    "    df = pd.DataFrame(list(zip([val for sublist in predictions for val in sublist], [val for sublist in indexes for val in sublist],\n",
    "                              [val for sublist in ys for val in sublist])), columns = ['prediction', 's_id', 'lbl'])\n",
    "    final_res.append(df.groupby(['s_id']).agg(lambda x:x.value_counts().index[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##!!!!!!!! this is the pipeline!!!LR\n",
    "\n",
    "best_estimators = []\n",
    "#accuracies = []\n",
    "\n",
    "results = []\n",
    "predictions = []\n",
    "#X,y, groups = shuffle(X,y,data.index ,random_state=42)\n",
    "X_shuffled, y_shuffled, groups_shuffled = shuffle(X,y,groups ,random_state=42)\n",
    "\n",
    "scalar = preprocessing.StandardScaler()\n",
    "parameter_candidates = {'model__penalty':['l1'], 'model__solver':['liblinear'],\n",
    "                        'model__C':np.logspace(-4,4,20)}\n",
    "clf = LogisticRegression(class_weight='balanced')\n",
    "pipeline = Pipeline(steps=[('preprocess', scalar), ('model', clf)])\n",
    "\n",
    "cv = GroupKFold(n_splits=5)\n",
    "#cross_val_score(pipeline, X, y, cv = cv)\n",
    "search = GridSearchCV(pipeline, parameter_candidates, scoring = ['accuracy','f1'],refit='f1', cv =cv)\n",
    "\n",
    "search.fit(X_shuffled, y_shuffled, groups = groups_shuffled)\n",
    "print(search.best_score_)\n",
    "print(search.best_estimator_)\n",
    "#pruint(pd.DataFrame.from_dict(search.cv_results_))\n",
    "#predictions.append(search.best_estimator_.predict(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.cv_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_shuffled, y_shuffled, groups_shuffled = shuffle(X,y,data.index ,random_state=42)\n",
    "scoring = ['accuracy', 'recall','precision','f1']\n",
    "scaler = preprocessing.StandardScaler()\n",
    "clf = LogisticRegression(C=0.0001,class_weight='balanced',penalty='l1', solver='liblinear')\n",
    "pipe = Pipeline(steps=[(\"scaler\", scaler), (\"clf\", clf)])\n",
    "cv = GroupKFold(n_splits=5)\n",
    "\n",
    "\n",
    "scores = cross_validate(pipe, X_shuffled, y_shuffled,groups=groups_shuffled, cv=cv, scoring=scoring, return_estimator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores['test_recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_scores = []\n",
    "for i in range(0,100):\n",
    "    y_shuffled,groups_shuffled= shuffle(y,groups,random_state=i)\n",
    "    scoring = ['accuracy', 'recall','precision','f1']\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    clf = LogisticRegression(C=1.61584821106602,class_weight='balanced',penalty='l2', solver='liblinear')\n",
    "    pipe = Pipeline(steps=[(\"scaler\", scaler), (\"clf\", clf)])\n",
    "    cv = GroupKFold(n_splits=5)\n",
    "    scores = cross_validate(pipe, X, y_shuffled,groups=groups_shuffled, cv=cv, scoring=scoring)\n",
    "    _scores.append(np.mean(scores['test_accuracy']))\n",
    "_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "def permutation_test(X,y,groups, clf):\n",
    "    _scores = []\n",
    "    for i in range(0,100):\n",
    "        y_shuffled,groups_shuffled= shuffle(y,groups,random_state=i)\n",
    "        \n",
    "        scoring = ['accuracy', 'recall','precision','f1']\n",
    "        scaler = preprocessing.StandardScaler()\n",
    "        pipe = Pipeline(steps=[(\"scaler\", scaler), (\"clf\", clf)])\n",
    "        cv = GroupKFold(n_splits=5)\n",
    "        scores = cross_validate(pipe, X, y_shuffled,groups=groups_shuffled, cv=cv, scoring=scoring)\n",
    "        _scores.append(np.mean(scores['test_accuracy']))\n",
    "    score_no_perm = cross_validate(pipe, X_shuffled, y_shuffled,groups=groups_shuffled, cv=cv, scoring=scoring)\n",
    "    t_test = stats.ttest_1samp(_scores, np.mean(score_no_perm['test_accuracy']))\n",
    "    return(_scores,np.mean(score_no_perm['test_accuracy']), t_test.pvalue)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation_test(X,y,groups, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_importances = [x.named_steps['clf'].coef_[0] for x in  scores['estimator']]\n",
    "np.mean(f_importances,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.Series(np.mean(f_importances, axis=0), index=data.columns[:-1])\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.abs().nlargest(20).plot(kind='barh')\n",
    "plt.savefig('features_child_meal_2.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### apply t test on features\n",
    "from itertools import combinations\n",
    "from scipy.stats import ttest_ind\n",
    "grps = data['label'].unique()\n",
    "combs = combinations(grps, 2)\n",
    "\n",
    "ttests = {\n",
    "    f'{c1}_{c2}': ttest_ind(\n",
    "        data.loc[data['label'] == c1, 'f0_mean'], \n",
    "        data.loc[data['label'] == c2, 'f0_mean']\n",
    "    ) for c1, c2 in combs\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('label')['f0_mean'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import std, mean, sqrt\n",
    "def cohen_d(x,y):\n",
    "    nx = len(x)\n",
    "    ny = len(y)\n",
    "    dof = nx + ny - 2\n",
    "    return (mean(x) - mean(y)) / sqrt(((nx-1)*std(x, ddof=1) ** 2 + (ny-1)*std(y, ddof=1) ** 2) / dof)\n",
    "cohen_d(rad_abs_jitter['f0_mean'], norad_abs_jitter['f0_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rad_abs_jitter = data[['localabsoluteJitter' ,'f0_mean']].loc[data['label'] == 'rad']\n",
    "norad_abs_jitter = data[['localabsoluteJitter','f0_mean']].loc[data['label'] == 'no_rad']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, np.mean(scores['test_accuracy']), np.mean(scores['test_recall']), np.mean(scores['test_precision'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C=1.61584821106602,class_weight='balanced',penalty='l2', solver='liblinear')\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('clf',clf)])\n",
    "cv = GroupKFold(n_splits=5)\n",
    "score, permutation_score, pval = permutation_test_score(pipe,X_shuffled, y_shuffled,groups=groups_shuffled,\n",
    "                                                        n_permutations = 100, cv = cv,scoring=\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, permutation_score, pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##!!!!!!!! this is the pipeline!!!\n",
    "\n",
    "best_estimators = [] \n",
    "#accuracies = []\n",
    "\n",
    "results = []\n",
    "predictions = []\n",
    "#X,y, groups = shuffle(X,y,data.index ,random_state=42)\n",
    "\n",
    "X_shuffled, y_shuffled, groups_shuffled = shuffle(X,y,groups ,random_state=42)\n",
    "\n",
    "scalar = preprocessing.StandardScaler()\n",
    "parameter_candidates = {'model__C':[0.001, 0.01, 0.1, 1, 10, 100], 'model__gamma':[0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                        'model__kernel':['rbf']}\n",
    "clf = SVC(class_weight='balanced')\n",
    "pipeline = Pipeline(steps=[('preprocess', scalar), ('model', clf)])\n",
    "\n",
    "cv = GroupKFold(n_splits=5)\n",
    "#cross_val_score(pipeline, X, y, cv = cv)\n",
    "search = GridSearchCV(pipeline, parameter_candidates, scoring = 'accuracy', cv =cv)\n",
    "\n",
    "search.fit(X_shuffled, y_shuffled, groups = groups_shuffled)\n",
    "print(search.best_score_)\n",
    "print(search.best_estimator_)\n",
    "#pruint(pd.DataFrame.from_dict(search.cv_results_))\n",
    "#predictions.append(search.best_estimator_.predict(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## idea: shift the labels between groups not within groups "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_shuffled, y_shuffled, groups_shuffled = shuffle(X,y,data.index ,random_state=42)\n",
    "scoring = ['accuracy', 'recall','precision', 'f1']\n",
    "scaler = preprocessing.StandardScaler()\n",
    "clf = SVC(kernel='rbf',C=0.001, gamma= 0.001, class_weight='balanced')\n",
    "pipe = Pipeline(steps=[(\"scaler\", scaler), (\"classifier\", clf)])\n",
    "cv = StratifiedGroupKFold(n_splits=5)\n",
    "\n",
    "scores = cross_validate(pipe, X_shuffled, y_shuffled,groups=groups_shuffled, cv=cv, scoring=scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv =GroupKFold(n_splits=5)\n",
    "i=1\n",
    "for train, test in cv.split(y,groups=groups_shuffled):\n",
    "    print('Fold:',i,\"Train:\",np.unique(y[train]),'group train:',np.unique(groups_shuffled[train]),'group test:',np.unique(groups_shuffled[test]), \"Test:\",np.unique(y[test]))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(scores['test_accuracy']), np.mean(scores['test_recall']), np.mean(scores['test_precision']), np.mean(scores['test_f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "cv = GroupShuffleSplit(n_splits=10, train_size=.8, random_state=42)\n",
    "clf = LogisticRegression(C=1.61584821106602,class_weight='balanced',penalty='l2', solver='liblinear')\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('clf', clf)])\n",
    "score, permutation_score, pval = permutation_test_score(pipe,X_shuffled, y_shuffled,groups=groups_shuffled,\n",
    "                                                        n_permutations = 100, cv = cv,scoring=\"accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, permutation_score, pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### group by group and shuffle labels:\n",
    "original_grouping_vector = data.index\n",
    "unique_values, indexes, inverse = np.unique(original_grouping_vector, return_inverse=True, return_index=True)\n",
    "new_grouping_vector = indexes[inverse] # This is where the magic happens!\n",
    "\n",
    "splitter = GroupKFold()\n",
    "for train, test in splitter.split(X, y, groups=new_grouping_vector):\n",
    "    print(data.iloc[test, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### group by group and shuffle labels:\n",
    "original_grouping_vector = data.index\n",
    "unique_values, indexes, inverse = np.unique(original_grouping_vector, return_inverse=True, return_index=True)\n",
    "new_grouping_vector = indexes[inverse] # This is where the magic happens!\n",
    "## inverse are the indices of the duplicated indices in original array \n",
    "## indexes are the indices of the unique values in original array\n",
    "splitter = GroupKFold()\n",
    "for train, test in splitter.split(X, y, groups=new_grouping_vector):\n",
    "    print(data.iloc[test, :],y[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### shuffle the y's but keep them consistent within groups \n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "gss = GroupShuffleSplit(n_splits=1, train_size=.8, random_state=42)\n",
    "for train_index, test_index in gss.split(X, y, groups):\n",
    "    print(\"TRAIN:\", np.unique(groups[train_index]), \"TEST:\", np.unique(groups[test_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pval, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('scaler', StandardScaler()), ('clf',logistic)])\n",
    "cv = KFold(n_splits=5)\n",
    "score, permutation_score, pval = permutation_test_score(pipe,X_shuffled, y_shuffled,\n",
    "                                                        n_permutations = 100, cv = cv,scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, permutation_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_shuffled, y_shuffled, groups_shuffled = shuffle(X,y,data.index ,random_state=42)\n",
    "scoring = ['accuracy', 'recall','precision']\n",
    "scaler = preprocessing.StandardScaler()\n",
    "clf = SVC(kernel='rbf',C=0.001,gamma= 0.001, class_weight='balanced')\n",
    "pipe = Pipeline(steps=[(\"scaler\", scaler), (\"classifier\", clf)])\n",
    "cv = GroupKFold(n_splits=5)\n",
    "\n",
    "scores = cross_validate(pipe, X_shuffled, y_shuffled,groups_shuffled, cv=cv, scoring=scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
