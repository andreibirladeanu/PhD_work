{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d15b2b6",
   "metadata": {},
   "source": [
    "# this notebook performs random forest regression on aggregate data of all acoustic scenarios (cg meal, cg play, child meal)\\\n",
    "for random forest regression on the entire acoustic data see a different notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd44c3525e1fa80a",
   "metadata": {},
   "source": [
    "# first running random forest regression on the aggregate dataset - caregiver meal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f6f01fb57dcc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset as pandas DataFrame  \n",
    "# read pandas from xlsx file\n",
    "\n",
    "df = pd.read_excel('/Users/andrei-macpro/Documents/Data/classification/accoustics/extraction_3.0/cg_meal_prosody_regression.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5835139a2b6d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from df remove columns \"intensity_percentile_1_99_range\"  \n",
    "df = df.drop(columns=['intensity_percentile_1_99_range', 'loudness_slidingwindow_percentile_1_99_range', \n",
    "                      'intensity_percentile_1_99_range', 'rms_mean', 'rms_std','rms_percentile_1_99_range'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e672f62d6899506a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn the dataset except the first column and last 2 columns into a numpy array \n",
    "X = df.iloc[:, 1:-2].values\n",
    "s_id = df.iloc[:,0].values\n",
    "dai = df.iloc[:,-2].values\n",
    "rinab = df.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86be3b6b1ab79225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run a random forest regression model on the dataset \n",
    "# define the model\n",
    "model = RandomForestRegressor(random_state=0, n_jobs=1)\n",
    "# shuffle the dataset\n",
    "X, s_id, dai, rinab = shuffle(X, s_id, dai, rinab, random_state=0) \n",
    "# define the evaluation procedure\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "# evaluate the model using mean squared error, coefficient of determination, and explained variance score\n",
    "scoring = ['neg_mean_squared_error', 'r2', 'explained_variance']\n",
    "scores = cross_validate(model, X, rinab, scoring=scoring, cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Mean MSE: %.3f (%.3f)' % (mean(scores['test_neg_mean_squared_error']), std(scores['test_neg_mean_squared_error'])))\n",
    "print('Mean R^2: %.3f (%.3f)' % (mean(scores['test_r2']), std(scores['test_r2'])))\n",
    "print('Mean EV: %.3f (%.3f)' % (mean(scores['test_explained_variance']), std(scores['test_explained_variance'])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b4543b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the dataset\n",
    "X, s_id, dai, rinab = shuffle(X, s_id, dai, rinab, random_state=0) \n",
    "# define the model\n",
    "model = RandomForestRegressor(random_state=0, n_jobs=1)\n",
    "# define the evaluation procedure\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "# evaluate the model using mean squared error, coefficient of determination, and explained variance score\n",
    "scoring = ['neg_mean_squared_error', 'r2', 'explained_variance']\n",
    "scores = cross_validate(model, X, rinab, scoring=scoring, cv=cv, n_jobs=1)\n",
    "# report performance\n",
    "print('Mean MSE: %.3f (%.3f)' % (mean(scores['test_neg_mean_squared_error']), std(scores['test_neg_mean_squared_error'])))\n",
    "print('Mean R^2: %.3f (%.3f)' % (mean(scores['test_r2']), std(scores['test_r2'])))\n",
    "print('Mean EV: %.3f (%.3f)' % (mean(scores['test_explained_variance']), std(scores['test_explained_variance'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6f48e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the dataset into training and testing sets\n",
    "X_train, X_test, s_id_train, s_id_test, dai_train, dai_test, rinab_train, rinab_test = train_test_split(X, s_id, dai, rinab, test_size=0.2, random_state=0)\n",
    "\n",
    "# define the model\n",
    "model = RandomForestRegressor(random_state=0, n_jobs=1)\n",
    "\n",
    "# define the evaluation procedure\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# evaluate the model using mean squared error, coefficient of determination, and explained variance score\n",
    "scoring = ['neg_mean_squared_error', 'r2', 'explained_variance']\n",
    "scores = cross_validate(model, X_train, rinab_train, scoring=scoring, cv=cv, n_jobs=1)\n",
    "\n",
    "# report performance\n",
    "print('Mean MSE: %.3f (%.3f)' % (mean(scores['test_neg_mean_squared_error']), std(scores['test_neg_mean_squared_error'])))\n",
    "print('Mean R^2: %.3f (%.3f)' % (mean(scores['test_r2']), std(scores['test_r2'])))\n",
    "print('Mean EV: %.3f (%.3f)' % (mean(scores['test_explained_variance']), std(scores['test_explained_variance'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6923d7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore why the r2 score is negative\n",
    "# use regularization for over or underfitting\n",
    "# scale the features \n",
    "# do feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a423515d",
   "metadata": {},
   "source": [
    "# feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9608d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# split the dataset into training and testing sets\n",
    "X_train, X_test, s_id_train, s_id_test, dai_train, dai_test, rinab_train, rinab_test = train_test_split(X, s_id, dai, rinab, test_size=0.2, random_state=0)\n",
    "\n",
    "# perform feature scaling\n",
    "## to note - the scaling is done on the training set and then applied to the test set - very good!\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# define the model\n",
    "model = RandomForestRegressor(random_state=0, n_jobs=1)\n",
    "\n",
    "# define the evaluation procedure\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# evaluate the model using mean squared error, coefficient of determination, and explained variance score\n",
    "scoring = ['neg_mean_squared_error', 'r2', 'explained_variance']\n",
    "scores = cross_validate(model, X_train_scaled, rinab_train, scoring=scoring, cv=cv, n_jobs=1)\n",
    "\n",
    "# report performance\n",
    "print('Mean MSE: %.3f (%.3f)' % (mean(scores['test_neg_mean_squared_error']), std(scores['test_neg_mean_squared_error'])))\n",
    "print('Mean R^2: %.3f (%.3f)' % (mean(scores['test_r2']), std(scores['test_r2'])))\n",
    "print('Mean EV: %.3f (%.3f)' % (mean(scores['test_explained_variance']), std(scores['test_explained_variance'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e220218a",
   "metadata": {},
   "source": [
    "# hypermarameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99d4289",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# define the model\n",
    "model = RandomForestRegressor(random_state=0, n_jobs=1)\n",
    "\n",
    "# define the hyperparameters to tune\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# define the evaluation procedure\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# perform grid search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='r2', cv=cv, n_jobs=1)\n",
    "grid_search.fit(X_train_scaled, rinab_train)\n",
    "\n",
    "# get the best hyperparameters and model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# evaluate the best model using mean squared error, coefficient of determination, and explained variance score\n",
    "scoring = ['neg_mean_squared_error', 'r2', 'explained_variance']\n",
    "scores = cross_validate(best_model, X_train_scaled, rinab_train, scoring=scoring, cv=cv, n_jobs=1)\n",
    "\n",
    "# report performance\n",
    "print('Best Hyperparameters:', best_params)\n",
    "print('Mean MSE: %.3f (%.3f)' % (mean(scores['test_neg_mean_squared_error']), std(scores['test_neg_mean_squared_error'])))\n",
    "print('Mean R^2: %.3f (%.3f)' % (mean(scores['test_r2']), std(scores['test_r2'])))\n",
    "print('Mean EV: %.3f (%.3f)' % (mean(scores['test_explained_variance']), std(scores['test_explained_variance'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a1ef39",
   "metadata": {},
   "source": [
    "ùëÖ2 can range from -‚àû to 1 in the world of machine learning. The closer ùëÖ2 is to 1, the better the model performance. There is a common misconception that ùëÖ2 can only range from 0 to 1. As shown in the formula of ùëÖ2 above, we can see that ùëÖ2 can be less than 0. This situation happens when the MSE of our designed model is larger than the 32 MSE of the baseline model that only predicts the mean value, which is a horizontal line. Simply speaking, in the world of machine learning, when your model is doing worse than a horizontal line in fitting the data, ùëÖ2 can be negative. \n",
    "\n",
    "Predictive modeling of webpage aesthetics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ee5128",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# perform feature scaling\n",
    "## to note - the scaling is done on the training set and then applied to the test set - very good!\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "# define the model\n",
    "model = RandomForestRegressor(random_state=0, n_jobs=1)\n",
    "\n",
    "# define the hyperparameters to tune\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# define the evaluation procedure\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# perform grid search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='r2', cv=cv, n_jobs=1)\n",
    "grid_search.fit(X_scaled, rinab)\n",
    "\n",
    "# get the best hyperparameters and model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# evaluate the best model using mean squared error, coefficient of determination, and explained variance score\n",
    "scoring = ['neg_mean_squared_error', 'r2', 'explained_variance']\n",
    "scores = cross_validate(best_model, X_scaled, rinab, scoring=scoring, cv=cv, n_jobs=1)\n",
    "\n",
    "# report performance\n",
    "print('Best Hyperparameters:', best_params)\n",
    "print('Mean MSE: %.3f (%.3f)' % (mean(scores['test_neg_mean_squared_error']), std(scores['test_neg_mean_squared_error'])))\n",
    "print('Mean R^2: %.3f (%.3f)' % (mean(scores['test_r2']), std(scores['test_r2'])))\n",
    "print('Mean EV: %.3f (%.3f)' % (mean(scores['test_explained_variance']), std(scores['test_explained_variance'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e562f2",
   "metadata": {},
   "source": [
    "## Results for Random Forest Regression (with 5-fold cross-validation, hyperparameter tuning) on Rinab in caregiver meal acoustic with participant aggregate data\n",
    "\n",
    "mean (std) \\\n",
    "\n",
    "Best Hyperparameters: {'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 200} \\\n",
    "\n",
    "Mean MSE: -41.168 (21.984) \\\n",
    "\n",
    "Mean R^2: -0.335 (0.192) \\\n",
    "\n",
    "Mean EV: -0.272 (0.230)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e5bb92",
   "metadata": {},
   "source": [
    "## Results for Random Forest Regression (with 5-fold cross-validation, hyperparameter tuning) on DAI in caregiver meal acoustic with participant aggregate data\n",
    "mean(std) \\\n",
    "Best Hyperparameters: {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 300} \n",
    "\n",
    "Mean MSE: -4.675 (1.157)\\\n",
    "Mean R^2: -0.616 (0.558)\\\n",
    "Mean EV: -0.316 (0.420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ff8a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# perform feature scaling\n",
    "## to note - the scaling is done on the training set and then applied to the test set - very good!\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "# define the model\n",
    "model = RandomForestRegressor(random_state=0, n_jobs=1)\n",
    "\n",
    "# define the hyperparameters to tune\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# define the evaluation procedure\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# perform grid search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='r2', cv=cv, n_jobs=1)\n",
    "grid_search.fit(X_scaled, dai)\n",
    "\n",
    "# get the best hyperparameters and model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# evaluate the best model using mean squared error, coefficient of determination, and explained variance score\n",
    "scoring = ['neg_mean_squared_error', 'r2', 'explained_variance']\n",
    "scores = cross_validate(best_model, X_scaled, dai, scoring=scoring, cv=cv, n_jobs=1)\n",
    "\n",
    "# report performance\n",
    "print('Best Hyperparameters:', best_params)\n",
    "print('Mean MSE: %.3f (%.3f)' % (mean(scores['test_neg_mean_squared_error']), std(scores['test_neg_mean_squared_error'])))\n",
    "print('Mean R^2: %.3f (%.3f)' % (mean(scores['test_r2']), std(scores['test_r2'])))\n",
    "print('Mean EV: %.3f (%.3f)' % (mean(scores['test_explained_variance']), std(scores['test_explained_variance'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9187fec9",
   "metadata": {},
   "source": [
    "# now running the same code on the cg play dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca368982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset as pandas DataFrame  \n",
    "# read pandas from xlsx file\n",
    "\n",
    "df = pd.read_csv('/Users/andrei-macpro/Documents/Data/classification/accoustics/extraction_3.0/cg_play_prosody_regression.csv')\n",
    "# from df remove columns \"intensity_percentile_1_99_range\"  \n",
    "df = df.drop(columns=['intensity_percentile_1_99_range', 'loudness_slidingwindow_percentile_1_99_range', \n",
    "                      'intensity_percentile_1_99_range', 'rms_mean', 'rms_std','rms_percentile_1_99_range'])\n",
    "\n",
    "# turn the dataset except the first column and last 2 columns into a numpy array \n",
    "X = df.iloc[:, 1:-2].values\n",
    "s_id = df.iloc[:,0].values\n",
    "dai = df.iloc[:,-2].values\n",
    "rinab = df.iloc[:,-1].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a2b268",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# perform feature scaling\n",
    "## to note - the scaling is done on the training set and then applied to the test set - very good!\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "# define the model\n",
    "model = RandomForestRegressor(random_state=0, n_jobs=1)\n",
    "\n",
    "# define the hyperparameters to tune\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# define the evaluation procedure\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# perform grid search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='r2', cv=cv, n_jobs=1)\n",
    "grid_search.fit(X_scaled, dai)\n",
    "\n",
    "# get the best hyperparameters and model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# evaluate the best model using mean squared error, coefficient of determination, and explained variance score\n",
    "scoring = ['neg_mean_squared_error', 'r2', 'explained_variance']\n",
    "scores = cross_validate(best_model, X_scaled, dai, scoring=scoring, cv=cv, n_jobs=1)\n",
    "\n",
    "# report performance\n",
    "print('Best Hyperparameters:', best_params)\n",
    "print('Mean MSE: %.3f (%.3f)' % (mean(scores['test_neg_mean_squared_error']), std(scores['test_neg_mean_squared_error'])))\n",
    "print('Mean R^2: %.3f (%.3f)' % (mean(scores['test_r2']), std(scores['test_r2'])))\n",
    "print('Mean EV: %.3f (%.3f)' % (mean(scores['test_explained_variance']), std(scores['test_explained_variance'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8390090",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b3aef3",
   "metadata": {},
   "source": [
    "## Results for Random Forest Regression (with 5-fold cross-validation, hyperparameter tuning) on DAI in caregiver play acoustic with participant aggregate data\\\n",
    "Best Hyperparameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\\\n",
    "Mean MSE: -3.809 (0.660)\\\n",
    "Mean R^2: -0.220 (0.391)\\\n",
    "Mean EV: -0.135 (0.301)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5345db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# perform feature scaling\n",
    "## to note - the scaling is done on the training set and then applied to the test set - very good!\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "# define the model\n",
    "model = RandomForestRegressor(random_state=0, n_jobs=1)\n",
    "\n",
    "# define the hyperparameters to tune\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# define the evaluation procedure\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# perform grid search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='r2', cv=cv, n_jobs=1)\n",
    "grid_search.fit(X_scaled, rinab)\n",
    "\n",
    "# get the best hyperparameters and model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# evaluate the best model using mean squared error, coefficient of determination, and explained variance score\n",
    "scoring = ['neg_mean_squared_error', 'r2', 'explained_variance']\n",
    "scores = cross_validate(best_model, X_scaled, rinab, scoring=scoring, cv=cv, n_jobs=1)\n",
    "\n",
    "# report performance\n",
    "print('Best Hyperparameters:', best_params)\n",
    "print('Mean MSE: %.3f (%.3f)' % (mean(scores['test_neg_mean_squared_error']), std(scores['test_neg_mean_squared_error'])))\n",
    "print('Mean R^2: %.3f (%.3f)' % (mean(scores['test_r2']), std(scores['test_r2'])))\n",
    "print('Mean EV: %.3f (%.3f)' % (mean(scores['test_explained_variance']), std(scores['test_explained_variance'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8976b30",
   "metadata": {},
   "source": [
    "## Results for Random Forest Regression (with 5-fold cross-validation, hyperparameter tuning) on Rinab in caregiver play acoustic with participant aggregate data\\\n",
    "Best Hyperparameters: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 100}\\\n",
    "Mean MSE: -51.585 (21.752)\\\n",
    "Mean R^2: -0.360 (0.484)\\\n",
    "Mean EV: -0.193 (0.281)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a40f88",
   "metadata": {},
   "source": [
    "# now running the same code on the child meal dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
