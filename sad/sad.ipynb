{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying out just one file and concatenating the speech segments to assess them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/andrei-macpro/.cache/torch/hub/pyannote_pyannote-audio_master\n"
     ]
    }
   ],
   "source": [
    "import pyannote.core\n",
    "from pydub import AudioSegment\n",
    "file = {'uri':'1043_meal', 'audio':'/Users/andrei-macpro/Documents/Data/Audio/Meal/1043_meal.wav'}\n",
    "import torch\n",
    "# speech activity detection model trained on AMI training set\n",
    "sad = torch.hub.load('pyannote/pyannote-audio', 'sad_ami')\n",
    "# obtain raw SAD scores (as `pyannote.core.SlidingWindowFeature` instance)\n",
    "sad_scores = sad(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyannote.audio.utils.signal import Binarize\n",
    "binarize = Binarize(offset=0.52, onset=0.52, log_scale=True, \n",
    "                    min_duration_off=0.1, min_duration_on=0.1)\n",
    "\n",
    "# speech regions (as `pyannote.core.Timeline` instance)\n",
    "speech = binarize.apply(sad_scores, dimension=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyannote.core.segment.Segment"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert timestamps to miliseconds \n",
    "type(speech[0])\n",
    "# speech is a timeline made of segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#extract speech and non-speech segments (start and end time) as a dictionary\n",
    "timestamps_speech=dict(speech)\n",
    "timestamps_silence = dict(speech.gaps())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file=AudioSegment.from_wav('/Users/andrei-macpro/Documents/Data/Audio/1043_meal.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pydub works in miliseconds so we're going to convert the timestamps from the pyannote seconds to miliseconds\n",
    "start_times_speech=[x*1000 for x in list(timestamps_speech.keys())]\n",
    "end_times_speech=[x*1000 for x in list(timestamps_speech.values())]\n",
    "start_times_silence=[x*1000 for x in list(timestamps_silence.keys())]\n",
    "end_times_silence=[x*1000 for x in list(timestamps_silence.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "speech_segments=[file[start_time:end_time] for start_time,end_time in zip(start_times_speech, end_times_speech)]\n",
    "silence_segments=[file[start_time:end_time] for start_time,end_time in zip(start_times_silence, end_times_silence)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# export the concatenated speech and silence segments to disk\n",
    "sum(speech_segments).export('/Users/andrei-macpro/Documents/Data/Audio/speech.wav', format=\"wav\")\n",
    "sum(silence_segments).export('/Users/andrei-macpro/Documents/Data/Audio/non-speech.wav', format=\"wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Now let's get on with the full speech detection processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pyannote.core\n",
    "import torch\n",
    "from pyannote.core import Timeline, Segment\n",
    "from pyannote.audio.utils.signal import Binarize\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/andrei-macpro/Documents/Data/Audio/Meal')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/andrei-macpro/Documents/Data/Audio/Meal'  #if string starts with slash it is considered absolute\n",
    "dirs = os.listdir( path )\n",
    "file_names=sorted([i for i in os.listdir(\".\") if not i.startswith(\".\")])\n",
    "#file_names = [x.replace('.wav','') for x in file_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sad = torch.hub.load('pyannote/pyannote-audio', 'sad_ami') # ok so this isn't taking up too much memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binarize = Binarize(offset=0.52, onset=0.52, log_scale=True, \n",
    "                    min_duration_off=0.1, min_duration_on=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract a dictionary of key-filename : value-#pyannoteTimeline \n",
    "def timeline(file_names):\n",
    "    temp_list1=list()\n",
    "    temp_list2=list()\n",
    "    for file_name in tqdm(file_names):\n",
    "        sad_scores=sad(file_name)\n",
    "        speech=binarize.apply(sad_scores,dimension=1)\n",
    "        del sad_scores\n",
    "        temp_list1.append(file_name.get('audio'))\n",
    "        temp_list2.append(speech)\n",
    "    trial_dict=dict(zip(temp_list1,temp_list2))\n",
    "    return trial_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract json files of the #pyannoteTimeline objects which can then be loaded again\n",
    "def write_disk(sad_segments):\n",
    "    for key in sad_segments.keys():\n",
    "        temp_json=sad_segments[key].for_json()\n",
    "        with open(str(key)+'.json', 'w') as outfile:\n",
    "            json.dump(temp_json, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dictionary for files and filenames\n",
    "list_dict_filenames=list()\n",
    "files = dict()\n",
    "for file_name in file_names:\n",
    "    list_dict_filenames.append({'audio':str(file_name)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sad_segments=timeline(list_dict_filenames) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "write_disk(sad_segments) #save Timeline objects as json files to disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now we load the json files back to timelines to get the durations and no of intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first for meal\n",
    "import os\n",
    "import json\n",
    "import pyannote.core\n",
    "from pyannote.core import Timeline, Segment\n",
    "import statistics\n",
    "os.chdir('/Users/andrei-macpro/Documents/Data/Audio/speech_detection_timestamps/speech_detection_meal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes as input a list of file-names and outputs a list of pyannote timelines \n",
    "path = '/Users/andrei-macpro/Documents/Data/Audio/speech_detection_timestamps/speech_detection_meal'\n",
    "json_files = [pos_json for pos_json in sorted(os.listdir(path))]\n",
    "def get_timelines(json_files):\n",
    "    list_json=list()\n",
    "    list_timelines=list()\n",
    "    for filename in json_files: # loop that imports all json data into separate dictionaries\n",
    "        with open(filename) as json_file:\n",
    "            data = json.load(json_file)\n",
    "            list_json.append(data)\n",
    "    for file, segments in zip(json_files, list_json): # loop to iterate through the files and create a new timeline for each of them \n",
    "        timeline=Timeline()\n",
    "        list_timelines.append(timeline.from_json(segments))\n",
    "    return list_timelines\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_intervals(list_timelines): # standard dev of intervals of speech\n",
    "    std_interval_duration_speech_meal=list()\n",
    "    for timeline in list_timelines: # go thru each timeline\n",
    "        segment_duration=list()\n",
    "        for segment in timeline: # take the duration of each interval/segment\n",
    "            segment_duration.append(segment.duration) #append to a list ==> list of all interval durations from one TL\n",
    "        std_interval_duration_speech_meal.append(statistics.stdev(segment_duration)) # take std of that list\n",
    "    return std_interval_duration_speech_meal\n",
    "\n",
    "\n",
    "def std_intervals_silence(list_timelines):\n",
    "    std_interval_duration_silence_meal=list()\n",
    "    for timeline in list_timelines: # go thru each timeline\n",
    "        segment_duration=list()\n",
    "        for segment in timeline.gaps(): # take the duration of each interval/segment\n",
    "            segment_duration.append(segment.duration) #append to a list ==> list of all interval durations from one TL\n",
    "        std_interval_duration_silence_meal.append(statistics.stdev(segment_duration)) # take std of that list\n",
    "    return std_interval_duration_silence_meal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_timelines_meal=get_timelines(json_files) # list containing the pyannote timeline of each meal recording "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now need to extract duration of speech and duration of non-speech and number of segments/intervals for each\n",
    "duration_speech_meal = [timeline.duration()/(timeline.duration()+timeline.gaps().duration())*100 for timeline in list_timelines_meal] # this is in seconds\n",
    "intervals_speech_meal =[len(timeline) for timeline in list_timelines_meal]\n",
    "intervals_per_min_meal= [(interval/timeline.duration())*60 for interval,timeline in zip(intervals_speech_meal, list_timelines_meal)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_interval_duration__speech_meal= [timeline.duration()/len(timeline) for timeline in list_timelines_meal]\n",
    "std_interval_duration_speech_meal=std_intervals(list_timelines_meal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_interval_duration__silence_meal= [timeline.gaps().duration()/len(timeline.gaps()) for timeline in list_timelines_meal]\n",
    "std_interval_duration_silence_meal=std_intervals_silence(list_timelines_meal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'list_timelines' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-150-826569872b1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlist_timelines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'list_timelines' is not defined"
     ]
    }
   ],
   "source": [
    "list_timelines[0].gaps().duration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now for play\n",
    "os.chdir('/Users/andrei-macpro/Documents/Data/Audio/speech_detection_timestamps/speech_detection_play')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/andrei-macpro/Documents/Data/Audio/speech_detection_timestamps/speech_detection_play'\n",
    "json_files = [pos_json for pos_json in sorted(os.listdir(path))]\n",
    "list_timelines_play=get_timelines(json_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_speech_play = [timeline.duration()/(timeline.duration()+timeline.gaps().duration())*100 for timeline in list_timelines_play] # this is in seconds\n",
    "intervals_speech_play =[len(timeline) for timeline in list_timelines_play]\n",
    "intervals_per_min_play= [(interval/timeline.duration())*60 for interval,timeline in zip(intervals_speech_play, list_timelines_play)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_interval_duration__speech_play= [timeline.duration()/len(timeline) for timeline in list_timelines_play]\n",
    "std_interval_duration_speech_play=std_intervals(list_timelines_play)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_interval_duration__silence_play= [timeline.gaps().duration()/len(timeline.gaps()) for timeline in list_timelines_play]\n",
    "std_interval_duration_silence_play=std_intervals_silence(list_timelines_play)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's do number of transitions after 1,2,3 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's write them to pandas and then save it to a spreadsheet\n",
    "# first need to get an index for pandas \n",
    "index_participants=sorted([int(i[:4]) for i in os.listdir(\".\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pandas df\n",
    "df = pd.DataFrame(list(zip(duration_speech_meal, intervals_per_min_meal,avg_interval_duration__speech_meal, \n",
    "                           std_interval_duration_speech_meal,avg_interval_duration__silence_meal, std_interval_duration_silence_meal,\n",
    "                           duration_speech_play, \n",
    "                           intervals_per_min_play, \n",
    "                           avg_interval_duration__speech_play,\n",
    "                           std_interval_duration_speech_play,\n",
    "                           avg_interval_duration__silence_play,\n",
    "                           std_interval_duration_silence_play)), \n",
    "               columns =['Percent speech meal', 'intervals/min meal', 'Avg speech duration meal', \n",
    "                         'std speech duration meal', 'Avg silence duration meal',\n",
    "                         'std silence duration meal',\n",
    "                         'Percent speech play',\n",
    "                        'intervals/min play','Avg speech duration play', \n",
    "                         'std speech duration play', 'Avg silence duration play', \n",
    "                         'std silence duration play'], index=index_participants) \n",
    "df.index.name='Subject_ID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('speech_detection_features.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Percent speech meal</th>\n",
       "      <th>intervals/min meal</th>\n",
       "      <th>Avg speech duration meal</th>\n",
       "      <th>std speech duration meal</th>\n",
       "      <th>Avg silence duration meal</th>\n",
       "      <th>std silence duration meal</th>\n",
       "      <th>Percent speech play</th>\n",
       "      <th>intervals/min play</th>\n",
       "      <th>Avg speech duration play</th>\n",
       "      <th>std speech duration play</th>\n",
       "      <th>Avg silence duration play</th>\n",
       "      <th>std silence duration play</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subject_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>62.701336</td>\n",
       "      <td>17.529338</td>\n",
       "      <td>3.422833</td>\n",
       "      <td>3.947883</td>\n",
       "      <td>2.046831</td>\n",
       "      <td>2.348845</td>\n",
       "      <td>82.601449</td>\n",
       "      <td>11.204970</td>\n",
       "      <td>5.354767</td>\n",
       "      <td>5.890128</td>\n",
       "      <td>1.141813</td>\n",
       "      <td>0.947178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>77.610462</td>\n",
       "      <td>13.859264</td>\n",
       "      <td>4.329234</td>\n",
       "      <td>5.094716</td>\n",
       "      <td>1.254307</td>\n",
       "      <td>1.216747</td>\n",
       "      <td>88.128893</td>\n",
       "      <td>10.087324</td>\n",
       "      <td>5.948059</td>\n",
       "      <td>4.799366</td>\n",
       "      <td>0.815270</td>\n",
       "      <td>0.668524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>43.958353</td>\n",
       "      <td>26.899321</td>\n",
       "      <td>2.230540</td>\n",
       "      <td>4.112050</td>\n",
       "      <td>2.860906</td>\n",
       "      <td>3.518392</td>\n",
       "      <td>59.860975</td>\n",
       "      <td>26.081915</td>\n",
       "      <td>2.300445</td>\n",
       "      <td>1.990709</td>\n",
       "      <td>1.572198</td>\n",
       "      <td>2.032243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>80.624091</td>\n",
       "      <td>11.131207</td>\n",
       "      <td>5.390251</td>\n",
       "      <td>6.769518</td>\n",
       "      <td>1.304219</td>\n",
       "      <td>1.227086</td>\n",
       "      <td>81.194650</td>\n",
       "      <td>16.224784</td>\n",
       "      <td>3.698046</td>\n",
       "      <td>4.286129</td>\n",
       "      <td>0.865910</td>\n",
       "      <td>0.786110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>77.260313</td>\n",
       "      <td>12.069696</td>\n",
       "      <td>4.971127</td>\n",
       "      <td>8.375445</td>\n",
       "      <td>1.472950</td>\n",
       "      <td>1.586202</td>\n",
       "      <td>67.370598</td>\n",
       "      <td>21.286176</td>\n",
       "      <td>2.818731</td>\n",
       "      <td>3.380160</td>\n",
       "      <td>1.376956</td>\n",
       "      <td>1.251870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Percent speech meal  intervals/min meal  Avg speech duration meal  \\\n",
       "Subject_ID                                                                      \n",
       "1043                  62.701336           17.529338                  3.422833   \n",
       "1047                  77.610462           13.859264                  4.329234   \n",
       "1049                  43.958353           26.899321                  2.230540   \n",
       "1053                  80.624091           11.131207                  5.390251   \n",
       "1059                  77.260313           12.069696                  4.971127   \n",
       "\n",
       "            std speech duration meal  Avg silence duration meal  \\\n",
       "Subject_ID                                                        \n",
       "1043                        3.947883                   2.046831   \n",
       "1047                        5.094716                   1.254307   \n",
       "1049                        4.112050                   2.860906   \n",
       "1053                        6.769518                   1.304219   \n",
       "1059                        8.375445                   1.472950   \n",
       "\n",
       "            std silence duration meal  Percent speech play  \\\n",
       "Subject_ID                                                   \n",
       "1043                         2.348845            82.601449   \n",
       "1047                         1.216747            88.128893   \n",
       "1049                         3.518392            59.860975   \n",
       "1053                         1.227086            81.194650   \n",
       "1059                         1.586202            67.370598   \n",
       "\n",
       "            intervals/min play  Avg speech duration play  \\\n",
       "Subject_ID                                                 \n",
       "1043                 11.204970                  5.354767   \n",
       "1047                 10.087324                  5.948059   \n",
       "1049                 26.081915                  2.300445   \n",
       "1053                 16.224784                  3.698046   \n",
       "1059                 21.286176                  2.818731   \n",
       "\n",
       "            std speech duration play  Avg silence duration play  \\\n",
       "Subject_ID                                                        \n",
       "1043                        5.890128                   1.141813   \n",
       "1047                        4.799366                   0.815270   \n",
       "1049                        1.990709                   1.572198   \n",
       "1053                        4.286129                   0.865910   \n",
       "1059                        3.380160                   1.376956   \n",
       "\n",
       "            std silence duration play  \n",
       "Subject_ID                             \n",
       "1043                         0.947178  \n",
       "1047                         0.668524  \n",
       "1049                         2.032243  \n",
       "1053                         0.786110  \n",
       "1059                         1.251870  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
