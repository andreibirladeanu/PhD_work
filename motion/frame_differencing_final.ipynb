{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2e3f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.fft import fftshift\n",
    "import os \n",
    "#import seaborn as sns\n",
    "from itertools import zip_longest\n",
    "from tqdm import tqdm\n",
    "import matplotlib.lines as mlines\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a212ca15",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/andreibirladeanu/Documents/Data/Meal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2677cd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/andreibirladeanu/Documents/Data/Meal'\n",
    "\n",
    "videos = [file for file in sorted(os.listdir(path))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e889c1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rad = [1047, 1059, 1069, 1079, 1089, 1093, 1099, 1107, 1108, \n",
    "      1117, 1122, 1124, 1125, 1129, 1131, 1132, 1134, 1148, 1186, \n",
    "      1190, 1195, 1206, 1210, 1217, 1230, 1246, 1250, 1264, 2009, 2027]\n",
    "no_rad = [1043, 1049, 1053, 1062, 1073, 1080, 1082, 1091, 1092, \n",
    "         1096, 1097, 1098, 1104, 1105, 1112, 1118, 1130, 1146, \n",
    "         1161, 1170, 1180, 1181, 1184, 1188, 1234, 1241, 1245, 1263,\n",
    "         1269, 1282, 2025]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d87347",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_differencing(video_input, threshold_method,granularity):\n",
    "    cap = cv2.VideoCapture(video_input)\n",
    "    frames = []\n",
    "    counter = 0\n",
    "    differences = []\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret == False:\n",
    "            break\n",
    "        gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY) #converts captured frame to Grayscale for easier analysis\n",
    "        frames.append(gray)\n",
    "        if counter > granularity:\n",
    "            difference = np.abs(cv2.subtract(frames[counter], frames[counter-granularity]))\n",
    "            ret2,th = cv2.threshold(difference,0,1,threshold_method)\n",
    "            differences.append(np.sum(th))\n",
    "        counter = counter + 1\n",
    "    differences=np.array(differences)\n",
    "    differences = differences[np.where(differences < np.percentile(differences, 98))[0]]\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return differences\n",
    "\n",
    "def dataframes(videos, threshold_method, granularity, title):\n",
    "    frame_diffs = []\n",
    "    for video in tqdm(videos): \n",
    "        frame_diffs.append(frame_differencing(video,threshold_method,granularity))\n",
    "    frame_diffs = np.array(frame_diffs, dtype='object')\n",
    "    data = pd.DataFrame(zip_longest(*frame_diffs), columns = [video.split('_')[0] for video in videos])\n",
    "    data_rad = data[data.columns & [str(x) for x in rad]]\n",
    "    data_no_rad = data[data.columns & [str(x) for x in no_rad]]\n",
    "    df =  pd.concat([data_rad.T.assign(label='rad'), data_no_rad.T.assign(label='no-rad')])\n",
    "    df['label'] = df['label'].sort_index()\n",
    "    plt.rcParams['font.size']=30\n",
    "    #figure(facecolor='grey')\n",
    "    plt.rcParams['axes.facecolor'] = 'white'\n",
    "    plt.rcParams[\"figure.figsize\"] = [50,25]\n",
    "    #plt.rc('legend',fontsize=20)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    for x in data_rad:  \n",
    "        n, bins, patches= ax.hist(data_rad[x], bins='fd',  color='red', alpha=.5, stacked=True)\n",
    "    \n",
    "    for y in data_no_rad:\n",
    "        n, bins, patches= plt.hist(data_no_rad[y], bins='fd',  color='green', alpha=.5, stacked=True)\n",
    "    #plt.legend(loc=2, prop={'size': 6})\n",
    "    eight = mlines.Line2D([], [], color='red', marker='o', ls='', label='rad', markersize = 9)\n",
    "    nine = mlines.Line2D([], [], color='green', marker='o', ls='', label='no-rad', markersize = 9)\n",
    "    # etc etc\n",
    "    ax.legend(handles=[eight, nine], markerscale=7, fontsize='x-large')\n",
    "    \n",
    "    #plt.axvline(0.36, color='k', linestyle='dashed', linewidth=5)\n",
    "    #plt.text(0.25, 250, ' <5%', size='large')\n",
    "    #plt.xlim(right = 1)\n",
    "    plt.grid(True)\n",
    "    plt.xlabel(\"Frame change\")\n",
    "    plt.ylabel(\"Probability (%)\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    return data,df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ce16c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, df = dataframes(videos, cv2.THRESH_BINARY+cv2.THRESH_OTSU, 15, \"Meal Otsu 15 frames Absolute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b6e31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rad = data[data.columns & [str(x) for x in rad]]\n",
    "data_no_rad = data[data.columns & [str(x) for x in no_rad]]\n",
    "df =  pd.concat([data_rad.T.assign(label='rad'), data_no_rad.T.assign(label='no-rad')])\n",
    "df['label'] = df['label'].sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af813825",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('meal_otsu_15_abs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba0e8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean and variance\n",
    "mean, variance = df.iloc[:,:-2].mean(axis=1), df.iloc[:,:-2].var(axis=1)\n",
    "mean, variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fab90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.concat([mean, variance], axis=1)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48b8436",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe590bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_df.to_numpy()\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dfe0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "## classification with a grid search\n",
    "\n",
    "X_shuffled, y_shuffled, groups_shuffled = shuffle(X,y,big_df.index ,random_state=42)\n",
    "print(groups_shuffled)\n",
    "scalar = preprocessing.StandardScaler()\n",
    "#clf = GridSearchCV(estimator=svm.SVC(), param_grid=parameter_candidates, n_jobs=-1)\n",
    "parameter_candidates = {'model__kernel':['linear', 'rbf'], 'model__C':[1, 10,100]}\n",
    "clf = svm.SVC()\n",
    "pipeline = Pipeline(steps=[('preprocess', scalar), ('model', clf)])\n",
    "\n",
    "cv = GroupKFold(n_splits=5)\n",
    "#cross_val_score(pipeline, X, y, cv = cv)\n",
    "search = GridSearchCV(pipeline, parameter_candidates, scoring = 'accuracy', cv =cv)\n",
    "search.fit(X_shuffled, y_shuffled, groups = groups_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe79ada1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050869a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df.plot.scatter(x = 'mean', y ='variance', c = 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a749629",
   "metadata": {},
   "outputs": [],
   "source": [
    "## run the best hyperparameters 10 times \n",
    "\n",
    "i = 0\n",
    "means = []\n",
    "#stds = []\n",
    "stds = []\n",
    "for i in range(10):\n",
    "    X_shuffled, y_shuffled = shuffle(X,y, random_state=i)\n",
    "    scalar = preprocessing.StandardScaler()\n",
    "    parameter_candidates = {'model__kernel':['linear', 'rbf'], 'model__C':[1, 10,100]}\n",
    "    clf = svm.SVC()\n",
    "    pipeline = Pipeline(steps=[('preprocess', scalar), ('model', clf)])\n",
    "    cv = KFold(n_splits=5)\n",
    "    #for train_index, test_index in cv.split(X_shuffled):\n",
    "     # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    #cross_val_score(pipeline, X, y, cv = cv)\n",
    "    search = GridSearchCV(pipeline, parameter_candidates, cv =cv)\n",
    "    search.fit(X_shuffled, y_shuffled)\n",
    "    means.append(search.best_score_)\n",
    "    stds.append(search.cv_results_['std_test_score'].mean())\n",
    "\n",
    "np.mean(means), np.mean(stds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9bdf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot decision regions \n",
    "\n",
    "resolution=0.2\n",
    "X, y = shuffle(X,y, random_state=0)\n",
    "cv = KFold(n_splits=5)\n",
    "plt.rcParams[\"figure.figsize\"] = [10,7]\n",
    "for train_index, test_index in cv.split(X):\n",
    "    markers = ('s', 'x', 'o', '^', 'v')\n",
    "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train, X_test = scaler.transform(X_train), scaler.transform(X_test)\n",
    "    model = SVC(kernel = 'rbf', C=1)\n",
    "    model.fit(X_train, y_train)\n",
    "    x1_min, x1_max = X_train[:, 0].min() - 1, X_train[:, 0].max() + 1\n",
    "    x2_min, x2_max = X_train[:, 1].min() - 1, X_train[:, 1].max() + 1\n",
    "    print(x1_min, x1_max)\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution), np.arange(x2_min, x2_max, resolution))\n",
    "    print(xx1)\n",
    "    Z = model.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "    plt.show()\n",
    "\n",
    "    for idx, cl in enumerate(np.unique(y_train)):\n",
    "        plt.scatter(x=X_train[y_train == cl, 0], y=X_train[y_train == cl, 1],\n",
    "                  alpha=0.8, c=cmap(idx),\n",
    "                  marker=markers[idx], label=cl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb3dea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_candidates = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    "]\n",
    "\n",
    "# Create a classifier object with the classifier and parameter candidates\n",
    "clf = GridSearchCV(estimator=svm.SVC(), param_grid=parameter_candidates, n_jobs=-1, cv = skf)\n",
    "\n",
    "# Train the classifier on data1's feature and target data\n",
    "clf.fit(X, y)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
