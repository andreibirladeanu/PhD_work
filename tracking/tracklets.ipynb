{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from pathlib import Path\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import re\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from sorted_alpha import sorted_alpha\n",
    "from scipy.spatial import distance\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy import interpolate\n",
    "from frame_count import frame_count\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.spatial import distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_skeleton_data(csv_file_path):\n",
    "    # 1. read data\n",
    "    data = pd.read_csv(csv_file_path)\n",
    "    temp_data = data.copy()\n",
    "\n",
    "    \n",
    "    # 2. drop skeletons with missing neck\n",
    "    for i in range(0, len(data.columns[1:]), 3):\n",
    "        neck_value = data[data.columns[1:][i]].loc[1]\n",
    "        if pd.isna(neck_value) or neck_value == 0:\n",
    "            temp_data = temp_data.drop([data.columns[1:][i], data.columns[1:][i+1], data.columns[1:][i+2]], axis=1)  # Drop skeletons with missing neck\n",
    "    data = temp_data\n",
    "\n",
    "    # 3. if no skeletons with neck return None\n",
    "    if len(data.columns) < 4:  # If not enough skeletons with neck present, return None\n",
    "        return None, None\n",
    "\n",
    "    # remove fourth skeleton if detected\n",
    "    elif len(data.columns) > 10:\n",
    "        # Drop the fourth skeleton if it has been detected\n",
    "        data = data.drop(data.columns[10:], axis=1) \n",
    "\n",
    "    # 4. initialize the tracking with the first two skeletons and save the neck_points\n",
    "    detections = []\n",
    "    neck_keypoints = []\n",
    "    for col in range(0, len(data.columns[1:]), 3):\n",
    "        skeleton = data.iloc[:, col:col+3].values\n",
    "        detections.append(skeleton[:,1:])  # Select only x and y columns\n",
    "        neck_keypoints.append(skeleton[:,1:][1])  # Assuming neck keypoint is the second row (index 1)\n",
    "    \n",
    "    detections = np.array(detections)  # Shape: (num_skeletons, num_keypoints)\n",
    "    neck_keypoints = np.array(neck_keypoints)  # Shape: (num_skeletons, 2)\n",
    "\n",
    "    return detections, neck_keypoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COMBINE multiple bbox features\n",
    "import numpy as np\n",
    "\n",
    "def relative_position(tracks, detection_buffer):\n",
    "    def calculate_bounding_box(keypoints):\n",
    "        if keypoints is None or len(keypoints) == 0 or not isinstance(keypoints[0], (list, np.ndarray)):\n",
    "            print(f\"Invalid keypoints format: {keypoints}\")\n",
    "            raise ValueError(\"Invalid keypoints format\")\n",
    "        x_coordinates = []\n",
    "        y_coordinates = []\n",
    "        for point in keypoints:\n",
    "            if isinstance(point, (list, np.ndarray)) and len(point) == 2:\n",
    "                if not np.isnan(point).any():\n",
    "                    x_coordinates.append(point[0])\n",
    "                    y_coordinates.append(point[1])\n",
    "            else:\n",
    "                print(f\"Invalid point format: {point}\")\n",
    "        if len(x_coordinates) == 0 or len(y_coordinates) == 0:\n",
    "            return 0, 0, 0, 0  # Return zero width and height if all coordinates are NaN\n",
    "        x_min, x_max = np.nanmin(x_coordinates), np.nanmax(x_coordinates)\n",
    "        y_min, y_max = np.nanmin(y_coordinates), np.nanmax(y_coordinates)\n",
    "        width = x_max - x_min\n",
    "        height = y_max - y_min\n",
    "        return x_min, y_min, x_max, y_max, width, height\n",
    "\n",
    "    def calculate_iou(box1, box2):\n",
    "        x1_min, y1_min, x1_max, y1_max = box1\n",
    "        x2_min, y2_min, x2_max, y2_max = box2\n",
    "\n",
    "        xi1 = max(x1_min, x2_min)\n",
    "        yi1 = max(y1_min, y2_min)\n",
    "        xi2 = min(x1_max, x2_max)\n",
    "        yi2 = min(y1_max, y2_max)\n",
    "        inter_area = max(0, xi2 - xi1) * max(0, yi2 - yi1)\n",
    "\n",
    "        box1_area = (x1_max - x1_min) * (y1_max - y1_min)\n",
    "        box2_area = (x2_max - x2_min) * (y2_max - y2_min)\n",
    "        union_area = box1_area + box2_area - inter_area\n",
    "\n",
    "        return inter_area / union_area if union_area != 0 else 0\n",
    "\n",
    "    def calculate_center(keypoints):\n",
    "        x_coordinates = [point[0] for point in keypoints if not np.isnan(point[0])]\n",
    "        y_coordinates = [point[1] for point in keypoints if not np.isnan(point[1])]\n",
    "        if len(x_coordinates) == 0 or len(y_coordinates) == 0:\n",
    "            return 0, 0\n",
    "        center_x = np.mean(x_coordinates)\n",
    "        center_y = np.mean(y_coordinates)\n",
    "        return center_x, center_y\n",
    "\n",
    "    def calculate_diagonal(width, height):\n",
    "        return np.sqrt(width**2 + height**2)\n",
    "\n",
    "    def calculate_velocity(center1, center2):\n",
    "        return np.sqrt((center2[0] - center1[0])**2 + (center2[1] - center1[1])**2)\n",
    "\n",
    "    def calculate_mean_features(track):\n",
    "        areas = []\n",
    "        aspect_ratios = []\n",
    "        centers = []\n",
    "        diagonals = []\n",
    "        velocities = []\n",
    "        for i in range(1, len(track[-50:])):\n",
    "            detection, _ = track[-50:][i]\n",
    "            prev_detection, _ = track[-50:][i-1]\n",
    "            _, _, _, _, width, height = calculate_bounding_box(detection)\n",
    "            prev_center = calculate_center(prev_detection)\n",
    "            center = calculate_center(detection)\n",
    "            areas.append(width * height)\n",
    "            aspect_ratios.append(width / height if height != 0 else 0)\n",
    "            centers.append(center)\n",
    "            diagonals.append(calculate_diagonal(width, height))\n",
    "            velocities.append(calculate_velocity(prev_center, center))\n",
    "        return np.mean(areas), np.mean(aspect_ratios), np.mean(centers, axis=0), np.mean(diagonals), np.mean(velocities)\n",
    "\n",
    "    def calculate_score(detection, mean_area, mean_aspect_ratio, mean_center, mean_diagonal, mean_velocity, last_detection):\n",
    "        x_min, y_min, x_max, y_max, width, height = calculate_bounding_box(detection)\n",
    "        area = width * height\n",
    "        aspect_ratio = width / height if height != 0 else 0\n",
    "        center = calculate_center(detection)\n",
    "        diagonal = calculate_diagonal(width, height)\n",
    "        velocity = calculate_velocity(calculate_center(last_detection), center)\n",
    "        iou = calculate_iou((x_min, y_min, x_max, y_max), calculate_bounding_box(last_detection)[:4])\n",
    "        return (weights['area'] * abs(area - mean_area) +\n",
    "                weights['aspect_ratio'] * abs(aspect_ratio - mean_aspect_ratio) +\n",
    "                weights['center'] * np.linalg.norm(np.array(center) - np.array(mean_center)) +\n",
    "                weights['diagonal'] * abs(diagonal - mean_diagonal) +\n",
    "                weights['velocity'] * abs(velocity - mean_velocity) -\n",
    "                weights['iou'] * iou)\n",
    "\n",
    "    # Flatten the buffered detections\n",
    "    all_detections = [det for sublist in detection_buffer for det in sublist[0]]\n",
    "    all_frame_numbers = [frame_number for sublist in detection_buffer for frame_number in [sublist[1]] * len(sublist[0])]\n",
    "\n",
    "    track1, track2 = tracks[:2]\n",
    "    mean_features_track1 = calculate_mean_features(track1)\n",
    "    mean_features_track2 = calculate_mean_features(track2)\n",
    "    # Define weights for each feature\n",
    "    weights = {\n",
    "        'area': 0.3,\n",
    "        'aspect_ratio': 0.5,\n",
    "        'center': 1.0,\n",
    "        'diagonal': 1.0,\n",
    "        'velocity': 1.0,\n",
    "        'iou': 1.0\n",
    "    }\n",
    "    scores = []\n",
    "    for detection in all_detections:\n",
    "        last_detection_track1 = track1[-1][0]\n",
    "        last_detection_track2 = track2[-1][0]\n",
    "        score_track1 = calculate_score(detection, *mean_features_track1, last_detection_track1)\n",
    "        score_track2 = calculate_score(detection, *mean_features_track2, last_detection_track2)\n",
    "        scores.append((score_track1, score_track2))\n",
    "\n",
    "    # Determine the best track for each detection\n",
    "    track_assignments = []\n",
    "    for score_track1, score_track2 in scores:\n",
    "        if score_track1 < score_track2:\n",
    "            track_assignments.append(1)\n",
    "        else:\n",
    "            track_assignments.append(2)\n",
    "\n",
    "    return track_assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### with smoothing \n",
    "import numpy as np\n",
    "\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "def savitzky_golay(data, window_size=5, polyorder=2):\n",
    "    \"\"\"Apply Savitzky-Golay smoothing to the data.\"\"\"\n",
    "    if len(data) < window_size:\n",
    "        return data  # Return the original data if it's too short to smooth\n",
    "    smoothed_data = savgol_filter(data, window_size, polyorder)\n",
    "    return smoothed_data\n",
    "\n",
    "def relative_position(tracks, detection_buffer):\n",
    "    def calculate_bounding_box(keypoints):\n",
    "        if keypoints is None or len(keypoints) == 0 or not isinstance(keypoints[0], (list, np.ndarray)):\n",
    "            print(f\"Invalid keypoints format: {keypoints}\")\n",
    "            raise ValueError(\"Invalid keypoints format\")\n",
    "        x_coordinates = []\n",
    "        y_coordinates = []\n",
    "        for point in keypoints:\n",
    "            if isinstance(point, (list, np.ndarray)) and len(point) == 2:\n",
    "                if not np.isnan(point).any():\n",
    "                    x_coordinates.append(point[0])\n",
    "                    y_coordinates.append(point[1])\n",
    "            else:\n",
    "                print(f\"Invalid point format: {point}\")\n",
    "        if len(x_coordinates) == 0 or len(y_coordinates) == 0:\n",
    "            return 0, 0, 0, 0  # Return zero width and height if all coordinates are NaN\n",
    "        x_min, x_max = np.nanmin(x_coordinates), np.nanmax(x_coordinates)\n",
    "        y_min, y_max = np.nanmin(y_coordinates), np.nanmax(y_coordinates)\n",
    "        width = x_max - x_min\n",
    "        height = y_max - y_min\n",
    "        return x_min, y_min, x_max, y_max, width, height\n",
    "\n",
    "    def calculate_iou(box1, box2):\n",
    "        x1_min, y1_min, x1_max, y1_max = box1\n",
    "        x2_min, y2_min, x2_max, y2_max = box2\n",
    "\n",
    "        xi1 = max(x1_min, x2_min)\n",
    "        yi1 = max(y1_min, y2_min)\n",
    "        xi2 = min(x1_max, x2_max)\n",
    "        yi2 = min(y1_max, y2_max)\n",
    "        inter_area = max(0, xi2 - xi1) * max(0, yi2 - yi1)\n",
    "\n",
    "        box1_area = (x1_max - x1_min) * (y1_max - y1_min)\n",
    "        box2_area = (x2_max - x2_min) * (y2_max - y2_min)\n",
    "        union_area = box1_area + box2_area - inter_area\n",
    "\n",
    "        return inter_area / union_area if union_area != 0 else 0\n",
    "\n",
    "    def calculate_center(keypoints):\n",
    "        x_coordinates = [point[0] for point in keypoints if not np.isnan(point[0])]\n",
    "        y_coordinates = [point[1] for point in keypoints if not np.isnan(point[1])]\n",
    "        if len(x_coordinates) == 0 or len(y_coordinates) == 0:\n",
    "            return 0, 0\n",
    "        center_x = np.mean(x_coordinates)\n",
    "        center_y = np.mean(y_coordinates)\n",
    "        return center_x, center_y\n",
    "\n",
    "    def calculate_diagonal(width, height):\n",
    "        return np.sqrt(width**2 + height**2)\n",
    "\n",
    "    def calculate_velocity(center1, center2):\n",
    "        return np.sqrt((center2[0] - center1[0])**2 + (center2[1] - center1[1])**2)\n",
    "\n",
    "    def calculate_mean_features(track):\n",
    "        areas = []\n",
    "        aspect_ratios = []\n",
    "        centers = []\n",
    "        diagonals = []\n",
    "        velocities = []\n",
    "        num_detections = len(track)\n",
    "        for i in range(1, num_detections):\n",
    "            detection, _ = track[i]\n",
    "            prev_detection, _ = track[i-1]\n",
    "            _, _, _, _, width, height = calculate_bounding_box(detection)\n",
    "            prev_center = calculate_center(prev_detection)\n",
    "            center = calculate_center(detection)\n",
    "            areas.append(width * height)\n",
    "            aspect_ratios.append(width / height if height != 0 else 0)\n",
    "            centers.append(center)\n",
    "            diagonals.append(calculate_diagonal(width, height))\n",
    "            velocities.append(calculate_velocity(prev_center, center))\n",
    "        return np.mean(areas), np.mean(aspect_ratios), np.mean(centers, axis=0), np.mean(diagonals), np.mean(velocities)\n",
    "\n",
    "    def calculate_score(detection, mean_area, mean_aspect_ratio, mean_center, mean_diagonal, mean_velocity, last_detection, weights):\n",
    "        x_min, y_min, x_max, y_max, width, height = calculate_bounding_box(detection)\n",
    "        area = width * height\n",
    "        aspect_ratio = width / height if height != 0 else 0\n",
    "        center = calculate_center(detection)\n",
    "        diagonal = calculate_diagonal(width, height)\n",
    "        velocity = calculate_velocity(calculate_center(last_detection), center)\n",
    "        iou = calculate_iou((x_min, y_min, x_max, y_max), calculate_bounding_box(last_detection)[:4])\n",
    "        return (weights['area'] * abs(area - mean_area) +\n",
    "                weights['aspect_ratio'] * abs(aspect_ratio - mean_aspect_ratio) +\n",
    "                weights['center'] * np.linalg.norm(np.array(center) - np.array(mean_center)) +\n",
    "                weights['diagonal'] * abs(diagonal - mean_diagonal) +\n",
    "                weights['velocity'] * abs(velocity - mean_velocity) -\n",
    "                weights['iou'] * iou)\n",
    "\n",
    "    # Flatten the buffered detections\n",
    "    all_detections = [det for sublist in detection_buffer for det in sublist[0]]\n",
    "    all_frame_numbers = [frame_number for sublist in detection_buffer for frame_number in [sublist[1]] * len(sublist[0])]\n",
    "\n",
    "    # Smooth the detections in the buffer\n",
    "    smoothed_detections = []\n",
    "    for detection in all_detections:\n",
    "        smoothed_detection = []\n",
    "        for keypoint in detection:\n",
    "            smoothed_detection.append(savitzky_golay(np.array(keypoint)))\n",
    "        smoothed_detections.append(smoothed_detection)\n",
    "\n",
    "    # Smooth the detections in the last 50 frames of each track\n",
    "    for track in tracks:\n",
    "        smoothed_track_detections = []\n",
    "        for detection, frame_number in track[-50:]:\n",
    "            smoothed_detection = []\n",
    "            for keypoint in detection:\n",
    "                smoothed_detection.append(savitzky_golay(np.array(keypoint)))\n",
    "            smoothed_track_detections.append((smoothed_detection, frame_number))\n",
    "        track[-50:] = smoothed_track_detections\n",
    "\n",
    "    track1, track2 = tracks[:2]\n",
    "    mean_features_track1 = calculate_mean_features(track1)\n",
    "    mean_features_track2 = calculate_mean_features(track2)\n",
    "\n",
    "    # Define weights for each feature\n",
    "    weights = {\n",
    "        'area': 1.0,\n",
    "        'aspect_ratio': 1.0,\n",
    "        'center': 1.0,\n",
    "        'diagonal': 1.0,\n",
    "        'velocity': 1.0,\n",
    "        'iou': 1.0\n",
    "    }\n",
    "\n",
    "    scores = []\n",
    "    for detection in smoothed_detections:\n",
    "        last_detection_track1 = track1[-1][0]\n",
    "        last_detection_track2 = track2[-1][0]\n",
    "        score_track1 = calculate_score(detection, *mean_features_track1, last_detection_track1, weights)\n",
    "        score_track2 = calculate_score(detection, *mean_features_track2, last_detection_track2, weights)\n",
    "        scores.append((score_track1, score_track2))\n",
    "\n",
    "    # Determine the best track for each detection\n",
    "    track_assignments = []\n",
    "    for score_track1, score_track2 in scores:\n",
    "        if score_track1 < score_track2:\n",
    "            track_assignments.append(1)\n",
    "        else:\n",
    "            track_assignments.append(2)\n",
    "\n",
    "    return track_assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "\n",
    "from scipy.spatial.distance import euclidean\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# Initialize tracking variables\n",
    "tracks = []\n",
    "frames = []\n",
    "knn = NearestNeighbors(n_neighbors=1, metric='euclidean')\n",
    "threshold = 80\n",
    "# Example usage\n",
    "path = '/Users/andrei-macpro/Documents/Data/pose/play_openpose/1264_play'\n",
    "detects = sorted_alpha(path)\n",
    "numbers = [int(f.split('_')[-1].split('.')[0]) for f in detects]\n",
    "buffer_size = 5  # Number of frames to buffer\n",
    "detection_buffer = []\n",
    "\n",
    "for i, number in zip(range(len(detects)), numbers):\n",
    "    frames.append(number)\n",
    "    print('frame no:', number)\n",
    "    \n",
    "    data = pd.read_csv(os.path.join(path, detects[i]))\n",
    "    \n",
    "    if i == 0:  # For the first frame, just get the skeletons, don't do anything\n",
    "        detections, necks = process_skeleton_data(os.path.join(path, detects[i]))\n",
    "        # Initialize track lists for each detection\n",
    "        for _ in range(len(detections)):\n",
    "            tracks.append([])\n",
    "\n",
    "        # Append each detection to its corresponding track list with the frame number\n",
    "        for j, detection in enumerate(detections):\n",
    "            tracks[j].append((detection, number))\n",
    "\n",
    "    else:\n",
    "        detections, necks = process_skeleton_data(os.path.join(path, detects[i]))\n",
    "\n",
    "        # Check if there are valid neck joints\n",
    "        if necks is None or len(necks) == 0 or all(neck is None for neck in necks):\n",
    "            continue\n",
    "        \n",
    "        # Add detections to the buffer\n",
    "        detection_buffer.append((detections, number))\n",
    "        if i<50:\n",
    "            last_necks = np.array([track[-1][0][1] for track in tracks])\n",
    "\n",
    "            # Fit the KNN model on the last neck positions\n",
    "            knn.fit(last_necks)\n",
    "            # Keep track of which detections have been assigned\n",
    "            assigned_detections = set()\n",
    "            # Store distances and indices\n",
    "            distances_indices = []\n",
    "            # Compute Euclidean distances between each pair of new detections \n",
    "            necks_array = np.array(necks)\n",
    "            num_detections = len(necks_array)\n",
    "            # Handle the case where there is only one detection\n",
    "            if num_detections == 1:\n",
    "                if len(tracks) == 1:\n",
    "                    tracks[0].append((detections[0], number))\n",
    "\n",
    "                else:\n",
    "                    # Assign the single detection to the closest track\n",
    "                    dist, index = knn.kneighbors([necks[0]])\n",
    "                    tracks[index[0][0]].append((detections[0], number))\n",
    "                            # Find the closest track for each new detection\n",
    "            elif len(tracks) == 1:\n",
    "                for j, neck in enumerate(necks):\n",
    "                    dist, index = knn.kneighbors([neck])\n",
    "                    distances_indices.append((dist[0][0], index[0][0], j))\n",
    "                    # Sort detections by distance to the closest track\n",
    "                distances_indices.sort()\n",
    "                # Assign the closest detections to the tracks\n",
    "                for dist, closest_track_index, j in distances_indices[:len(tracks)]:\n",
    "                    tracks[closest_track_index].append((detections[j], number))\n",
    "                    assigned_detections.add(j)\n",
    "\n",
    "            elif len(detections) == 3 and len(tracks) == 2:\n",
    "                for j, neck in enumerate(necks):\n",
    "                    dist, index = knn.kneighbors([neck])\n",
    "                    distances_indices.append((dist[0][0], index[0][0], j))\n",
    "                    # Sort detections by distance to the closest track\n",
    "                distances_indices.sort()\n",
    "                # Assign the closest detections to the tracks\n",
    "                for dist, closest_track_index, j in distances_indices[:len(tracks)]:\n",
    "                    tracks[closest_track_index].append((detections[j], number))\n",
    "                    assigned_detections.add(j)\n",
    "\n",
    "            else:    # Find the closest track for each new detection\n",
    "                for j, neck in enumerate(necks):\n",
    "                    dist, index = knn.kneighbors([neck])\n",
    "                    distances_indices.append((dist[0][0], index[0][0], j))\n",
    "                distances_indices.sort()\n",
    "                # Assign the closest detections to the tracks\n",
    "                for dist, closest_track_index, j in distances_indices[:len(tracks)]:\n",
    "                    tracks[closest_track_index].append((detections[j], number))\n",
    "                    assigned_detections.add(j)\n",
    "\n",
    "\n",
    "        else:\n",
    "            # Process buffer if it reaches the buffer size\n",
    "            if len(detection_buffer) >= buffer_size:\n",
    "\n",
    "                # Flatten the buffered detections\n",
    "                all_detections = [det for sublist in detection_buffer for det in sublist[0]]\n",
    "                all_frame_numbers = [frame_number for sublist in detection_buffer for frame_number in [sublist[1]] * len(sublist[0])]\n",
    "\n",
    "                # Assign detections to tracks using buffered data\n",
    "                track_assignments = relative_position(tracks, detection_buffer)\n",
    "\n",
    "                # Update tracks with buffered detections\n",
    "                for j, (detection, frame_number) in enumerate(zip(all_detections, all_frame_numbers)):\n",
    "                    if track_assignments[j] == 1:\n",
    "                        tracks[0].append((detection, frame_number))\n",
    "                    else:\n",
    "                        tracks[1].append((detection, frame_number))\n",
    "                \n",
    "                # Clear the buffer\n",
    "                detection_buffer = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "## let's see how the interpolated tracks look like in a dataframe \n",
    "\n",
    "# Example structure of a detection (assuming each detection is a list of keypoints, each keypoint is a list [x, y])\n",
    "# detections = [[[x1, y1], [x2, y2], ...], [[x1, y1], [x2, y2], ...], ...]\n",
    "\n",
    "# Flatten the tracks list and extract the detection, frame number, and track index\n",
    "flattened_tracks = [(detection, frame, track_index) for track_index, track in enumerate(tracks) for detection, frame in track]\n",
    "\n",
    "# Initialize a list to store the data for the DataFrame\n",
    "data = []\n",
    "\n",
    "# Iterate over the flattened tracks to extract keypoints\n",
    "for detection, frame, track_index in flattened_tracks:\n",
    "    for keypoint_index, (x, y) in enumerate(detection):\n",
    "        data.append({'Frame': frame, 'Track': track_index, 'Keypoint': keypoint_index, 'X': x, 'Y': y})\n",
    "\n",
    "# Create a DataFrame from the data\n",
    "df_tracks = pd.DataFrame(data)\n",
    "\n",
    "# Pivot the DataFrame to have 'Track' as columns and keypoints as rows\n",
    "df_pivot = df_tracks.pivot_table(index=['Frame', 'Keypoint'], columns='Track', values=['X', 'Y'])\n",
    "\n",
    "# Flatten the multi-level columns\n",
    "df_pivot.columns = [f'{coord}_Track{track}' for coord, track in df_pivot.columns]\n",
    "\n",
    "# Reset the index to make 'Frame' and 'Keypoint' columns\n",
    "df_pivot.reset_index(inplace=True)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = '/Users/andrei-macpro/Documents/Data/videos/play_videos/1264_play.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (255, 0, 255), (0, 255, 255)]\n",
    "# Get the width and height of the frames\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "output_path = '/Users/andrei-macpro/Documents/Data/videos/1264_play_annotated_multiple_.mp4'\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "# Flag to toggle frame number display\n",
    "show_frame_number = True\n",
    "\n",
    "# Iterate over the video frames\n",
    "frame_count = 1\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Get the rows for the current frame\n",
    "    frame_data = df_pivot[df_pivot['Frame'] == frame_count]\n",
    "\n",
    "    # Iterate over each track\n",
    "    for track in range(len(tracks)):\n",
    "        # Get the keypoints for the current track\n",
    "        keypoints = frame_data[[f'X_Track{track}', f'Y_Track{track}']].values\n",
    "\n",
    "        # Choose a color for the current track\n",
    "        color = colors[track % len(colors)]\n",
    "\n",
    "        # Draw bounding boxes around the keypoints and display track number\n",
    "        for x, y in keypoints:\n",
    "            if not pd.isna(x) and not pd.isna(y):\n",
    "                cv2.rectangle(frame, (int(x) - 5, int(y) - 5), (int(x) + 5, int(y) + 5), color, 2)\n",
    "                cv2.putText(frame, f'Track {track}', (int(x) + 10, int(y) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1, cv2.LINE_AA)\n",
    "\n",
    "    # Display the frame number if the flag is set\n",
    "    if show_frame_number:\n",
    "        cv2.putText(frame, f'Frame {frame_count}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "\n",
    "    # Write the frame to the output video\n",
    "    out.write(frame)\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "# Release the video capture object and close all OpenCV windows\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-python opencv-python-headless numpy torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install deep_sort_realtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "\n",
    "# Load YOLO model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
    "\n",
    "# Initialize DeepSORT\n",
    "deepsort = DeepSort(max_age=30, n_init=3, nms_max_overlap=1.0, max_cosine_distance=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install pytorch torchvision torchaudio -c pytorch-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import cv2\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "\n",
    "# Measure the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Set device to CPU or MPS (Metal Performance Shaders) for Mac M1\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Measure the time taken to set the device\n",
    "device_time = time.time()\n",
    "print(f\"Time to set device: {device_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Load YOLO model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5n', device=device)\n",
    "\n",
    "# Measure the time taken to load the model\n",
    "model_time = time.time()\n",
    "print(f\"Time to load YOLO model: {model_time - device_time:.2f} seconds\")\n",
    "\n",
    "# Initialize DeepSORT\n",
    "deepsort = DeepSort(max_age=30, n_init=3, nms_max_overlap=1.0, max_cosine_distance=0.2)\n",
    "\n",
    "# Measure the time taken to initialize DeepSORT\n",
    "deepsort_time = time.time()\n",
    "print(f\"Time to initialize DeepSORT: {deepsort_time - model_time:.2f} seconds\")\n",
    "\n",
    "# Total time\n",
    "total_time = time.time()\n",
    "print(f\"Total initialization time: {total_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "\n",
    "# Measure the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Set device to CPU or MPS (Metal Performance Shaders) for Mac M1\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Path to the YOLOv5 repository and weights\n",
    "repo_path = os.path.expanduser('/Users/andrei-macpro/Downloads/yolov5')\n",
    "weights_path = os.path.expanduser('/Users/andrei-macpro/Downloads/yolov5n.pt')\n",
    "\n",
    "# Load YOLO model with local weights\n",
    "model = torch.hub.load(repo_path, 'custom', path=weights_path, source='local', device=device)\n",
    "\n",
    "# Measure the time taken to load the model\n",
    "model_time = time.time()\n",
    "print(f\"Time to load YOLO model: {model_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Initialize DeepSORT\n",
    "deepsort = DeepSort(max_age=30, n_init=3, nms_max_overlap=1.0, max_cosine_distance=0.2)\n",
    "\n",
    "# Measure the time taken to initialize DeepSORT\n",
    "deepsort_time = time.time()\n",
    "print(f\"Time to initialize DeepSORT: {deepsort_time - model_time:.2f} seconds\")\n",
    "\n",
    "# Total time\n",
    "total_time = time.time()\n",
    "print(f\"Total initialization time: {total_time - start_time:.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepsort",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
