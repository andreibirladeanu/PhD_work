{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sorted_alpha import sorted_alpha\n",
    "import os\n",
    "from filterpy.kalman import KalmanFilter\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import cv2\n",
    "def get_skeletons(frame_no, detection):\n",
    "    skeletons = []\n",
    "    data = pd.read_csv(detection, index_col=0)\n",
    "    \n",
    "    prob_columns = [col for col in data.columns if col.startswith('prob')]\n",
    "    scores = [data[col].mean() for col in prob_columns]\n",
    "    \n",
    "    new_data = data[[col for col in data.columns if not col.startswith('prob')]]\n",
    "\n",
    "    for x, y in zip(new_data.columns[::2], new_data.columns[1::2]):\n",
    "        skeletons.append(new_data[[x, y]].to_numpy())\n",
    "    \n",
    "    valid_skeletons = []\n",
    "    for skeleton in skeletons:\n",
    "        if not (np.nanmin(skeleton[:, 0]) == np.nanmax(skeleton[:, 0]) or\n",
    "                np.nanmin(skeleton[:, 1]) == np.nanmax(skeleton[:, 1])):\n",
    "            valid_skeletons.append(skeleton)\n",
    "    \n",
    "    detections = []\n",
    "    for skeleton, score in zip(valid_skeletons, scores):\n",
    "        x1, y1 = np.nanmin(skeleton, axis=0)\n",
    "        x2, y2 = np.nanmax(skeleton, axis=0)\n",
    "        detections.append({'bbox': [x1, y1, x2, y2], 'score': score})\n",
    "\n",
    "    return detections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bb(detection):\n",
    "    \"\"\"takes a detection and returns its bounding box in format [min(x):min(y), max(x):max(y)]\"\"\"\n",
    "    min_x = np.min(detection[:,0][np.isfinite(detection[:,0])])\n",
    "    min_y = np.min(detection[:,1][np.isfinite(detection[:,0])])\n",
    "    max_x = np.max(detection[:,0][np.isfinite(detection[:,0])])\n",
    "    max_y = np.max(detection[:,1][np.isfinite(detection[:,0])])\n",
    "    return(np.array([min_x, min_y, max_x, max_y]).astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min_round(coord):\n",
    "    coord = np.array(coord)\n",
    "    x = round(np.min(coord[np.isfinite(coord)]))\n",
    "    return(x)\n",
    "\n",
    "def find_max_round(coord):\n",
    "    coord = np.array(coord)\n",
    "    x = round(np.max(coord[np.isfinite(coord)]))\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def get_skeletons(frame_no, detection):\n",
    "    \"\"\"function that reads a detections frame, checks if necks are present, and returns the skeletons\"\"\"\n",
    "    # returns skeletons as numpy arrays of shape (18,2)\n",
    "    # each x-y pair is a np array\n",
    "    # so each skeleton is an array of arrays \n",
    "    skeletons = []\n",
    "    data = pd.read_csv(detection, index_col=0)\n",
    "    \n",
    "    # Remove columns that start with 'prob' and compute the average score for each\n",
    "    prob_columns = [col for col in data.columns if col.startswith('prob')]\n",
    "    scores = [data[col].mean() for col in prob_columns]\n",
    "    \n",
    "    # Remove 'prob' columns from the data\n",
    "    new_data = data[[col for col in data.columns if not col.startswith('prob')]]\n",
    "\n",
    "    for x, y in zip(new_data.columns[::2], new_data.columns[1::2]):\n",
    "        skeletons.append(new_data[[x, y]].to_numpy())\n",
    "    \n",
    "    # Ensure that there are at least 4 different points for the bounding box\n",
    "    valid_skeletons = []\n",
    "    for skeleton in skeletons:\n",
    "        if not (np.nanmin(skeleton[:, 0]) == np.nanmax(skeleton[:, 0]) or\n",
    "                np.nanmin(skeleton[:, 1]) == np.nanmax(skeleton[:, 1])):\n",
    "            valid_skeletons.append(skeleton)\n",
    "    \n",
    "    # Create detections list\n",
    "    detections = []\n",
    "    for skeleton, score in zip(valid_skeletons, scores):\n",
    "        x1, y1 = np.nanmin(skeleton, axis=0)\n",
    "        x2, y2 = np.nanmax(skeleton, axis=0)\n",
    "        detections.append({'bbox': [x1, y1, x2, y2], 'score': score})\n",
    "\n",
    "    return detections  # this is a list of detections with bounding boxes and scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '/Users/andrei-macpro/Documents/Data/pose/meal_openpose/1043_meal'\n",
    "detections = sorted_alpha(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for detection in detections:\n",
    "    frame_no = int(detection.split('_')[-1].split('.')[0])\n",
    "    processed_det = get_skeletons(frame_no, os.path.join(folder, detection))\n",
    "    print(processed_det )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OCSORTKalmanBoxTracker:\n",
    "    def __init__(self, bbox):\n",
    "        \"\"\"\n",
    "        Initialize the Kalman filter for a bounding box.\n",
    "        bbox: [x1, y1, x2, y2] initial bounding box\n",
    "        \"\"\"\n",
    "        # Define the Kalman filter\n",
    "        self.kf = KalmanFilter(dim_x=7, dim_z=4)  # 7 states (x, y, dx, dy, h, dh, score), 4 measurements (x, y, h, score)\n",
    "        \n",
    "        # State transition matrix\n",
    "        self.kf.F = np.eye(7)\n",
    "        self.kf.F[0, 2] = 1  # Velocity model for x\n",
    "        self.kf.F[1, 3] = 1  # Velocity model for y\n",
    "        \n",
    "        # Measurement matrix (directly centered around observation)\n",
    "        self.kf.H = np.array([[1, 0, 0, 0, 0, 0, 0],\n",
    "                              [0, 1, 0, 0, 0, 0, 0],\n",
    "                              [0, 0, 0, 0, 1, 0, 0],\n",
    "                              [0, 0, 0, 0, 0, 0, 1]])\n",
    "\n",
    "        # Covariance matrix\n",
    "        self.kf.P *= 10  # Initial uncertainty\n",
    "        self.kf.R[2:, 2:] *= 10  # Measurement noise\n",
    "        self.kf.Q[-1, -1] *= 0.1  # Process noise\n",
    "        \n",
    "        self.time_since_update = 0\n",
    "        self.history = []\n",
    "        self.age = 0\n",
    "        self.id = None\n",
    "        \n",
    "        # Initialize state vector from bbox\n",
    "        self.update(bbox)\n",
    "    \n",
    "    def predict(self):\n",
    "        \"\"\"\n",
    "        Predict the next state.\n",
    "        \"\"\"\n",
    "        self.kf.predict()\n",
    "        self.time_since_update += 1\n",
    "        self.age += 1\n",
    "    \n",
    "    def update(self, bbox):\n",
    "        \"\"\"\n",
    "        Update the state with observed bounding box.\n",
    "        bbox: [x1, y1, x2, y2]\n",
    "        \"\"\"\n",
    "        self.kf.update(np.array([bbox[0], bbox[1], bbox[2], bbox[3]]))\n",
    "        self.time_since_update = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OCSORTKalmanBoxTrackerWithAccel(OCSORTKalmanBoxTracker):\n",
    "    def __init__(self, bbox):\n",
    "        super().__init__(bbox)\n",
    "        # Add acceleration to the state transition model\n",
    "        self.kf.F = np.eye(9)\n",
    "        self.kf.F[0, 2] = 1  # Velocity for x\n",
    "        self.kf.F[1, 3] = 1  # Velocity for y\n",
    "        self.kf.F[2, 4] = 1  # Acceleration for x\n",
    "        self.kf.F[3, 5] = 1  # Acceleration for y\n",
    "        \n",
    "        # Modify measurement matrix H to account for acceleration\n",
    "        self.kf.H = np.array([[1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                              [0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "                              [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "                              [0, 0, 0, 0, 0, 0, 1, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(bbox1, bbox2):\n",
    "    \"\"\"\n",
    "    Compute IoU between two bounding boxes.\n",
    "    bbox: [x1, y1, x2, y2]\n",
    "    \"\"\"\n",
    "    x1, y1, x2, y2 = max(bbox1[0], bbox2[0]), max(bbox1[1], bbox2[1]), min(bbox1[2], bbox2[2]), min(bbox1[3], bbox2[3])\n",
    "    intersection = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "    area1 = (bbox1[2] - bbox1[0]) * (bbox1[3] - bbox1[1])\n",
    "    area2 = (bbox2[2] - bbox2[0]) * (bbox2[3] - bbox2[1])\n",
    "    union = area1 + area2 - intersection\n",
    "    return intersection / union if union > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_metric(tracker_bbox, detection_bbox, observation_point1, observation_point2, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Adaptive distance metric combining IoU and observation-based Euclidean distance.\n",
    "    tracker_bbox: [x1, y1, x2, y2] from tracker\n",
    "    detection_bbox: [x1, y1, x2, y2] from detection\n",
    "    observation_point1: [x, y] central observation of the tracker\n",
    "    observation_point2: [x, y] central observation of the detection\n",
    "    alpha: weighting factor between IoU and Euclidean distance\n",
    "    \"\"\"\n",
    "    iou_score = iou(tracker_bbox, detection_bbox)\n",
    "    euclidean_distance = np.linalg.norm(np.array(observation_point1) - np.array(observation_point2))\n",
    "    \n",
    "    return alpha * iou_score + (1 - alpha) * (1 / (1 + euclidean_distance))  # Normalize distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OCSORTTracker:\n",
    "    def __init__(self):\n",
    "        self.trackers = []\n",
    "    \n",
    "    def update(self, detections):\n",
    "        # Predict new positions of the existing trackers\n",
    "        for tracker in self.trackers:\n",
    "            tracker.predict()\n",
    "\n",
    "        # Associate detections to trackers using observation-based adaptive metric\n",
    "        matches, unmatched_detections = self.associate_detections(detections)\n",
    "        \n",
    "        # Update matched trackers\n",
    "        for match in matches:\n",
    "            tracker_idx, detection_idx = match\n",
    "            self.trackers[tracker_idx].update(detections[detection_idx])\n",
    "        \n",
    "        # Create new trackers for unmatched detections\n",
    "        for idx in unmatched_detections:\n",
    "            self.trackers.append(OCSORTKalmanBoxTracker(detections[idx]['bbox']))\n",
    "    \n",
    "    def associate_detections(self, detections):\n",
    "        # Implementation of association strategy with IoU and observation metric\n",
    "        iou_matrix = np.zeros((len(self.trackers), len(detections)))\n",
    "        observation_matrix = np.zeros((len(self.trackers), len(detections)))\n",
    "        \n",
    "        for t, tracker in enumerate(self.trackers):\n",
    "            for d, detection in enumerate(detections):\n",
    "                iou_matrix[t, d] = iou(tracker.kf.x[:4], detection['bbox'])\n",
    "                observation_matrix[t, d] = adaptive_metric(tracker.kf.x[:4], detection['bbox'], tracker.kf.x[:2])\n",
    "        \n",
    "        # Combine IoU and observation metrics\n",
    "        combined_matrix = iou_matrix + observation_matrix\n",
    "        \n",
    "        # Solve the assignment problem using the Hungarian algorithm\n",
    "        row_indices, col_indices = linear_sum_assignment(-combined_matrix)\n",
    "        \n",
    "        matches = []\n",
    "        unmatched_detections = list(range(len(detections)))\n",
    "        \n",
    "        for row, col in zip(row_indices, col_indices):\n",
    "            if combined_matrix[row, col] > 0:  # Ensure a valid match\n",
    "                matches.append((row, col))\n",
    "                unmatched_detections.remove(col)\n",
    "        \n",
    "        return matches, unmatched_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from filterpy.kalman import KalmanFilter\n",
    "\n",
    "class OCSORTKalmanBoxTracker:\n",
    "    def __init__(self, bbox):\n",
    "        \"\"\"\n",
    "        Initialize the tracker with the initial bounding box.\n",
    "        bbox: [x1, y1, x2, y2] initial bounding box\n",
    "        \"\"\"\n",
    "        # Define the Kalman filter\n",
    "        self.kf = KalmanFilter(dim_x=7, dim_z=4)  # 7 states (cx, cy, vx, vy, w, h, score), 4 measurements (cx, cy, w, h)\n",
    "        \n",
    "        # State transition matrix\n",
    "        self.kf.F = np.eye(7)\n",
    "        self.kf.F[0, 2] = 1  # Velocity model for x\n",
    "        self.kf.F[1, 3] = 1  # Velocity model for y\n",
    "        self.kf.F[4, 5] = 1  # Velocity model for width and height\n",
    "        \n",
    "        # Measurement matrix (directly centered around observation)\n",
    "        self.kf.H = np.array([[1, 0, 0, 0, 0, 0, 0],\n",
    "                              [0, 1, 0, 0, 0, 0, 0],\n",
    "                              [0, 0, 0, 0, 1, 0, 0],\n",
    "                              [0, 0, 0, 0, 0, 1, 0]])\n",
    "\n",
    "        # Covariance matrix\n",
    "        self.kf.P *= 10  # Initial uncertainty\n",
    "        self.kf.R[2:, 2:] *= 10  # Measurement noise\n",
    "        self.kf.Q[-1, -1] *= 0.1  # Process noise\n",
    "        self.kf.Q[4:, 4:] *= 0.1  # Process noise for width and height\n",
    "\n",
    "        self.time_since_update = 0\n",
    "        self.history = []\n",
    "        self.age = 0\n",
    "        self.id = None\n",
    "        self.lost_frames = 0  # Initialize lost_frames attribute\n",
    "        \n",
    "        # Initialize state vector from bbox\n",
    "        self.init_state(bbox)\n",
    "    \n",
    "    def init_state(self, bbox):\n",
    "        \"\"\"\n",
    "        Initialize the state vector with the bounding box.\n",
    "        \"\"\"\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        cx = (x1 + x2) / 2.0  # Center x\n",
    "        cy = (y1 + y2) / 2.0  # Center y\n",
    "        w = x2 - x1  # Width\n",
    "        h = y2 - y1  # Height\n",
    "        score = 1.0  # Placeholder for the detection score\n",
    "        self.kf.x = np.array([cx, cy, 0, 0, w, h, score]).reshape((7, 1))\n",
    "        print(\"Kalman Filter initialized with bounding box:\", self.kf.x.flatten())\n",
    "    \n",
    "    def predict(self):\n",
    "        \"\"\"\n",
    "        Predict the next state.\n",
    "        \"\"\"\n",
    "        self.kf.predict()\n",
    "        self.time_since_update += 1\n",
    "        self.age += 1\n",
    "        print(\"Predicted state:\", self.kf.x.flatten())\n",
    "    \n",
    "    def update(self, bbox):\n",
    "        \"\"\"\n",
    "        Update the state with the new bounding box.\n",
    "        \"\"\"\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        cx = (x1 + x2) / 2.0\n",
    "        cy = (y1 + y2) / 2.0\n",
    "        w = x2 - x1  \n",
    "        h = y2 - y1\n",
    "        self.kf.update([cx, cy, w, h])\n",
    "        self.time_since_update = 0\n",
    "        self.history.append(self.kf.x)\n",
    "        self.lost_frames = 0  # Reset lost_frames on update\n",
    "        print(\"Updated state with bounding box:\", self.kf.x.flatten())\n",
    "    \n",
    "    def get_state(self):\n",
    "        \"\"\"\n",
    "        Get the current bounding box estimate.\n",
    "        \"\"\"\n",
    "        cx, cy, _, _, w, h, _ = self.kf.x.flatten()\n",
    "        x1 = cx - w / 2\n",
    "        y1 = cy - h / 2\n",
    "        x2 = cx + w / 2\n",
    "        y2 = cy + h / 2\n",
    "        return [x1, y1, x2, y2]\n",
    "\n",
    "def iou(bbox1, bbox2):\n",
    "    x1, y1, x2, y2 = bbox1\n",
    "    x1_, y1_, x2_, y2_ = bbox2\n",
    "\n",
    "    xi1 = max(x1, x1_)\n",
    "    yi1 = max(y1, y1_)\n",
    "    xi2 = min(x2, x2_)\n",
    "    yi2 = min(y2, y2_)\n",
    "\n",
    "    inter_area = max(0, xi2 - xi1) * max(0, yi2 - yi1)\n",
    "    bbox1_area = (x2 - x1) * (y2 - y1)\n",
    "    bbox2_area = (x2_ - x1_) * (y2_ - y1_)\n",
    "\n",
    "    union_area = bbox1_area + bbox2_area - inter_area\n",
    "\n",
    "    return inter_area / union_area\n",
    "\n",
    "def adaptive_metric(bbox1, bbox2, state):\n",
    "    return np.linalg.norm(state - np.array([bbox2[0], bbox2[1]]))\n",
    "\n",
    "class OCSORTTracker:\n",
    "    def __init__(self):\n",
    "        self.trackers = []\n",
    "        self.lost_trackers = []\n",
    "        self.max_lost_frames = 5\n",
    "    \n",
    "    def update(self, detections):\n",
    "        for tracker in self.trackers:\n",
    "            tracker.predict()\n",
    "\n",
    "        matches, unmatched_detections = self.associate_detections(detections)\n",
    "        \n",
    "        for match in matches:\n",
    "            tracker_idx, detection_idx = match\n",
    "            self.trackers[tracker_idx].update(detections[detection_idx]['bbox'])\n",
    "        \n",
    "        for idx in unmatched_detections:\n",
    "            self.trackers.append(OCSORTKalmanBoxTracker(detections[idx]['bbox']))\n",
    "        \n",
    "        self.lost_trackers = [tracker for tracker in self.trackers if tracker not in matches]\n",
    "        self.trackers = [tracker for tracker in self.trackers if tracker in matches]\n",
    "        \n",
    "        for tracker in self.lost_trackers:\n",
    "            tracker.lost_frames += 1\n",
    "            if tracker.lost_frames > self.max_lost_frames:\n",
    "                self.lost_trackers.remove(tracker)\n",
    "            else:\n",
    "                self.trackers.append(tracker)\n",
    "    \n",
    "    def associate_detections(self, detections):\n",
    "        iou_matrix = np.zeros((len(self.trackers), len(detections)))\n",
    "        observation_matrix = np.zeros((len(self.trackers), len(detections)))\n",
    "        \n",
    "        for t, tracker in enumerate(self.trackers):\n",
    "            for d, detection in enumerate(detections):\n",
    "                iou_matrix[t, d] = iou(tracker.kf.x[:4], detection['bbox'])\n",
    "                observation_matrix[t, d] = adaptive_metric(tracker.kf.x[:4], detection['bbox'], tracker.kf.x[:2])\n",
    "        \n",
    "        combined_matrix = iou_matrix + observation_matrix\n",
    "        \n",
    "        row_indices, col_indices = linear_sum_assignment(-combined_matrix)\n",
    "        \n",
    "        matches = []\n",
    "        unmatched_detections = list(range(len(detections)))\n",
    "        \n",
    "        for row, col in zip(row_indices, col_indices):\n",
    "            if combined_matrix[row, col] > 0.3:\n",
    "                matches.append((row, col))\n",
    "                unmatched_detections.remove(col)\n",
    "        \n",
    "        return matches, unmatched_detections\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "# Example usage\n",
    "folder = '/Users/andrei-macpro/Documents/Data/pose/meal_openpose/1047_meal'\n",
    "detection_files = sorted_alpha(folder)\n",
    "\n",
    "video_path = '/Users/andrei-macpro/Documents/Data/videos/meal_videos/1047_meal.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "tracker = OCSORTTracker()\n",
    "\n",
    "print(\"Detection files:\", detection_files)\n",
    "\n",
    "for detection_file in detection_files:\n",
    "    frame_no = int(detection_file.split('_')[-1].split('.')[0])\n",
    "    print(f'Processing detection file: {detection_file}, frame number: {frame_no}')\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_no)\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(f'Failed to read frame {frame_no}')\n",
    "        continue\n",
    "    \n",
    "    detections = get_skeletons(frame_no, os.path.join(folder, detection_file))\n",
    "    tracker.update(detections)\n",
    "    \n",
    "    for t in tracker.trackers:\n",
    "        bbox = t.get_state()\n",
    "\n",
    "        x1, y1, x2, y2 = map(int, bbox)\n",
    "\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    \n",
    "    # Draw the x, y grid\n",
    "    step_size = 50  # Adjust the step size as needed\n",
    "    for x in range(0, frame.shape[1], step_size):\n",
    "        cv2.putText(frame, f'{x}', (x, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1, cv2.LINE_AA)\n",
    "    for y in range(0, frame.shape[0], step_size):\n",
    "        cv2.putText(frame, f'{y}', (10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1, cv2.LINE_AA)\n",
    "    \n",
    "    cv2.imshow('Tracking', frame)\n",
    "    while True:\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            exit()\n",
    "        elif key == 32:  # Space bar key code\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_files = sorted_alpha(folder)\n",
    "detection_files"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepsort",
   "language": "python",
   "name": "deepsort"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
