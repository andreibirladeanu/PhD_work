{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/andrei-macpro/Documents/Data/tracking/features/play/combined_features.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#remove columns Age, DAI, Rinab, IQ_T2, duration_meal, duration_play, Gender from df\n",
    "df = df.drop(columns=['Age', 'DAI', 'Rinab', 'IQ_T2', 'duration_meal', 'duration_play','Gender'])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)\n",
    "\n",
    "# Create a group column by extracting the numeric part of the index\n",
    "df['group'] = df['s_id'].str.extract('(\\d+)').astype(int)\n",
    "\n",
    "# Set the index back to s_id\n",
    "df.set_index('s_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming df is your DataFrame and 'label' is the target variable\n",
    "# Assuming 'group' is the column in your DataFrame that defines the groups\n",
    "X = df.drop('label', axis=1)\n",
    "y = df['label']\n",
    "groups = df['group']\n",
    "\n",
    "# Create a GroupKFold object\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "scores = []\n",
    "\n",
    "# Split the data into training and testing sets based on the groups\n",
    "for train_index, test_index in gkf.split(X, y, groups):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Fit the model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    scores.append(accuracy)\n",
    "\n",
    "print(f'Average Accuracy: {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming df is your DataFrame and 'label' is the target variable\n",
    "# Assuming 'group' is the column in your DataFrame that defines the groups\n",
    "X = df.drop('label', axis=1)\n",
    "y = df['label']\n",
    "groups = df['group']\n",
    "\n",
    "# Create a GroupKFold object\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', SVC())\n",
    "])\n",
    "\n",
    "scores = []\n",
    "\n",
    "# Split the data into training and testing sets based on the groups\n",
    "for train_index, test_index in gkf.split(X, y, groups):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Fit the model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    scores.append(accuracy)\n",
    "\n",
    "print(f'Average Accuracy: {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Feature extraction\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "rfe = RFE(estimator=model, n_features_to_select=10)\n",
    "fit = rfe.fit(X_scaled, y)\n",
    "print(\"Num Features: %d\" % fit.n_features_)\n",
    "print(\"Selected Features: %s\" % fit.support_)\n",
    "print(\"Feature Ranking: %s\" % fit.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming 'group' is the column in your DataFrame that defines the groups\n",
    "groups = df['group']\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Feature extraction\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "rfe = RFE(estimator=model, n_features_to_select=15)\n",
    "fit = rfe.fit(X_scaled, y)\n",
    "\n",
    "# Select only the most important features\n",
    "X_important = X_scaled[:, fit.support_]\n",
    "\n",
    "# Create a GroupKFold object\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "scores = []\n",
    "\n",
    "# Split the data into training and testing sets based on the groups\n",
    "for train_index, test_index in gkf.split(X_important, y, groups):\n",
    "    X_train, X_test = X_important[train_index], X_important[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    scores.append(accuracy)\n",
    "\n",
    "print(f'Average Accuracy: {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming 'group' is the column in your DataFrame that defines the groups\n",
    "groups = df['group']\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Feature extraction\n",
    "model = SVC(kernel='linear')\n",
    "rfe = RFE(estimator=model, n_features_to_select=10)\n",
    "fit = rfe.fit(X_scaled, y)\n",
    "\n",
    "# Select only the most important features\n",
    "X_important = X_scaled[:, fit.support_]\n",
    "\n",
    "# Create a GroupKFold object\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "scores = []\n",
    "\n",
    "# Split the data into training and testing sets based on the groups\n",
    "for train_index, test_index in gkf.split(X_important, y, groups):\n",
    "    X_train, X_test = X_important[train_index], X_important[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    scores.append(accuracy)\n",
    "\n",
    "print(f'Average Accuracy: {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Define the classifiers and their parameters\n",
    "classifiers = [\n",
    "    ('lr', LogisticRegression(), {'lr__C': [0.1, 1]}),\n",
    "    ('svc', SVC(), {'svc__C': [0.1, 1], 'svc__kernel': ['linear']}),\n",
    "    ('rf', RandomForestClassifier(), {'rf__n_estimators': [10, 50], 'rf__max_depth': [None, 5]})\n",
    "]\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Perform a grid search for each classifier\n",
    "for name, classifier, params in classifiers:\n",
    "    pipeline = Pipeline([(name, classifier)])\n",
    "    grid_search = GridSearchCV(pipeline, params, cv=3)\n",
    "    grid_search.fit(X_scaled, y)\n",
    "\n",
    "    print(f'Best parameters for {name}: {grid_search.best_params_}')\n",
    "    print(f'Best score for {name}: {grid_search.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, GroupKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Define the classifiers and their parameters\n",
    "classifiers = [\n",
    "    ('lr', LogisticRegression(), {'lr__C': [0.1, 1]}),\n",
    "    ('svc_linear', SVC(kernel='linear'), {'svc_linear__C': [0.1, 1]}),\n",
    "    ('svc_rbf', SVC(kernel='rbf'), {'svc_rbf__C': [0.1, 1], 'svc_rbf__gamma': [0.1, 1]}),\n",
    "    ('rf', RandomForestClassifier(), {'rf__n_estimators': [10, 50], 'rf__max_depth': [None, 5]})\n",
    "]\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_shuffled, y_shuffled, groups_shuffled = shuffle(X_scaled, y, groups, random_state=0)\n",
    "\n",
    "# Select the 15 most important features\n",
    "selector = SelectKBest(f_classif, k=15)\n",
    "X_selected = selector.fit_transform(X_shuffled, y_shuffled)\n",
    "\n",
    "# Assuming 'group' is the column in your DataFrame that defines the groups\n",
    "groups = df['group']\n",
    "\n",
    "# Create a GroupKFold object\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "# Perform a grid search for each classifier\n",
    "for name, classifier, params in classifiers:\n",
    "    pipeline = Pipeline([(name, classifier)])\n",
    "    grid_search = GridSearchCV(pipeline, params, cv=gkf)\n",
    "    grid_search.fit(X_shuffled, y_shuffled, groups=groups_shuffled)\n",
    "\n",
    "    print(f'Best parameters for {name}: {grid_search.best_params_}')\n",
    "    print(f'Best score for {name}: {grid_search.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'features' is a list of feature names\n",
    "features = list(df.columns)\n",
    "\n",
    "# Select the 15 most important features\n",
    "selector = SelectKBest(f_classif, k=15)\n",
    "X_selected = selector.fit_transform(X_shuffled, y_shuffled)\n",
    "\n",
    "# Get the names of the selected features\n",
    "selected_features = [feature for feature, mask in zip(features, selector.get_support()) if mask]\n",
    "\n",
    "print('Selected features:', selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the SelectKBest method\n",
    "selector.fit(X_shuffled, y_shuffled)\n",
    "\n",
    "# Get the scores\n",
    "scores = selector.scores_\n",
    "\n",
    "# Create a list of tuples, each containing a feature and its score\n",
    "feature_scores = list(zip(features, scores))\n",
    "\n",
    "# Sort the list of tuples by the score, in descending order\n",
    "sorted_feature_scores = sorted(feature_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Get the names of the features, in order of their score\n",
    "sorted_features = [feature for feature, score in sorted_feature_scores]\n",
    "\n",
    "print('Features sorted by importance:', sorted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, GroupKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "# Define the classifiers and their parameters\n",
    "classifiers = [\n",
    "('lr', LogisticRegression(), {'lr__C': [0.01, 0.1, 1, 10, 100], 'lr__penalty': ['l1', 'l2'], 'lr__solver': ['liblinear', 'saga']}),\n",
    "    ('svc_linear', SVC(kernel='linear'), {'svc_linear__C': [0.01, 0.1, 1, 10, 100]}),\n",
    "    ('svc_rbf', SVC(kernel='rbf'), {'svc_rbf__C': [0.01, 0.1, 1, 10, 100], 'svc_rbf__gamma': [0.01, 0.1, 1, 10, 100]}),\n",
    "    ('rf', RandomForestClassifier(), {'rf__n_estimators': [10, 50, 100, 200], 'rf__max_depth': [None, 5, 10, 15], 'rf__min_samples_split': [2, 5, 10]})\n",
    "]\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_shuffled, y_shuffled, groups_shuffled = shuffle(X_scaled, y, groups, random_state=0)\n",
    "\n",
    "# Select the 15 most important features\n",
    "selector = SelectKBest(f_classif, k=15)\n",
    "X_selected = selector.fit_transform(X_shuffled, y_shuffled)\n",
    "\n",
    "# Assuming 'group' is the column in your DataFrame that defines the groups\n",
    "groups = df['group']\n",
    "\n",
    "# Create a GroupKFold object\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "# Perform a grid search for each classifier\n",
    "for name, classifier, params in classifiers:\n",
    "    pipeline = Pipeline([(name, classifier)])\n",
    "    grid_search = GridSearchCV(pipeline, params, cv=gkf)\n",
    "    grid_search.fit(X_shuffled, y_shuffled, groups=groups_shuffled)\n",
    "\n",
    "    print(f'Best parameters for {name}: {grid_search.best_params_}')\n",
    "    print(f'Best score for {name}: {grid_search.best_score_}')\n",
    "\n",
    "    # Calculate the cross-validated F1 score, precision, and recall\n",
    "    f1_scores = cross_val_score(grid_search.best_estimator_, X_shuffled, y_shuffled, cv=gkf, scoring='f1_macro', groups=groups_shuffled)\n",
    "    precision_scores = cross_val_score(grid_search.best_estimator_, X_shuffled, y_shuffled, cv=gkf, scoring='precision_macro', groups=groups_shuffled)\n",
    "    recall_scores = cross_val_score(grid_search.best_estimator_, X_shuffled, y_shuffled, cv=gkf, scoring='recall_macro', groups=groups_shuffled)\n",
    "\n",
    "    print(f'Cross-validated F1 score for {name}: {f1_scores.mean()}')\n",
    "    print(f'Cross-validated precision for {name}: {precision_scores.mean()}')\n",
    "    print(f'Cross-validated recall for {name}: {recall_scores.mean()}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, GroupKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "## this time using just the 15 best features \n",
    "\n",
    "\n",
    "# Define the classifiers and their parameters\n",
    "classifiers = [\n",
    "    ('lr', LogisticRegression(), {'lr__C': [0.01, 0.1, 1, 10, 100], 'lr__penalty': ['l1', 'l2'], 'lr__solver': ['liblinear', 'saga']}),\n",
    "    ('svc_linear', SVC(kernel='linear'), {'svc_linear__C': [0.01, 0.1, 1, 10, 100]}),\n",
    "    ('svc_rbf', SVC(kernel='rbf'), {'svc_rbf__C': [0.01, 0.1, 1, 10, 100], 'svc_rbf__gamma': [0.01, 0.1, 1, 10, 100]}),\n",
    "    ('rf', RandomForestClassifier(), {'rf__n_estimators': [10, 50, 100, 200], 'rf__max_depth': [None, 5, 10, 15], 'rf__min_samples_split': [2, 5, 10]})\n",
    "]\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_shuffled, y_shuffled, groups_shuffled = shuffle(X_scaled, y, groups, random_state=0)\n",
    "\n",
    "# Select the 15 most important features\n",
    "selector = SelectKBest(f_classif, k=15)\n",
    "X_selected = selector.fit_transform(X_shuffled, y_shuffled)\n",
    "\n",
    "# Assuming 'group' is the column in your DataFrame that defines the groups\n",
    "groups = df['group']\n",
    "\n",
    "# Create a GroupKFold object\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "# Perform a grid search for each classifier\n",
    "for name, classifier, params in classifiers:\n",
    "    pipeline = Pipeline([(name, classifier)])\n",
    "    grid_search = GridSearchCV(pipeline, params, cv=gkf)\n",
    "    grid_search.fit(X_selected, y_shuffled, groups=groups_shuffled)\n",
    "\n",
    "    print(f'Best parameters for {name}: {grid_search.best_params_}')\n",
    "    print(f'Best score for {name}: {grid_search.best_score_}')\n",
    "\n",
    "    # Calculate the cross-validated F1 score, precision, and recall\n",
    "    f1_scores = cross_val_score(grid_search.best_estimator_, X_selected, y_shuffled, cv=gkf, scoring='f1_macro', groups=groups_shuffled)\n",
    "    precision_scores = cross_val_score(grid_search.best_estimator_, X_selected, y_shuffled, cv=gkf, scoring='precision_macro', groups=groups_shuffled)\n",
    "    recall_scores = cross_val_score(grid_search.best_estimator_, X_selected, y_shuffled, cv=gkf, scoring='recall_macro', groups=groups_shuffled)\n",
    "\n",
    "    print(f'Cross-validated F1 score for {name}: {f1_scores.mean()}')\n",
    "    print(f'Cross-validated precision for {name}: {precision_scores.mean()}')\n",
    "    print(f'Cross-validated recall for {name}: {recall_scores.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].unique()   \n",
    "# count how many samples are in each class based on the group column\n",
    "\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create a dummy classifier\n",
    "dummy = DummyClassifier(strategy='most_frequent')\n",
    "\n",
    "# Fit the dummy classifier\n",
    "dummy.fit(X_shuffled, y_shuffled)\n",
    "\n",
    "# Predict the labels of the training set\n",
    "y_pred_dummy = dummy.predict(X_shuffled)\n",
    "\n",
    "# Calculate the accuracy of the dummy classifier\n",
    "accuracy_dummy = accuracy_score(y_shuffled, y_pred_dummy)\n",
    "\n",
    "print(f'Accuracy of dummy classifier: {accuracy_dummy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from numpy.random import RandomState\n",
    "\n",
    "# Create a dummy classifier\n",
    "dummy = DummyClassifier(strategy='stratified')\n",
    "\n",
    "# Create an SVC classifier with specific parameters\n",
    "svc_rbf = SVC(kernel='rbf', C=100, gamma=0.1)\n",
    "\n",
    "# Initialize a RandomState\n",
    "rs = RandomState(123)\n",
    "\n",
    "# Initialize a GroupKFold\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "# Perform 10 random shuffles\n",
    "for i in range(10):\n",
    "    X_shuffled, y_shuffled, groups_shuffled = shuffle(X_scaled, y, groups, random_state=rs)\n",
    "\n",
    "    # Calculate the cross-validated accuracy of the dummy classifier\n",
    "    accuracy_dummy = cross_val_score(dummy, X_shuffled, y_shuffled, groups=groups_shuffled, cv=gkf, scoring='accuracy').mean()\n",
    "\n",
    "    print(f'Cross-validated accuracy of dummy classifier for shuffle {i+1}: {accuracy_dummy}')\n",
    "\n",
    "    # Calculate the cross-validated accuracy of the SVC classifier\n",
    "    accuracy_svc = cross_val_score(svc_rbf, X_shuffled, y_shuffled, groups=groups_shuffled, cv=gkf, scoring='accuracy').mean()\n",
    "\n",
    "    print(f'Cross-validated accuracy of SVC classifier for shuffle {i+1}: {accuracy_svc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import make_scorer, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import GroupKFold, cross_validate\n",
    "from numpy.random import RandomState\n",
    "\n",
    "# Create a dummy classifier\n",
    "dummy = DummyClassifier(strategy='most_frequent')\n",
    "\n",
    "# Create an SVC classifier with specific parameters\n",
    "svc_rbf = SVC(kernel='rbf', C=100, gamma=0.1)\n",
    "\n",
    "# Initialize a RandomState\n",
    "rs = RandomState(123)\n",
    "\n",
    "# Initialize a GroupKFold\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "# Define scoring metrics\n",
    "scoring = {'accuracy': make_scorer(accuracy_score),\n",
    "           'precision': make_scorer(precision_score, average='macro'),\n",
    "           'recall': make_scorer(recall_score, average='macro'),\n",
    "           'f1': make_scorer(f1_score, average='macro')}\n",
    "\n",
    "# Perform 10 random shuffles\n",
    "for i in range(10):\n",
    "    X_shuffled, y_shuffled, groups_shuffled = shuffle(X_scaled, y, groups, random_state=rs)\n",
    "\n",
    "    # Calculate the cross-validated scores of the dummy classifier\n",
    "    scores_dummy = cross_validate(dummy, X_shuffled, y_shuffled, groups=groups_shuffled, cv=gkf, scoring=scoring)\n",
    "\n",
    "    print(f'Cross-validated scores of dummy classifier for shuffle {i+1}:')\n",
    "    for metric, scores in scores_dummy.items():\n",
    "        print(f'{metric}: {scores.mean()}')\n",
    "\n",
    "    # Calculate the cross-validated scores of the SVC classifier\n",
    "    scores_svc = cross_validate(svc_rbf, X_shuffled, y_shuffled, groups=groups_shuffled, cv=gkf, scoring=scoring)\n",
    "\n",
    "    print(f'Cross-validated scores of SVC classifier for shuffle {i+1}:')\n",
    "    for metric, scores in scores_svc.items():\n",
    "        print(f'{metric}: {scores.mean()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepsort",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
