{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20122010-a941-4b62-93f3-c443dc84b217",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tf_pose import common\n",
    "import tf_slim as slim\n",
    "from tf_pose.estimator import TfPoseEstimator\n",
    "from tf_pose.networks import get_graph_path, model_wh\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c140bf30-cc5b-493d-b879-ff5a101e82dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img(image, axis=False, grid=False, showBG = True):\n",
    "    plt.figure(figsize=(15,8))\n",
    "    if showBG:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(image);\n",
    "    if grid == True:\n",
    "        plt.grid();\n",
    "    if axis == False:       \n",
    "        plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bb3b60-b05e-4466-bb7c-cc100f3eca78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_human_pose(image, showBG = True):\n",
    "    image = image\n",
    "  \n",
    "    if image is None:\n",
    "        logger.error('Image can not be read, path=%s' % image)\n",
    "        sys.exit(-1)\n",
    "\n",
    "    t = time.time()\n",
    "    \n",
    "    humans = e.inference(image, resize_to_default=(w > 0 and h > 0), upsample_size=4.0)\n",
    "    elapsed = time.time() - t\n",
    "\n",
    "    #logger.info('inference image: %s in %.4f seconds.' % (image, elapsed))\n",
    "    if showBG == False:\n",
    "        image = np.zeros(image.shape)\n",
    "    image = TfPoseEstimator.draw_humans(image, humans, imgcopy=False)\n",
    "    return image, humans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac831ca6-0d40-451c-9ad8-f1ecdf6e9646",
   "metadata": {},
   "outputs": [],
   "source": [
    "model='cmu'\n",
    "resize='480x432'\n",
    "w, h = model_wh(resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c884f4-3517-4c16-82c4-60f6d39dbeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = TfPoseEstimator(get_graph_path(model), target_size=(w, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f3912a-5e73-491a-a015-a769da21a398",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = '/Users/andrei-macpro/Documents/Data/videoss/1042_meal.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e2dfb6-6995-4e90-b6b6-20261797b7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfc3acf-acef-4822-bd57-c067353624b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "while(cap.isOpened()):\n",
    "        ret_val, image = cap.read()\n",
    "        if ret_val == False:\n",
    "            break\n",
    "        frames.append(image)\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d676d2d8-d213-448b-b511-3a42d04f7675",
   "metadata": {},
   "outputs": [],
   "source": [
    "humans = e.inference(frames[50], resize_to_default=(w > 0 and h > 0), upsample_size=4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0017b1bb-31f1-487f-9d01-370b8ef24432",
   "metadata": {},
   "outputs": [],
   "source": [
    "black_background = np.zeros(frames[50].shape)\n",
    "skeleton = TfPoseEstimator.draw_humans(black_background, humans, imgcopy=False)\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.imshow(skeleton);\n",
    "plt.grid(); \n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbf9ec8-01f7-4a24-a11f-da6a94bfb95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(frames[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00afe13f-d206-40c9-83e8-a4239f25c121",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, hum = get_human_pose(frames[110])\n",
    "plot_img(img, axis=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
