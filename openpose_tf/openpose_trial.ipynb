{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f52c418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2566a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from tf_pose import common\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tf_pose.estimator import TfPoseEstimator\n",
    "from tf_pose.networks import get_graph_path, model_wh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947b6f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_pose.estimator import TfPoseEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b502828",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_style = tf_pose.infer('/Users/andrei-macpro/Documents/Data/im1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc48894f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/andrei-macpro/Documents/Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3969c234",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3fbf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "image=common.read_imgfile('/Users/andrei-macpro/Documents/Data/im1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd402806",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = TfPoseEstimator(get_graph_path('mobilenet_thin'), target_size=(432,368))\n",
    "image=common.read_imgfile('/Users/andrei-macpro/Documents/Data/im1.png')\n",
    "#humans = e.inference(image)\n",
    "#image = TfPoseEstimator.draw_humans(image, humans, imgcopy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1938fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('image', image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f9d743",
   "metadata": {},
   "outputs": [],
   "source": [
    "image=common.read_imgfile('/Users/andrei-macpro/Documents/Data/im1.png')\n",
    "#humans = e.inference(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fb2e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = TfPoseEstimator.draw_humans(image, humans, imgcopy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e40ab64",
   "metadata": {},
   "outputs": [],
   "source": [
    "humans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8876d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from tf_pose import common\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tf_pose.estimator import TfPoseEstimator\n",
    "from tf_pose.networks import get_graph_path, model_wh\n",
    "\n",
    "logger = logging.getLogger('TfPoseEstimatorRun')\n",
    "logger.handlers.clear()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('[%(asctime)s] [%(name)s] [%(levelname)s] %(message)s')\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='tf-pose-estimation run')\n",
    "    parser.add_argument('--image', type=str, default='./images/p1.jpg')\n",
    "    parser.add_argument('--model', type=str, default='cmu',\n",
    "                        help='cmu / mobilenet_thin / mobilenet_v2_large / mobilenet_v2_small')\n",
    "    parser.add_argument('--resize', type=str, default='0x0',\n",
    "                        help='if provided, resize images before they are processed. '\n",
    "                             'default=0x0, Recommends : 432x368 or 656x368 or 1312x736 ')\n",
    "    parser.add_argument('--resize-out-ratio', type=float, default=4.0,\n",
    "                        help='if provided, resize heatmaps before they are post-processed. default=1.0')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    w, h = model_wh(args.resize)\n",
    "    if w == 0 or h == 0:\n",
    "        e = TfPoseEstimator(get_graph_path(args.model), target_size=(432, 368))\n",
    "    else:\n",
    "        e = TfPoseEstimator(get_graph_path(args.model), target_size=(w, h))\n",
    "\n",
    "    # estimate human poses from a single image !\n",
    "    image = common.read_imgfile(args.image, None, None)\n",
    "    if image is None:\n",
    "        logger.error('Image can not be read, path=%s' % args.image)\n",
    "        sys.exit(-1)\n",
    "\n",
    "    t = time.time()\n",
    "    humans = e.inference(image, resize_to_default=(w > 0 and h > 0), upsample_size=args.resize_out_ratio)\n",
    "    elapsed = time.time() - t\n",
    "\n",
    "    logger.info('inference image: %s in %.4f seconds.' % (args.image, elapsed))\n",
    "\n",
    "    image = TfPoseEstimator.draw_humans(image, humans, imgcopy=False)\n",
    "\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        fig = plt.figure()\n",
    "        a = fig.add_subplot(2, 2, 1)\n",
    "        a.set_title('Result')\n",
    "        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        bgimg = cv2.cvtColor(image.astype(np.uint8), cv2.COLOR_BGR2RGB)\n",
    "        bgimg = cv2.resize(bgimg, (e.heatMat.shape[1], e.heatMat.shape[0]), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        # show network output\n",
    "        a = fig.add_subplot(2, 2, 2)\n",
    "        plt.imshow(bgimg, alpha=0.5)\n",
    "        tmp = np.amax(e.heatMat[:, :, :-1], axis=2)\n",
    "        plt.imshow(tmp, cmap=plt.cm.gray, alpha=0.5)\n",
    "        plt.colorbar()\n",
    "\n",
    "        tmp2 = e.pafMat.transpose((2, 0, 1))\n",
    "        tmp2_odd = np.amax(np.absolute(tmp2[::2, :, :]), axis=0)\n",
    "        tmp2_even = np.amax(np.absolute(tmp2[1::2, :, :]), axis=0)\n",
    "\n",
    "        a = fig.add_subplot(2, 2, 3)\n",
    "        a.set_title('Vectormap-x')\n",
    "        # plt.imshow(CocoPose.get_bgimg(inp, target_size=(vectmap.shape[1], vectmap.shape[0])), alpha=0.5)\n",
    "        plt.imshow(tmp2_odd, cmap=plt.cm.gray, alpha=0.5)\n",
    "        plt.colorbar()\n",
    "\n",
    "        a = fig.add_subplot(2, 2, 4)\n",
    "        a.set_title('Vectormap-y')\n",
    "        # plt.imshow(CocoPose.get_bgimg(inp, target_size=(vectmap.shape[1], vectmap.shape[0])), alpha=0.5)\n",
    "        plt.imshow(tmp2_even, cmap=plt.cm.gray, alpha=0.5)\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        logger.warning('matplitlib error, %s' % e)\n",
    "        cv2.imshow('result', image)\n",
    "        cv2.waitKey()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5b63f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "humans = e.inference(image=image, resize_to_default=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f845e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = TfPoseEstimator.draw_humans(image, humans, imgcopy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6012ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c12edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "e = TfPoseEstimator(get_graph_path('mobilenet_v2_large'), target_size=(432,368))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe29a2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "humans = e.inference(image, resize_to_default=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d5d57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "humans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9904ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tf_pose\n",
    "humans, jsons = tf_pose.infer('/Users/andrei-macpro/Documents/Data/im1.PNG', model = 'mobilenet_v2_large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a95b021",
   "metadata": {},
   "outputs": [],
   "source": [
    "humans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b2b3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(humans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3f9832",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(jsons[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c39ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "image=common.read_imgfile('/Users/andreibirladeanu/Documents/Data/im1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f0244b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tf_pose import common\n",
    "from tf_pose.estimator import TfPoseEstimator\n",
    "from tf_pose.networks import get_graph_path, model_wh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a010720e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model='mobilenet_v2_large'\n",
    "resize='432x368'\n",
    "w, h = model_wh(resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080af2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = TfPoseEstimator(get_graph_path(model), target_size=(w, h))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7af33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '/Users/andreibirladeanu/Documents/Data/frames/2009_meal.png'\n",
    "image = cv2.imread(image_path)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(image)\n",
    "plt.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae45b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38561b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = common.read_imgfile(image_path, None, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd77cbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "humans = e.inference(image, resize_to_default=(w > 0 and h > 0), upsample_size=4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b4acd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(humans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2a5b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = TfPoseEstimator.draw_humans(image, humans, imgcopy=False)\n",
    "plt.imshow(image)\n",
    "#cv2.imwrite('2027_play.png', image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e39dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.heatMat[0][0][17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0746d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_prob = np.amax(e.heatMat[:, :, :-1], axis=2)\n",
    "plt.imshow(max_prob)\n",
    "plt.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c8d834",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "bgimg = cv2.cvtColor(image.astype(np.uint8), cv2.COLOR_BGR2RGB)\n",
    "bgimg = cv2.resize(bgimg, (e.heatMat.shape[1], e.heatMat.shape[0]), interpolation=cv2.INTER_AREA)\n",
    "plt.imshow(bgimg, alpha=0.5)\n",
    "plt.imshow(max_prob, alpha=0.5)\n",
    "plt.colorbar()\n",
    "plt.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f398280b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = TfPoseEstimator.draw_humans(image, humans, imgcopy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea2db63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_keypoints(image, hum, human=1, color='orange', showBG = True):\n",
    "    if human == 0: human = 1\n",
    "    num_hum = len(hum)\n",
    "    keypoints = str(str(str(hum[human-1]).split('BodyPart:')[1:]).split('-')).split(' score=')\n",
    "    keypoints_list=[]\n",
    "    for i in range (len(keypoints)-1): \n",
    "        pnt = keypoints[i][-11:-1]\n",
    "        pnt = tuple(map(float, pnt.split(', ')))\n",
    "        keypoints_list.append(pnt)\n",
    "\n",
    "    keypts_array = np.array(keypoints_list)\n",
    "    keypts_array = keypts_array*(image.shape[1],image.shape[0])\n",
    "    keypts_array = keypts_array.astype(int)\n",
    "    keypts_array\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.axis([0, image.shape[1], 0, image.shape[0]])  \n",
    "    plt.scatter(*zip(*keypts_array), s=200, color=color, alpha=0.6)\n",
    "    if showBG:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)      \n",
    "    plt.imshow(image)\n",
    "    ax=plt.gca() \n",
    "    ax.set_ylim(ax.get_ylim()[::-1]) \n",
    "    ax.xaxis.tick_top() \n",
    "    plt.title('Keypoints Person [{}] from {} humans detected\\n'.format(human, num_hum))\n",
    "    plt.grid();\n",
    "\n",
    "    for i, txt in enumerate(keypts_array):\n",
    "        ax.annotate(i, (keypts_array[i][0]-5, keypts_array[i][1]+5))\n",
    "            \n",
    "    return keypts_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb2d3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_keypoints(image, humans, human=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f25384e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45866a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('2009_meal.png', image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25da19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = common.read_imgfile(image_path, None, None)\n",
    "humans = e.inference(image, resize_to_default=(w > 0 and h > 0), upsample_size=4.0)\n",
    "black_background = np.zeros(image.shape)\n",
    "skeleton = TfPoseEstimator.draw_humans(black_background, humans, imgcopy=False)\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.imshow(skeleton);\n",
    "plt.grid()\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11950765",
   "metadata": {},
   "outputs": [],
   "source": [
    "humans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cff0602",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('TfPoseEstimator-Video')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('[%(asctime)s] [%(name)s] [%(levelname)s] %(message)s')\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8e13e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fps_time = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95debf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "model='cmu'\n",
    "#show_process = True # for debug purpose, if enabled, speed for inference is dropped.\n",
    "#logger.debug('initialization %s : %s' % (model, get_graph_path(model)))\n",
    "\n",
    "resolution='432x368'\n",
    "w, h = model_wh(resolution)\n",
    "e = TfPoseEstimator(get_graph_path(model), target_size=(w, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526a7796",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('TfPoseEstimatorRun')\n",
    "logger.handlers.clear()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('[%(asctime)s] [%(name)s] [%(levelname)s] %(message)s')\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d2006d",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = '/Users/andreibirladeanu/Documents/Data/Meal/1132_meal.mp4'\n",
    "fps_time = 0\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if cap.isOpened() is False:\n",
    "    print(\"Error opening video stream or file\")\n",
    "while True:\n",
    "    ret_val, image = cap.read()\n",
    "\n",
    "    humans = e.inference(image,\n",
    "                         resize_to_default=(w > 0 and h > 0),\n",
    "                         upsample_size=4.0)\n",
    "    #if not showBG:\n",
    "    #image = np.zeros(image.shape)\n",
    "    image = TfPoseEstimator.draw_humans(image, humans, imgcopy=False)\n",
    "\n",
    "    cv2.putText(image, \"FPS: %f\" % (1.0 / (time.time() - fps_time)), (10, 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    cv2.imshow('tf-pose-estimation result', image)\n",
    "    fps_time = time.time()\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#logger.debug('finished+')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
