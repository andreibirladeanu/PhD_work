{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130bf83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tf_pose import common\n",
    "import tf_slim as slim\n",
    "from tf_pose.estimator import TfPoseEstimator\n",
    "from tf_pose.networks import get_graph_path, model_wh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e887f88c-e531-430b-8c73-158ba2630506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keypoints(human):\n",
    "    scores = []\n",
    "    keypoints = str(str(str(human).split('BodyPart:')[1:]).split('-')).split(' score=')\n",
    "    keypoints_list=[]\n",
    "    for i in range (len(keypoints)-1): \n",
    "        pnt = keypoints[i][-11:-1]\n",
    "        pnt = tuple(map(float, pnt.split(', ')))\n",
    "        keypoints_list.append(pnt)\n",
    "        scores.append(float(str(keypoints[i]).split('score=')[1][0:4]))\n",
    "   # human=np.array(human)\n",
    "\n",
    "    \n",
    "        \n",
    "    keypts_array = np.array(keypoints_list)\n",
    "    keypts_array = keypts_array*(image.shape[1],image.shape[0])\n",
    "    keypts_array = keypts_array.astype(int)\n",
    "    return(keypts_array, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4689f4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model='mobilenet_thin'\n",
    "resize='480x432'\n",
    "w, h = model_wh(resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4d0c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = TfPoseEstimator(get_graph_path(model), target_size=(w, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b7a913",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = '/Users/andrei-macpro/Documents/Data/excerpt.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52cc334",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baaa0a4-d983-49c5-9a5f-bd02f4c686d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "if cap.isOpened():\n",
    "    while True:\n",
    "        ret_val, image = cap.read()\n",
    "        frame_no+=1\n",
    "        humans = e.inference(image,\n",
    "                             resize_to_default=(w > 0 and h > 0),\n",
    "                             upsample_size=4.0)\n",
    "        \n",
    "        humans_0 = np.array(humans[0])\n",
    "        keypoints = str(str(str(humans[0]).split('BodyPart:')[1:]).split('-')).split(' score=')\n",
    "        print((str(humans_0).split('score=')[1][0:4]))\n",
    "        scores.append(x[1][0:4] for x in str(humans_0).split('score='))\n",
    "       \n",
    "        print(scores)\n",
    "        keypoints_list=[]\n",
    "        for i in range (len(keypoints)-1): \n",
    "            pnt = keypoints[i][-11:-1]\n",
    "            score = keypoints[i][-10]\n",
    "            pnt = tuple(map(float, pnt.split(', ')))\n",
    "            print(type(pnt))\n",
    "            keypoints_list.append(pnt)\n",
    "        keypts_array = np.array(keypoints_list)\n",
    "        print(keypts_array)\n",
    "        keypts_array = keypts_array*(image.shape[1],image.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15265f08-f691-4b10-87a3-8a223eaf1b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673d4ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "showBG = True\n",
    "fps_time = 0\n",
    "if cap.isOpened():\n",
    "    while True:\n",
    "        ret_val, image = cap.read()\n",
    "        humans = e.inference(image,\n",
    "                             resize_to_default=(w > 0 and h > 0),\n",
    "                             upsample_size=4.0)\n",
    "        keypoints = str(str(str(humans[0]).split('BodyPart:')[1:]).split('-')).split(' score=')\n",
    "        print(keypoints)\n",
    "        keypoints_list=[]\n",
    "        for i in range (len(keypoints)-1): \n",
    "            pnt = keypoints[i][-11:-1]\n",
    "            pnt = tuple(map(float, pnt.split(', ')))\n",
    "            print(pnt)\n",
    "            keypoints_list.append(pnt)\n",
    "        keypts_array = np.array(keypoints_list)\n",
    "        print(keypts_array)\n",
    "        keypts_array = keypts_array*(image.shape[1],image.shape[0])\n",
    "        print(image.shape)\n",
    "        keypts_array = keypts_array.astype(int)\n",
    "        print(f\"keypoints for person 1 {keypts_array}\")\n",
    "        minimum = np.amin(keypts_array, axis=0)\n",
    "        maximum = np.amax(keypts_array, axis=0)\n",
    "        #rect = cv2.rectangle(image,(minimum[0]-20, minimum[1]-20),(maximum[0]+20,maximum[1]+20),(0,255,0),2)\n",
    "        #cv2.boundingRect(minimum[0]-20:minimum[1]-20,maximum[0]+20:maximum[1]+20)\n",
    "        #x,y,w,h = cv2.boundingRect((minimum[0]-20, minimum[1]-20,maximum[0]+20,maximum[1]+20))\n",
    "        #roi=image[y:y+h,x:x+w]\n",
    "        #https://stackoverflow.com/questions/54054865/given-pixel-label-draw-a-bounding-box-in-python\n",
    "        #cv2.imshow('rect.png', rect)\n",
    "        #image = np.zeros(image.shape)\n",
    "        #cv2.imshow('image', image)\n",
    "        rect = image[minimum[1]:maximum[1],minimum[0]:maximum[0]]\n",
    "        cv2.imwrite('rect.png', rect)\n",
    "        image = TfPoseEstimator.draw_humans(image, humans, imgcopy=True)\n",
    "       # cv2.putText(image, \"FPS: %f\" % (1.0 / (time.time() - fps_time)), (10, 10),\n",
    "        #            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "       # cv2.imshow('tf-pose-estimation result', image)\n",
    "        #fps_time = time.time()\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf31a736-23b4-4a66-aa82-d7a86658c446",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15c273d-7b20-466e-a3ae-86883c13bce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(0.44, 0.12) *(image.shape[1],image.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062df375-4bd4-482e-a89e-296191c6853d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import mul\n",
    "res = tuple(map(mul, (0.44, 0.12), (image.shape[1],image.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3381328f-f762-435e-8024-5435a1c69144",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple(map(float, res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619e39a1-d62c-4282-9539-6bbcad540bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f17431b-8366-448c-afc7-230582a81893",
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = np.array(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ba16f1-d528-463e-81f4-28eb075d3640",
   "metadata": {},
   "outputs": [],
   "source": [
    "res2.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab6da9d-1c6f-41b7-b7f5-58acaa29d895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keypoints(human):\n",
    "    scores = []\n",
    "    keypoints = str(str(str(human).split('BodyPart:')[1:]).split('-')).split(' score=')\n",
    "    keypoints_list=[]\n",
    "    for i in range (len(keypoints)-1): \n",
    "        pnt = keypoints[i][-11:-1]\n",
    "        pnt = tuple(map(float, pnt.split(', ')))\n",
    "        keypoints_list.append(pnt)\n",
    "    human=np.array(human)\n",
    "    for i in str(human).split(\" score=\"):\n",
    "        if i[0:4]==\"Body\":\n",
    "            continue\n",
    "        else:\n",
    "            scores.append(float(i[0:4]))\n",
    "    scores=np.array(scores)\n",
    "    keypts_array = np.array(keypoints_list)\n",
    "    keypts_array = keypts_array*(image.shape[1],image.shape[0])\n",
    "    keypts_array = keypts_array.astype(int)\n",
    "    return(keypts_array, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a6e5b0-2d07-4b49-92b6-7c14738113d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(video_path)\n",
    "while(cap.isOpened()):\n",
    "    ret_val, image = cap.read()\n",
    "    if ret_val == False:\n",
    "        break\n",
    "    humans = e.inference(image,\n",
    "                         resize_to_default=(w > 0 and h > 0),\n",
    "                         upsample_size=4.0)\n",
    "    \n",
    "    keypoints = str(str(str(humans[0]).split('BodyPart:')[1:]).split('-')).split(' score=')\n",
    "    keypoints_list=[]\n",
    "    humans = np.array(humans[0])\n",
    "    print(humans)\n",
    "    for i in str(humans).split(\" score=\"):\n",
    "        if i[0:4]==\"Body\":\n",
    "            continue\n",
    "        else:\n",
    "            print(i[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8944b3-70ef-46e2-8453-4438bbc5c058",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(video_path)\n",
    "human_no = []\n",
    "frame_no = 0\n",
    "failed_frames = []\n",
    "human_1 = []\n",
    "human_2 = []\n",
    "human_3 =[]\n",
    "probs_1 = []\n",
    "while(cap.isOpened()):\n",
    "    ret_val, image = cap.read()\n",
    "    if ret_val == False:\n",
    "        break\n",
    "    frame_no+=1\n",
    "    humans = e.inference(image,\n",
    "                         resize_to_default=(w > 0 and h > 0),\n",
    "                         upsample_size=4.0)\n",
    "    human_no.append(len(humans))\n",
    "    \n",
    "    if len(humans)>2:\n",
    "        keypoints_3 = keypoints(humans[2])\n",
    "        keypoints_2 = keypoints(humans[1])\n",
    "        keypoints_1 = keypoints(humans[0])\n",
    "        failed_frames.append('success')\n",
    "    \n",
    "    elif len(humans)>1:\n",
    "        keypoints_2 = keypoints(humans[1])\n",
    "        keypoints_1 = keypoints(humans[0])\n",
    "        failed_frames.append('success')\n",
    "    elif len(humans) == 1:\n",
    "        keypoints_1 = keypoints(humans[0])\n",
    "        failed_frames.append('success')\n",
    "    else:\n",
    "        failed_frames.append(frame_no)\n",
    "    human_1.append({frame_no:keypoints_1})\n",
    "    human_2.append({frame_no:keypoints_2})\n",
    "    human_3.append({frame_no:keypoints_3})\n",
    " \n",
    "\n",
    "    \n",
    " \n",
    "cap.release()\n",
    "human_1 = np.array(human_1)\n",
    "human_2 = np.array(human_2)\n",
    "human_3 = np.array(human_3)\n",
    "human_no = np.array(human_no)\n",
    "failed_frames = np.array(failed_frames) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885b72e8-e522-44cf-b2ab-9bea421c8c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b29666f-2704-43ea-93c6-7a849387ff94",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9ca0a2-20e1-43e7-abe4-ce7a8697882a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(18):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bd31a3-e50a-4793-a057-ed47067c8398",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "while(cap.isOpened()):\n",
    "    ret_val, image = cap.read()\n",
    "    if ret_val == False:\n",
    "        break\n",
    "    humans = e.inference(image,\n",
    "                         resize_to_default=(w > 0 and h > 0),\n",
    "                         upsample_size=4.0)\n",
    "    human_0 = humans[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a14ea7-0892-4c7e-b067-c47ebe021199",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ceed60-d148-4b5b-894b-26e97babc2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "(str(human_0).split(\"-\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee4322c",
   "metadata": {},
   "outputs": [],
   "source": [
    "showBG = True\n",
    "fps_time = 0\n",
    "if cap.isOpened():\n",
    "    while True:\n",
    "        ret_val, image = cap.read()\n",
    "        humans = e.inference(image,\n",
    "                             resize_to_default=(w > 0 and h > 0),\n",
    "                             upsample_size=4.0)\n",
    "        keypoints = str(str(str(humans[0]).split('BodyPart:')[1:]).split('-')).split(' score=')\n",
    "        print(keypoints)\n",
    "        keypoints_list=[]\n",
    "        for i in range (len(keypoints)-1): \n",
    "            pnt = keypoints[i][-11:-1]\n",
    "            pnt = tuple(map(float, pnt.split(', ')))\n",
    "            print(pnt)\n",
    "            keypoints_list.append(pnt)\n",
    "        keypts_array = np.array(keypoints_list)\n",
    "        print(keypts_array)\n",
    "        keypts_array = keypts_array*(image.shape[1],image.shape[0])\n",
    "        print(image.shape)\n",
    "        keypts_array = keypts_array.astype(int)\n",
    "        print(f\"keypoints for person 1 {keypts_array}\")\n",
    "        minimum = np.amin(keypts_array, axis=0)\n",
    "        maximum = np.amax(keypts_array, axis=0)\n",
    "        #rect = cv2.rectangle(image,(minimum[0]-20, minimum[1]-20),(maximum[0]+20,maximum[1]+20),(0,255,0),2)\n",
    "        #cv2.boundingRect(minimum[0]-20:minimum[1]-20,maximum[0]+20:maximum[1]+20)\n",
    "        #x,y,w,h = cv2.boundingRect((minimum[0]-20, minimum[1]-20,maximum[0]+20,maximum[1]+20))\n",
    "        #roi=image[y:y+h,x:x+w]\n",
    "        #https://stackoverflow.com/questions/54054865/given-pixel-label-draw-a-bounding-box-in-python\n",
    "        #cv2.imshow('rect.png', rect)\n",
    "        #image = np.zeros(image.shape)\n",
    "        #cv2.imshow('image', image)\n",
    "        rect = image[minimum[1]:maximum[1],minimum[0]:maximum[0]]\n",
    "        cv2.imwrite('rect.png', rect)\n",
    "        image = TfPoseEstimator.draw_humans(image, humans, imgcopy=True)\n",
    "       # cv2.putText(image, \"FPS: %f\" % (1.0 / (time.time() - fps_time)), (10, 10),\n",
    "        #            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "       # cv2.imshow('tf-pose-estimation result', image)\n",
    "        #fps_time = time.time()\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c874d229-8233-4e5e-8cab-61a229d6673d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "subscriptable = str(human_0).split(\"BodyPart:\")[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed35e15-437d-494a-a31c-abf56f4d20a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "kpts = []\n",
    "coords_x = []\n",
    "coords_y = []\n",
    "probs = []\n",
    "all_points = [x for x in range(18)]\n",
    "big_dic = []\n",
    "subscriptable = str(human_0).split(\"BodyPart:\")[1:]\n",
    "for x in subscriptable:\n",
    "    kpts.append(int((x.split('-')[0])))\n",
    "    coords_x.append(float((str(x.split('-')[1]).split(\" score=\")[0][1:5]))*image.shape[1])\n",
    "    coords_y.append(float((str(x.split('-')[1]).split(\" score=\")[0][6:11]))*image.shape[0])\n",
    "    probs.append(float(str(x.split('-')[1]).split(\" score=\")[1]))\n",
    "for x,y,cox, coy, prob in zip(all_points,kpts, coords_x, coords_y, probs):\n",
    "    if x not in kpts:\n",
    "        big_dic.append({x:['no_x','no_y','no_prob']})\n",
    "    else:\n",
    "        big_dic.append({y:[round(cox,2),round(coy,2), prob]})\n",
    "\n",
    "#return(np.array(kpts), np.array(coords_x), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cd3fb9-eace-4c8a-8cfe-92533f7f9d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "huh = str(human_0).replace('BodyPart:', \"\").replace(\"score=\", \"\")\n",
    "huh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cd4379-f08e-4e83-bca3-ca61f4778715",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9748dba6-52ca-47ff-9219-27eb1702f394",
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoint = []\n",
    "for i in range(len(keyp_coord)):\n",
    "    keypoint.append(int(keyp_coord[i][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac5f321-c8e0-44d3-ad5e-b514719d053c",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(human_0).find('score=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793e5199-b284-4567-8d30-4e5a27182511",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json.loads(human_0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
