{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef97fd5-f961-4bbc-8518-b158a73a8c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from pathlib import Path\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import re\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from sorted_alpha import sorted_alpha\n",
    "import imutils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ddf235-c804-4aad-862a-f0b88b3e1c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import video capture\n",
    "cap = cv2.VideoCapture('/Users/andreibirladeanu/Documents/Data/play_videos/1073_play.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b4eb53-cd87-424d-8f47-f8c4c61f41c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.set(1,900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d58b3d-4904-4d92-b33d-3cacb4e0c665",
   "metadata": {},
   "outputs": [],
   "source": [
    "prototxtPath = \"/Users/andreibirladeanu/Documents/Code/PhD_work/openpose_tf/deploy.prototxt.txt\"\n",
    "weightsPath = \"/Users/andreibirladeanu/Documents/Code/PhD_work/openpose_tf/res10_300x300_ssd_iter_140000.caffemodel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953c62f4-9391-458e-8570-247b383b586f",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = cv2.dnn.readNetFromCaffe(prototxtPath , weightsPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41b7e01-0a35-45dc-91cf-7c10b00336bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, image = cap.read()\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1151932-b553-420e-8a28-37cb5cb67fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_img = image.copy()\n",
    "original_size = base_img.shape\n",
    "target_size = (300, 300)\n",
    "image = cv2.resize(image, target_size)\n",
    "aspect_ratio_x = (original_size[1] / target_size[1])\n",
    "aspect_ratio_y = (original_size[0] / target_size[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c76991-d0a2-44f7-bde0-9e8e2db008e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "imageBlob = cv2.dnn.blobFromImage(image = image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a79df4-bb64-4b72-9c34-0fc5bf27031c",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector.setInput(imageBlob)\n",
    "detections = detector.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b142862f-1529-4fa6-8840-aa2111c5e197",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_labels = [\"img_id\", \"is_face\", \"confidence\", \"left\", \"top\", \"right\", \"bottom\"]\n",
    "detections_df = pd.DataFrame(detections[0][0], columns = column_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8b38d6-c46c-4b89-8578-409358544fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "detections_df = detections_df[detections_df['is_face'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57750a9f-394f-4a77-8efe-aef20bdc3e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "detections_df['left'] = (detections_df['left'] * 300).astype(int)\n",
    "detections_df['bottom'] = (detections_df['bottom'] * 300).astype(int)\n",
    "detections_df['right'] = (detections_df['right'] * 300).astype(int)\n",
    "detections_df['top'] = (detections_df['top'] * 300).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5954d3e2-fbc6-454a-b824-ef78923a2185",
   "metadata": {},
   "outputs": [],
   "source": [
    "detections_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f58866-dbfe-4ef6-9b0c-342409fc4f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_faces = []\n",
    "for i, instance in detections_df.iterrows():\n",
    "    confidence_score = str(round(100*instance[\"confidence\"], 2))+\" %\"\n",
    "    left = instance[\"left\"]; right = instance[\"right\"]\n",
    "    bottom = instance[\"bottom\"]; top = instance[\"top\"]\n",
    "    detected_face = base_img[int(top*aspect_ratio_y):int(bottom*aspect_ratio_y) ,\n",
    "    int(left*aspect_ratio_x):int(right*aspect_ratio_x)]\n",
    "    detected_faces.append(detected_face)\n",
    "    print(\"Id \",i,\". Confidence: \", confidence_score)\n",
    "plt.imshow(detected_face[:,:,::-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2da9cd7-ebd7-4c6a-9d3c-86850ec0bf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(detected_faces[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3446882-911c-44f1-b03c-2d7bed28f4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(detected_faces[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dad6f5-313f-4aac-9fee-99d3252a09b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install deepface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d931dc-1b37-4b90-b7bc-ca0cc6d857df",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "# load face detection model\n",
    "mp_face = mp.solutions.face_detection.FaceDetection(\n",
    "    model_selection=1, # model selection\n",
    "    min_detection_confidence=0.1 # confidence threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812be47c-b506-4cf3-ae58-b572c6399078",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_input = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "# get results\n",
    "results = mp_face.process(image_input)\n",
    "\n",
    "if not results.detections:\n",
    "    print('No faces detected.')\n",
    "else:\n",
    "    for detection in results.detections: # iterate over each detection and draw on image\n",
    "        mp_drawing.draw_detection(image, detection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bea0071-20d3-466d-a155-13966cb0bfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepface import DeepFace\n",
    "from retinaface import RetinaFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cb6e4a-d145-452e-b254-decb6afe700a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('img.jpg', image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284bd811-c934-4f40-a454-320f31992314",
   "metadata": {},
   "outputs": [],
   "source": [
    "backends = ['opencv', 'ssd', 'dlib', 'mtcnn', 'retinaface', 'mediapipe']\n",
    "face = DeepFace.detectFace(img_path = \"img.jpg\", target_size = (224, 224), detector_backend = backends[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03d5b73-98e5-44b8-ba13-b8e6095d2680",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8416685-04ec-4f79-814e-25098a420719",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detector = RetinaFace.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83387f69-3342-48ed-82ae-d0363087a4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face(face_detector, img, align = True):\n",
    "\n",
    "    from retinaface import RetinaFace\n",
    "    from retinaface.commons import postprocess\n",
    "\n",
    "    #---------------------------------\n",
    "\n",
    "    resp = []\n",
    "\n",
    "    # The BGR2RGB conversion will be done in the preprocessing step of retinaface.\n",
    "    # img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) #retinaface expects RGB but OpenCV read BGR\n",
    "\n",
    "    \"\"\"\n",
    "    face = None\n",
    "    img_region = [0, 0, img.shape[0], img.shape[1]] #Really?\n",
    "    faces = RetinaFace.extract_faces(img_rgb, model = face_detector, align = align)\n",
    "    if len(faces) > 0:\n",
    "        face = faces[0][:, :, ::-1]\n",
    "    return face, img_region\n",
    "    \"\"\"\n",
    "\n",
    "    #--------------------------\n",
    "\n",
    "    obj = RetinaFace.detect_faces(img, model = face_detector, threshold = 0.9)\n",
    "\n",
    "    if type(obj) == dict:\n",
    "        for key in obj:\n",
    "            identity = obj[key]\n",
    "            facial_area = identity[\"facial_area\"]\n",
    "\n",
    "            y = facial_area[1]\n",
    "            h = facial_area[3] - y\n",
    "            x = facial_area[0]\n",
    "            w = facial_area[2] - x\n",
    "            img_region = [x, y, w, h]\n",
    "\n",
    "            #detected_face = img[int(y):int(y+h), int(x):int(x+w)] #opencv\n",
    "            detected_face = img[facial_area[1]: facial_area[3], facial_area[0]: facial_area[2]]\n",
    "\n",
    "            if align:\n",
    "                landmarks = identity[\"landmarks\"]\n",
    "                left_eye = landmarks[\"left_eye\"]\n",
    "                right_eye = landmarks[\"right_eye\"]\n",
    "                nose = landmarks[\"nose\"]\n",
    "                #mouth_right = landmarks[\"mouth_right\"]\n",
    "                #mouth_left = landmarks[\"mouth_left\"]\n",
    "\n",
    "                detected_face = postprocess.alignment_procedure(detected_face, right_eye, left_eye, nose)\n",
    "\n",
    "            resp.append((detected_face, img_region))\n",
    "\n",
    "    return resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d443afd1-2e37-4e2b-bea0-02d9d76a7959",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anonymize_face_pixelate(image, blocks=3):\n",
    "\t# divide the input image into NxN blocks\n",
    "\t(h, w) = image.shape[:2]\n",
    "\txSteps = np.linspace(0, w, blocks + 1, dtype=\"int\")\n",
    "\tySteps = np.linspace(0, h, blocks + 1, dtype=\"int\")\n",
    "\t# loop over the blocks in both the x and y direction\n",
    "\tfor i in range(1, len(ySteps)):\n",
    "\t\tfor j in range(1, len(xSteps)):\n",
    "\t\t\t# compute the starting and ending (x, y)-coordinates\n",
    "\t\t\t# for the current block\n",
    "\t\t\tstartX = xSteps[j - 1]\n",
    "\t\t\tstartY = ySteps[i - 1]\n",
    "\t\t\tendX = xSteps[j]\n",
    "\t\t\tendY = ySteps[i]\n",
    "\t\t\t# extract the ROI using NumPy array slicing, compute the\n",
    "\t\t\t# mean of the ROI, and then draw a rectangle with the\n",
    "\t\t\t# mean RGB values over the ROI in the original image\n",
    "\t\t\troi = image[startY:endY, startX:endX]\n",
    "\t\t\t(B, G, R) = [int(x) for x in cv2.mean(roi)[:3]]\n",
    "\t\t\tcv2.rectangle(image, (startX, startY), (endX, endY),\n",
    "\t\t\t\t(B, G, R), -1)\n",
    "\t# return the pixelated blurred image\n",
    "\treturn image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b04c180-c33b-4f72-99a3-795b214935cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.CAP_PROP_FPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50375905-6832-4726-8f77-ac3412106731",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('/Users/andreibirladeanu/Documents/Data/play_videos/1073_play.mp4')\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')# note the lower case\n",
    "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH) \n",
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT) \n",
    "out = cv2.VideoWriter('/Users/andreibirladeanu/Documents/Data/1073_play_blurred.mp4', fourcc, 25.0, (int(width),int(height)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68f30b4-afb1-4cab-95e8-4197a059b4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "while (cap.isOpened()):\n",
    "    ret, image = cap.read()\n",
    "    if ret!=True:\n",
    "        break\n",
    "    faces = detect_face(face_detector, image, align=True)\n",
    "    print(cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "    for k in range(len(faces)):\n",
    "        start_x, start_y, end_x, end_y = faces[k][1][0], faces[k][1][1], faces[k][1][0]+faces[k][1][2], faces[k][1][1]+faces[k][1][3]\n",
    "        cropped = image[start_y:end_y, start_x:end_x]\n",
    "        blur = anonymize_face_pixelate(cropped)\n",
    "        image[start_y:end_y, start_x:end_x] = blur\n",
    "    out.write(image)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7982895-2c3e-4e8f-a0f1-65876a922ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd4974e-db01-4538-9b00-84328488dc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(faces)):\n",
    "    print(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b9605a-a636-4f2a-bbab-d5715bed518a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image[199:199+47, 290:290+32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0465bc0-5d40-48b1-b186-a67f2c5ea61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.GaussianBlur(image[199:199+47, 290:290+32], (1,1), 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5472f7fe-eb8b-45ea-aebb-a64a3339c125",
   "metadata": {},
   "outputs": [],
   "source": [
    "face = detect_face(face_detector, image, align = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce443fa1-569d-4a93-8f65-11ef7f5cdefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "face"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
