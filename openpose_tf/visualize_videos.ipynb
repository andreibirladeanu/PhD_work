{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7904b184-908c-41d5-a5f2-439c07fda73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import re\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from sort_alpha import sorted_alpha\n",
    "import random\n",
    "from frame_count import frame_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3de80c3-4083-429d-8a42-a01b988d22da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min_round(array):\n",
    "    array = np.array(array)\n",
    "    x = round(np.min(array[np.nonzero(array)]))\n",
    "    return(x)\n",
    "\n",
    "def find_max_round(array):\n",
    "    array = np.array(array)\n",
    "    x = round(np.max(array))\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045cde08-17a8-414c-bf90-0ee1f35f1bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def torso_size(data):\n",
    "    neck = [data['x'].loc[1], data['y'].loc[1]]\n",
    "    if neck ==0:\n",
    "        return([0])\n",
    "    hip1 = [data['x'].loc[8], data['y'].loc[8]]\n",
    "    hip2 = [data['x'].loc[11], data['y'].loc[11]]\n",
    "    if hip1[0]>0 and hip2[0]>0:\n",
    "        probabilities = [data['p'].loc[8], data['p'].loc[11]]\n",
    "        max_p = np.argmax(probabilities)\n",
    "        if max_p==0:\n",
    "            torso = np.subtract(hip1, neck)\n",
    "        else:\n",
    "            torso = np.subtract(hip2, neck)\n",
    "    elif hip1[0]==0:\n",
    "        torso = np.subtract(hip2, neck)\n",
    "    else:\n",
    "        torso = np.subtract(hip1, neck)\n",
    "    return(torso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1786cb-f6a1-434a-a36c-4067d25d606f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigger_torso(skel1, skel2):\n",
    "    torso1 = torso_size(data)\n",
    "    torso2 = torso_size(data)\n",
    "    return(numpy.linalg.norm(torso1-torso2))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b01e17-ecb5-4f36-8eeb-50fca84660cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_openpose = '/Users/andreibirladeanu/Documents/Data/meal_tracked_exp/1129_meal/'\n",
    "path_video = '/Users/andreibirladeanu/Documents/Data/meal_videos/1129_meal.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74ee539-802e-446d-84a6-7ccfd9c871eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "skel_1 = sorted_alpha(os.path.join(path_openpose, sorted_alpha(path_openpose)[0]))\n",
    "skel_2 = sorted_alpha(os.path.join(path_openpose, sorted_alpha(path_openpose)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e97394-fb96-4f25-a425-6040f1be9a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "skel1 = [int(x.split('.')[0]) for x in skel_1]\n",
    "skel2 = [int(x.split('.')[0]) for x in skel_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e303f7b7-8ff4-4b39-a697-eb7918adf4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_length = frame_count(path_video, manual=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f58f3c-d954-446e-a35b-1e00f5c68499",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_1 = (222, 49, 99)\n",
    "color_2 = (100, 149, 237)\n",
    "thickness = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae68b594-42e1-46fb-94a3-b1e8a583bf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')# note the lower case\n",
    "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH) \n",
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT) \n",
    "out = cv2.VideoWriter('1043_meal_track.mp4', fourcc, 25.0, (int(width),int(height)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2670b43-3fa0-48d7-89b6-65fa8cbb285d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap =  cv2.VideoCapture(path_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6bec49-a86d-479c-b120-3f520af2ec1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "skel_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3101fb0-1eba-4b31-b59e-b79d478a277b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = ['child', 'caregiver']\n",
    "for frame in (range(1,video_length)):\n",
    "    search = np.any([[frame in skel1], [frame in skel2]], axis=1)\n",
    "    print(search)\n",
    "    select = np.where(search ==True)[0]\n",
    "    if len(select) ==2:\n",
    "        print(select)\n",
    "        cap.set(1,frame)\n",
    "        ret, image = cap.read()\n",
    "        data1 = pd.read_csv(os.path.join(path_openpose,path_openpose+sorted_alpha(path_openpose)[0],str(frame)+\".csv\"))\n",
    "        \n",
    "        data2 = pd.read_csv(os.path.join(path_openpose,path_openpose+sorted_alpha(path_openpose)[0],str(frame)+\".csv\"))\n",
    "        rekt = cv2.rectangle(image, (find_min_round(data1['x']), find_min_round(data1['y'])),  \n",
    "                                 (find_max_round(data1['x']), find_max_round(data1['y'])), color_1, thickness)\n",
    "        if bigger_torso(data1, data2) \n",
    "        \n",
    "        cv2.putText(image, , (find_min_round(data['x']), find_min_round(data['y'])-5),  \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (36,255,12), 2)\n",
    "        rek2 = cv2.rectangle(image, (find_min_round(data2['x']), find_min_round(data2['y'])),  \n",
    "                                 (find_max_round(data2['x']), find_max_round(data2['y'])), color_2, thickness)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155e5dd9-9ba7-48f9-a78e-c8aa22dbeff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm([2,3]-[4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13f0e22-486a-418c-a008-f3def82823c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (2,3)\n",
    "b = (4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d216ed14-e1ba-4030-9212-4fbf0f6e72c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(a-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4900ddf-9c34-4dc0-945d-98e99fa5171f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
