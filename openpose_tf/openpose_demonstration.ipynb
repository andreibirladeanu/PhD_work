{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96a3005",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tf_pose import common\n",
    "from tf_pose.estimator import TfPoseEstimator\n",
    "from tf_pose.networks import get_graph_path, model_wh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60de9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_keypoints(image, hum, human=1, color='orange', showBG = True):\n",
    "    if human == 0: human = 1\n",
    "    num_hum = len(hum)\n",
    "    keypoints = str(str(str(hum[human-1]).split('BodyPart:')[1:]).split('-')).split(' score=')\n",
    "    keypoints_list=[]\n",
    "    for i in range (len(keypoints)-1): \n",
    "        pnt = keypoints[i][-11:-1]\n",
    "        pnt = tuple(map(float, pnt.split(', ')))\n",
    "        keypoints_list.append(pnt)\n",
    "\n",
    "    keypts_array = np.array(keypoints_list)\n",
    "    keypts_array = keypts_array*(image.shape[1],image.shape[0])\n",
    "    keypts_array = keypts_array.astype(int)\n",
    "    keypts_array\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.axis([0, image.shape[1], 0, image.shape[0]])  \n",
    "    plt.scatter(*zip(*keypts_array), s=200, color=color, alpha=0.6)\n",
    "    if showBG:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)      \n",
    "    plt.imshow(image)\n",
    "    ax=plt.gca() \n",
    "    ax.set_ylim(ax.get_ylim()[::-1]) \n",
    "    ax.xaxis.tick_top() \n",
    "    plt.title('Keypoints Person [{}] from {} humans detected\\n'.format(human, num_hum))\n",
    "    plt.grid();\n",
    "\n",
    "    for i, txt in enumerate(keypts_array):\n",
    "        ax.annotate(i, (keypts_array[i][0]-5, keypts_array[i][1]+5))\n",
    "            \n",
    "    return keypts_array\n",
    "\n",
    "def get_human_pose(image_path, showBG = True):\n",
    "    image = common.read_imgfile(image_path, None, None)\n",
    "  \n",
    "    if image is None:\n",
    "        logger.error('Image can not be read, path=%s' % image)\n",
    "        sys.exit(-1)\n",
    "\n",
    "    t = time.time()\n",
    "    \n",
    "    humans = e.inference(image, resize_to_default=(w > 0 and h > 0), upsample_size=4.0)\n",
    "    elapsed = time.time() - t\n",
    "\n",
    "    #logger.info('inference image: %s in %.4f seconds.' % (image, elapsed))\n",
    "    if showBG == False:\n",
    "        image = np.zeros(image.shape)\n",
    "    image = TfPoseEstimator.draw_humans(image, humans, imgcopy=False)\n",
    "    return image, humans\n",
    "\n",
    "def show_heatmap(image):\n",
    "    bgimg = cv2.cvtColor(image.astype(np.uint8), cv2.COLOR_BGR2RGB)\n",
    "    bgimg = cv2.resize(bgimg, (e.heatMat.shape[1], e.heatMat.shape[0]), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plt.imshow(bgimg, alpha=0.5)\n",
    "    tmp = np.amax(e.heatMat[:, :, :-1], axis=2)\n",
    "    plt.imshow(tmp, cmap=plt.cm.gray, alpha=0.5)\n",
    "    plt.colorbar()\n",
    "    plt.axis('off');\n",
    "    \n",
    "def show_vectormaps(image):\n",
    "    tmp2 = e.pafMat.transpose((2, 0, 1))\n",
    "    tmp2_odd = np.amax(np.absolute(tmp2[::2, :, :]), axis=0)\n",
    "    tmp2_even = np.amax(np.absolute(tmp2[1::2, :, :]), axis=0)\n",
    "    \n",
    "    fig = plt.figure(figsize=(20,15))\n",
    "\n",
    "    a = fig.add_subplot(2, 2, 3)\n",
    "    a.set_title('Vectormap-x')\n",
    "    # plt.imshow(CocoPose.get_bgimg(inp, target_size=(vectmap.shape[1], vectmap.shape[0])), alpha=0.5)\n",
    "    plt.imshow(tmp2_odd, cmap=plt.cm.gray, alpha=0.5)\n",
    "    plt.colorbar()\n",
    "\n",
    "    a = fig.add_subplot(2, 2, 4)\n",
    "    a.set_title('Vectormap-y')\n",
    "    # plt.imshow(CocoPose.get_bgimg(inp, target_size=(vectmap.shape[1], vectmap.shape[0])), alpha=0.5)\n",
    "    plt.imshow(tmp2_even, cmap=plt.cm.gray, alpha=0.5)\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf964d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '/Users/andreibirladeanu/Documents/Data/frames/2009_meal.png'\n",
    "image = cv2.imread(image_path)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(image)\n",
    "plt.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb86591",
   "metadata": {},
   "outputs": [],
   "source": [
    "image=common.read_imgfile('/Users/andreibirladeanu/Documents/Data/frames/2009_meal.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438b0839",
   "metadata": {},
   "outputs": [],
   "source": [
    "model='mobilenet_v2_large'\n",
    "resize='480x432'\n",
    "w, h = model_wh(resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0030a9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = TfPoseEstimator(get_graph_path(model), target_size=(w, h))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be543adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "humans = e.inference(image, resize_to_default=(w > 0 and h > 0), upsample_size=4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a04d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_prob = np.amax(e.heatMat[:, :, :-1], axis=2)\n",
    "plt.imshow(max_prob)\n",
    "plt.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd22579",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = TfPoseEstimator.draw_humans(image, humans, imgcopy=False)\n",
    "plt.imshow(image)\n",
    "plt.savefig('image.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5593647",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = common.read_imgfile(image_path, None, None)\n",
    "humans = e.inference(image, resize_to_default=(w > 0 and h > 0), upsample_size=4.0)\n",
    "black_background = np.zeros(image.shape)\n",
    "skeleton = TfPoseEstimator.draw_humans(black_background, humans, imgcopy=False)\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.imshow(skeleton)\n",
    "plt.grid()\n",
    "plt.axis('off')\n",
    "plt.savefig('skeleton.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e46111d",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_keypoints(image, humans, human=1)\n",
    "#show_keypoints(image, humans, human=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b690bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, hum = get_human_pose(image_path, showBG=False)\n",
    "keypoints = show_keypoints(img, hum, human=1 ,color='white', showBG=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac9ecf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c030e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "humans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef4f7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_heatmap(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5e0da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(humans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c260883",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "bgimg = cv2.cvtColor(image.astype(np.uint8), cv2.COLOR_BGR2RGB)\n",
    "bgimg = cv2.resize(bgimg, (e.heatMat.shape[1], e.heatMat.shape[0]), interpolation=cv2.INTER_AREA)\n",
    "plt.imshow(bgimg, alpha=0.5)\n",
    "plt.imshow(max_prob, alpha=0.5)\n",
    "plt.colorbar()\n",
    "plt.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1048579b",
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoints = str(str(str(humans[0]).split('BodyPart:')[1:]).split('-')).split(' score=')\n",
    "len(keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02602277",
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoints_list=[]\n",
    "for i in range (len(keypoints)-1): \n",
    "    pnt = keypoints[i][-11:-1]\n",
    "    pnt = tuple(map(float, pnt.split(', ')))\n",
    "    keypoints_list.append(pnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9765e90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "keypts_array = np.array(keypoints_list)\n",
    "keypts_array = keypts_array*(image.shape[1],image.shape[0])\n",
    "keypts_array = keypts_array.astype(int)\n",
    "keypts_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7f2fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.axis([0, image.shape[1], 0, image.shape[0]])  \n",
    "plt.scatter(*zip(*keypts_array))\n",
    "ax=plt.gca() \n",
    "ax.set_ylim(ax.get_ylim()[::-1]) \n",
    "ax.xaxis.tick_top() \n",
    "plt.grid();\n",
    "plt.savefig('keypoints_adult.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd345fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model='cmu'\n",
    "resize='432x368'\n",
    "w, h = model_wh(resize)\n",
    "e = TfPoseEstimator(get_graph_path(model), target_size=(w, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131c85d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = '/Users/andreibirladeanu/Documents/Data/Meal/2009_meal.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if cap.isOpened() is False:\n",
    "    print(\"Error opening video stream or file\")\n",
    "while True:\n",
    "    ret_val, image = cap.read()\n",
    "    #cv2.imshow('image', image)\n",
    "    #cv2.waitKey(0)\n",
    "\n",
    "    humans = e.inference(image,\n",
    "                         resize_to_default=(w > 0 and h > 0),\n",
    "                         upsample_size=4.0)\n",
    "    #print(len(humans))\n",
    "    if not showBG:\n",
    "        image = np.zeros(image.shape)\n",
    "    image = TfPoseEstimator.draw_humans(image, humans, imgcopy=False)\n",
    "\n",
    "    cv2.putText(image, \"FPS: %f\" % (1.0 / (time.time() - fps_time)), (10, 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    cv2.imshow('tf-pose-estimation result', image)\n",
    "    fps_time = time.time()\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
