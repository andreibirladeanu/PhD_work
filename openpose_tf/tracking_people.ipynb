{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25e836a4-000a-4a47-86e5-e69de6ae8bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import re\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from pathlib import Path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cccb50a-e336-468b-96cf-80dc8fa17948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorted_alphanumeric(data):\n",
    "    convert = lambda text: int(text) if text.isdigit() else text.lower()\n",
    "    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ] \n",
    "    return sorted(data, key=alphanum_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c5db1f-2870-4028-8be3-2ad77f4abd6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee2da97c-1ad8-4191-979e-dad31978d608",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_neighbour(new_skeleton, various_skeletons):\n",
    "    joint=1\n",
    "    neigh.fit([[new_skeleton[-1][0][joint],  new_skeleton[-1][1][joint]]])\n",
    "    if len(various_skeletons) ==1:\n",
    "        dist, nn = neigh.kneighbors([[list(various_skeletons.values())[0][0][joint], list(various_skeletons.values())[0][1][joint]]], \n",
    "                                        return_distance = True)\n",
    "        return([dist])\n",
    "    elif len(various_skeletons)==2:\n",
    "        dist1, nn = neigh.kneighbors([[list(various_skeletons.values())[0][0][joint], list(various_skeletons.values())[0][1][joint]]], \n",
    "                                        return_distance = True)\n",
    "        dist2, nn = neigh.kneighbors([[list(various_skeletons.values())[1][0][joint], list(various_skeletons.values())[1][1][joint]]], \n",
    "                                        return_distance = True)\n",
    "        return([dist1, dist2])\n",
    "    elif len(various_skeletons) ==3:\n",
    "        dist1, nn = neigh.kneighbors([[list(various_skeletons.values())[0][0][joint], list(various_skeletons.values())[0][1][joint]]], \n",
    "                                        return_distance = True)\n",
    "        dist2, nn = neigh.kneighbors([[list(various_skeletons.values())[1][0][joint], list(various_skeletons.values())[1][1][joint]]], \n",
    "                                        return_distance = True)\n",
    "        dist3, nn = neigh.kneighbors([[list(various_skeletons.values())[2][0][joint], list(various_skeletons.values())[2][1][joint]]], \n",
    "                                        return_distance = True)\n",
    "        return([dist1,dist2,dist3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62b77d55-364a-4e58-b015-873ffbde6235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_missing(skeletons):\n",
    "    \"\"\"if value is missing then it returns True\"\"\"\n",
    "    temp_list = []\n",
    "    for key,value in skeletons.items():\n",
    "        \n",
    "        if value[0][1] ==0:\n",
    "            temp_list.append(True)\n",
    "        else:\n",
    "            temp_list.append(False)\n",
    "    return(np.all(temp_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec12e7e7-9eb5-4cc2-a6a5-8667ddea23c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "openpose_path = '/Users/andreibirladeanu/Documents/Data/meal_openpose/1043_meal/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d5a301c-56f3-466c-8dcc-2a45d9d97bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "poses = [x for x in sorted_alphanumeric(os.listdir(openpose_path))]\n",
    "#poses = [int(x.split('.')[0].split(\"_\")[1]) for x in poses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a57f628e-946e-4c6f-86d7-b177543dbafd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " ...]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_no = []\n",
    "for frame in sorted_alphanumeric(os.listdir(openpose_path)):\n",
    "    data = pd.read_csv(openpose_path + frame)\n",
    "       # print(len(data.columns)-1)\n",
    "    human_no.append((len(data.columns)-1)/3)\n",
    "human_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "769f802f-61a9-43dd-817b-b2ee2fbba48d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_no.count(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4810db1e-2e0b-4489-bfef-32981b6c6aee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## frames\n",
    "def return_frames(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    count = 0\n",
    "    while(cap.isOpened()):\n",
    "            ret_val, image = cap.read()\n",
    "            if ret_val == False:\n",
    "                break\n",
    "            if count> 100 and count <200:\n",
    "                frames.append(image)\n",
    "            count = count+1\n",
    "                \n",
    "    return (frames)\n",
    "frames = return_frames('/Users/andreibirladeanu/Documents/Data/meal_videos/1043_meal.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b814406f-d180-4299-bc90-7f606a5ae5b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('/Users/andreibirladeanu/Documents/Data/meal_videos/1043_meal.mp4')\n",
    "count = 0\n",
    "while(cap.isOpened()):\n",
    "    ret_val, image = cap.read()\n",
    "    if ret_val == False:\n",
    "                break\n",
    "    count += 1\n",
    "    if count in frames_3:\n",
    "        cv2.imshow('human', image[round(np.nanmin(new_skeleton3[count][0])):round(np.nanmax(new_skeleton3[count][0])),\n",
    "                       round(np.nanmin(new_skeleton3[count][1])):round(np.nanmax(new_skeleton3[count][1]))])\n",
    "        cv2.waitKey(0)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be4d18ce-31ef-4dae-8fbe-791385f19494",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 48, saw 12\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/02/tbtgqj615xgfmzqw5gqf0mm80000gn/T/ipykernel_31079/3268104538.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mskeletons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted_alphanumeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopenpose_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopenpose_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m3\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/openpose/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/openpose/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/openpose/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/openpose/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/openpose/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/openpose/lib/python3.7/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/openpose/lib/python3.7/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/openpose/lib/python3.7/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/openpose/lib/python3.7/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 48, saw 12\n"
     ]
    }
   ],
   "source": [
    "skeletons = []\n",
    "for frame in sorted_alphanumeric(os.listdir(openpose_path)):\n",
    "    data = pd.read_csv(openpose_path + frame, encoding='latin1')\n",
    "    data = data.fillna(0)\n",
    "    if (len(data.columns)-1)/3 == 1:\n",
    "        skeletons.append({'skeleton1':[np.array(data['x_1']), np.array(data['y_1']), np.array(data['prob_1'])]})\n",
    "    elif (len(data.columns)-1)/3 == 2:\n",
    "        skeletons.append({'skeleton1':[np.array(data['x_1']), np.array(data['y_1']),  np.array(data['prob_1'])],'skeleton2':[np.array(data['x_2']), np.array(data['y_2']),\n",
    "                                                                                                                             np.array(data['prob_2'])]})\n",
    "    elif (len(data.columns)-1)/3 == 3:\n",
    "        skeletons.append({'skeleton1':[np.array(data['x_1']), np.array(data['y_1']),  np.array(data['prob_1'])],'skeleton2':[np.array(data['x_2']), np.array(data['y_2']),\n",
    "                             np.array(data['prob_2'])],\n",
    "                          'skeleton3':[np.array(data['x_3']), np.array(data['y_3']),  np.array(data['prob_3'])]})                                  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7f034ac-a952-47d3-bc73-802db7837887",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(skeletons)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d9c6e97d-948a-4240-9934-e0960860976b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_skeletons1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/02/tbtgqj615xgfmzqw5gqf0mm80000gn/T/ipykernel_19849/2300379143.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_skeletons1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'new_skeletons1' is not defined"
     ]
    }
   ],
   "source": [
    "new_skeletons1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e01598b-0042-4170-a05d-c5b528e50d36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "neigh = NearestNeighbors(n_neighbors=1, algorithm = 'brute', metric='euclidean')\n",
    "new_skeleton1 = []\n",
    "new_skeleton2 = []\n",
    "hooman1 = []\n",
    "counter=0\n",
    "hooman2_frames = []\n",
    "for i in range(len(skeletons)): \n",
    "    if i == 0 and len(skeletons[i])==1:   # we start in the case where only one skeleton is available\n",
    "        new_skeleton1.append(skeletons[i]['skeleton1'])\n",
    "        continue\n",
    "    if i==0 and len(skeletons[i])==2: ## if both skeletons are available \n",
    "        new_skeleton1.append(skeletons[i]['skeleton1'])\n",
    "        new_skeleton2.append(skeletons[i]['skeleton2'])\n",
    "        hooman2_frames.append(i)\n",
    "        continue\n",
    "    ## the first frame will meet either of these 2 conditions above and then loop will carry on to the next frame\n",
    "    if len(skeletons[i])==1 and len(skeletons[i-1])==1:\n",
    "        neigh.fit([[new_skeleton1[-1][0][1],  new_skeleton1[-1][1][1]]])\n",
    "        dist, nn = neigh.kneighbors([[skeletons[i]['skeleton1'][0][1],  skeletons[i]['skeleton1'][1][1]]], \n",
    "                                    return_distance = True)\n",
    "        if dist[0][0] < 10:\n",
    "            new_skeleton1.append(skeletons[i]['skeleton1'])\n",
    "\n",
    "\n",
    "    if len(skeletons[i])==2 and len(skeletons[i-1])==1:\n",
    "        neigh.fit([[new_skeleton1[-1][0][1], new_skeleton1[-1][1][1]]])\n",
    "        dist_1, nn_1 = neigh.kneighbors([[skeletons[i]['skeleton1'][0][1],  skeletons[i]['skeleton1'][1][1]]], \n",
    "                                    return_distance = True)\n",
    "        dist_2, nn_2 =  neigh.kneighbors([[skeletons[i]['skeleton2'][0][1],  skeletons[i]['skeleton2'][1][1]]], \n",
    "                                    return_distance = True)\n",
    "\n",
    "        if dist_1 < dist_2 and dist_1 <10:\n",
    "            new_skeleton1.append(skeletons[i]['skeleton1'])\n",
    "            new_skeleton2.append(skeletons[i]['skeleton2'])\n",
    "            hooman2_frames.append(i)\n",
    "        elif dist_2 < dist_1 and dist_2 <10:\n",
    "            new_skeleton1.append(skeletons[i]['skeleton2'])\n",
    "            new_skeleton2.append(skeletons[i]['skeleton1'])\n",
    "            hooman2_frames.append(i)\n",
    "\n",
    "\n",
    "\n",
    "    if len(skeletons[i])==1 and len(skeletons[i-1])==2:\n",
    "        neigh.fit([[new_skeleton1[-1][0][1], new_skeleton1[-1][1][1]], \n",
    "                [new_skeleton2[-1][0][1], new_skeleton2[-1][1][1]]])\n",
    "        dist, nn = neigh.kneighbors([[skeletons[i]['skeleton1'][0][1],  skeletons[i]['skeleton1'][1][1]]], \n",
    "                                    return_distance = True)\n",
    "        if nn[0][0] ==0 and dist[0][0] < 10:\n",
    "            new_skeleton1.append(skeletons[i]['skeleton1'])\n",
    "        elif nn[0][0] ==1 and dist[0][0] < 10:\n",
    "            new_skeleton2.append(skeletons[i]['skeleton1'])\n",
    "\n",
    "\n",
    "    if len(skeletons[i])==2 and len(skeletons[i-1])==2:\n",
    "        neigh.fit([[new_skeleton1[-1][0][1], new_skeleton1[-1][1][1]], \n",
    "                [new_skeleton2[-1][0][1], new_skeleton2[-1][1][1]]])\n",
    "    \n",
    "        \n",
    "        dist_1, nn_1 = neigh.kneighbors([[skeletons[i]['skeleton1'][0][1],  skeletons[i]['skeleton1'][1][1]]], \n",
    "                                    n_neighbors=1, return_distance = True)\n",
    "  \n",
    "        dist_2, nn_2 = neigh.kneighbors([[skeletons[i]['skeleton2'][0][1],  skeletons[i]['skeleton2'][1][1]]], \n",
    "                                    return_distance = True)\n",
    "\n",
    "        if nn_1[0][0] == 0 and dist_1[0][0] < 15:\n",
    "            new_skeleton1.append(skeletons[i]['skeleton1'])\n",
    "            if dist_2[0][0] <15: ## making sure the other person hasn't suddenly switched to something/someone else\n",
    "                new_skeleton2.append(skeletons[i]['skeleton2'])\n",
    "                hooman2_frames.append(i)\n",
    "        elif nn_1[0][0] == 1 and dist_1[0][0] < 15:\n",
    "            new_skeleton2.append(skeletons[i]['skeleton1'])\n",
    "            if dist_2[0][0] <15:\n",
    "                new_skeleton1.append(skeletons[i]['skeleton2'])\n",
    "                hooman2_frames.append(i)\n",
    "        else:\n",
    "            print(\"2 and 2\", i)\n",
    "\n",
    "    counter +=1\n",
    "\n",
    "    #hooman1.append(frames[i][round(np.nanmin(new_skeleton1[i][1])):round(np.nanmax(new_skeleton1[i][1])),\n",
    "     #                   round(np.nanmin(new_skeleton1[i][0])):round(np.nanmax(new_skeleton1[i][0]))])            \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73af17f7-c392-4f54-b9e9-6e58d97cd3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for hooman in hooman1:\n",
    "    cv2.imshow('human1', hooman)\n",
    "    cv2.waitKey(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddf9181-07a6-479b-8b62-0bd9ce2b1aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hooman2=[]\n",
    "for ind, skel in zip(hooman2_frames, new_skeleton2):\n",
    "    hooman2.append(frames[ind][round(np.nanmin(skel[1])):round(np.nanmax(skel[1])),\n",
    "                        round(np.nanmin(skel[0])):round(np.nanmax(skel[0]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd85bcea-e3c3-4d14-aa1b-9048ab241c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "for hooman in hooman2:\n",
    "    cv2.imshow('human2', hooman)\n",
    "    cv2.waitKey(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bc0c7a-7c3c-4526-b533-1bd1b2c3f9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae221e1d-3c13-4fef-b355-14f14d5407f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## saving output\n",
    "output_path = '/Users/andrei-macpro/Documents/Data/1042_meal_skeletons/child/'\n",
    "for hooman in range(len(hooman2)):\n",
    "    cv2.imwrite(output_path + 'frame '+ str(hooman)+'.png', hooman2[hooman])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a866ba-3dc1-46b6-b2d3-39729652a13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_skeleton1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eb8c9e-6277-45c6-80d7-4a383ee0cda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## pop it out? \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdf3cdf-e2c2-4e7d-bed3-93ffb0b4d2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "skeletons[0]['skeleton1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b61379fe-9bdf-478d-83d9-7c9298cd4dc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### new pop rule\n",
    "### extracting Skeleton 1\n",
    "\n",
    "neigh = NearestNeighbors(n_neighbors=1, algorithm = 'brute', metric='euclidean')\n",
    "new_skeleton1 = []\n",
    "hooman1 = []\n",
    "counter=0\n",
    "hooman2_frames = []\n",
    "main_kpt = 1\n",
    "fallback = 0\n",
    "frames_1=[]\n",
    "for i in range(len(skeletons)): \n",
    "        if i==0:\n",
    "            new_skeleton1.append(skeletons[i]['skeleton1'])\n",
    "            frames_1.append(i+1)\n",
    "            skeletons[i].pop('skeleton1')\n",
    "            continue\n",
    "        if len(skeletons[i])==1:\n",
    "            if new_skeleton1[-1][0][main_kpt] and new_skeleton1[-1][1][main_kpt] and \\\n",
    "                skeletons[i]['skeleton1'][0][main_kpt] and  skeletons[i]['skeleton1'][1][main_kpt] > 0.0:\n",
    "                neigh.fit([[new_skeleton1[-1][0][main_kpt],  new_skeleton1[-1][1][main_kpt]]])\n",
    "                neigh.fit([[new_skeleton1[-1][0][main_kpt],  new_skeleton1[-1][1][main_kpt]]])\n",
    "                dist, nn = neigh.kneighbors([[skeletons[i]['skeleton1'][0][main_kpt],  skeletons[i]['skeleton1'][1][main_kpt]]], \n",
    "                                        return_distance = True)\n",
    "                \n",
    "                if dist[0][0] < 50:\n",
    "                    new_skeleton1.append(skeletons[i]['skeleton1'])\n",
    "                    frames_1.append(i+1)\n",
    "                    skeletons[i].pop('skeleton1')\n",
    "            else:\n",
    "                neigh.fit([[new_skeleton1[-1][0][fallback],  new_skeleton1[-1][1][fallback]]])\n",
    "                neigh.fit([[new_skeleton1[-1][0][fallback],  new_skeleton1[-1][1][fallback]]])\n",
    "                dist, nn = neigh.kneighbors([[skeletons[i]['skeleton1'][0][fallback],  skeletons[i]['skeleton1'][1][fallback]]], \n",
    "                                        return_distance = True)\n",
    "                \n",
    "                if dist[0][0] < 50:\n",
    "                    new_skeleton1.append(skeletons[i]['skeleton1'])\n",
    "                    frames_1.append(i+1)\n",
    "                    skeletons[i].pop('skeleton1')\n",
    "            \n",
    "        elif len(skeletons[i])==2:\n",
    "            if new_skeleton1[-1][0][main_kpt] and new_skeleton1[-1][1][main_kpt] and \\\n",
    "           skeletons[i]['skeleton1'][0][main_kpt] and  skeletons[i]['skeleton1'][1][main_kpt] and \\\n",
    "           skeletons[i]['skeleton2'][0][main_kpt] and  skeletons[i]['skeleton2'][1][main_kpt]> 0.0:\n",
    "            \n",
    "                neigh.fit([[new_skeleton1[-1][0][main_kpt],  new_skeleton1[-1][1][main_kpt]]])\n",
    "                dist_0, nn_0 = neigh.kneighbors([[skeletons[i]['skeleton1'][0][main_kpt],  skeletons[i]['skeleton1'][1][main_kpt]]], \n",
    "                                        return_distance = True)\n",
    "                dist_1, nn_1 = neigh.kneighbors([[skeletons[i]['skeleton2'][0][main_kpt],  skeletons[i]['skeleton2'][1][main_kpt]]], \n",
    "                                        return_distance = True)\n",
    "                if dist_0 < dist_1 and dist_0 <50:\n",
    "                    new_skeleton1.append(skeletons[i]['skeleton1'])\n",
    "                    frames_1.append(i+1)\n",
    "                    skeletons[i].pop('skeleton1')\n",
    "                elif dist_0 > dist_1 and dist_1 <50:\n",
    "                    new_skeleton1.append(skeletons[i]['skeleton2'])\n",
    "                    frames_1.append(i+1)\n",
    "                    skeletons[i].pop('skeleton2')\n",
    "            else:\n",
    "                neigh.fit([[new_skeleton1[-1][0][fallback],  new_skeleton1[-1][1][fallback]]])\n",
    "                dist_0, nn_0 = neigh.kneighbors([[skeletons[i]['skeleton1'][0][fallback],  skeletons[i]['skeleton1'][1][fallback]]], \n",
    "                                        return_distance = True)\n",
    "                dist_1, nn_1 = neigh.kneighbors([[skeletons[i]['skeleton2'][0][fallback],  skeletons[i]['skeleton2'][1][fallback]]], \n",
    "                                        return_distance = True)\n",
    "                if dist_0 < dist_1 and dist_0 <50:\n",
    "                    new_skeleton1.append(skeletons[i]['skeleton1'])\n",
    "                    frames_1.append(i+1)\n",
    "                    skeletons[i].pop('skeleton1')\n",
    "                elif dist_0 > dist_1 and dist_1 <50:\n",
    "                    new_skeleton1.append(skeletons[i]['skeleton2'])\n",
    "                    frames_1.append(i+1)\n",
    "                    skeletons[i].pop('skeleton2')\n",
    "        \n",
    "    \n",
    "     \n",
    "        elif len(skeletons[i])==3:\n",
    "            if new_skeleton1[-1][0][main_kpt] and new_skeleton1[-1][1][main_kpt] and \\\n",
    "           skeletons[i]['skeleton1'][0][main_kpt] and  skeletons[i]['skeleton1'][1][main_kpt] and \\\n",
    "           skeletons[i]['skeleton2'][0][main_kpt] and  skeletons[i]['skeleton2'][1][main_kpt] and \\\n",
    "            skeletons[i]['skeleton3'][0][main_kpt] and  skeletons[i]['skeleton3'][1][main_kpt] > 0.0:\n",
    "                neigh.fit([[new_skeleton1[-1][0][main_kpt],  new_skeleton1[-1][1][main_kpt]]])\n",
    "                dist_0, nn_0 = neigh.kneighbors([[skeletons[i]['skeleton1'][0][main_kpt],  skeletons[i]['skeleton1'][1][main_kpt]]], \n",
    "                                        return_distance = True)\n",
    "                dist_1, nn_1 = neigh.kneighbors([[skeletons[i]['skeleton2'][0][main_kpt],  skeletons[i]['skeleton2'][1][main_kpt]]], \n",
    "                                        return_distance = True)\n",
    "                dist_2, nn_2 = neigh.kneighbors([[skeletons[i]['skeleton3'][0][main_kpt],  skeletons[i]['skeleton3'][1][main_kpt]]], \n",
    "                                        return_distance = True)\n",
    "                if dist_0 < dist_1 < dist_2 and dist_0<50:\n",
    "                    new_skeleton1.append(skeletons[i]['skeleton1'])\n",
    "                    frames_1.append(i+1)\n",
    "                    skeletons[i].pop('skeleton1')\n",
    "                elif dist_1 < dist_0 < dist_2 and dist_1<50:\n",
    "                    new_skeleton1.append(skeletons[i]['skeleton2'])\n",
    "                    frames_1.append(i+1)\n",
    "                    skeletons[i].pop('skeleton2')\n",
    "                elif dist_2 < dist_1 < dist_0 and dist_2<50:\n",
    "                    new_skeleton1.append(skeletons[i]['skeleton3'])\n",
    "                    frames_1.append(i+1)\n",
    "                    skeletons[i].pop('skeleton3')\n",
    "            else:\n",
    "                neigh.fit([[new_skeleton1[-1][0][fallback],  new_skeleton1[-1][1][fallback]]])\n",
    "                dist_0, nn_0 = neigh.kneighbors([[skeletons[i]['skeleton1'][0][fallback],  skeletons[i]['skeleton1'][1][fallback]]], \n",
    "                                        return_distance = True)\n",
    "                dist_1, nn_1 = neigh.kneighbors([[skeletons[i]['skeleton2'][0][fallback],  skeletons[i]['skeleton2'][1][fallback]]], \n",
    "                                        return_distance = True)\n",
    "                dist_2, nn_2 = neigh.kneighbors([[skeletons[i]['skeleton3'][0][fallback],  skeletons[i]['skeleton3'][1][fallback]]], \n",
    "                                        return_distance = True)\n",
    "                if dist_0 < dist_1 < dist_2 and dist_0<50:\n",
    "                    new_skeleton1.append(skeletons[i]['skeleton1'])\n",
    "                    frames_1.append(i+1)\n",
    "                    skeletons[i].pop('skeleton1')\n",
    "                elif dist_1 < dist_0 < dist_2 and dist_1<50:\n",
    "                    new_skeleton1.append(skeletons[i]['skeleton2'])\n",
    "                    frames_1.append(i+1)\n",
    "                    skeletons[i].pop('skeleton2')\n",
    "                elif dist_2 < dist_1 < dist_0 and dist_2<50:\n",
    "                    new_skeleton1.append(skeletons[i]['skeleton3'])\n",
    "                    frames_1.append(i+1)\n",
    "                    skeletons[i].pop('skeleton3')\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e4129bb-cbcc-4480-b25e-c330e30fce51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23892"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_skeleton1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db0527f3-417a-4263-b56b-94fb89e3d5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### new pop rule\n",
    "## extracting skeleton 2\n",
    "\n",
    "neigh = NearestNeighbors(n_neighbors=1, algorithm = 'brute', metric='euclidean')\n",
    "new_skeleton2 = []\n",
    "hooman1 = []\n",
    "counter=0\n",
    "frames_2 = []\n",
    "for i in range(len(skeletons)): \n",
    "    if skeletons[i] == {}:\n",
    "        continue\n",
    "    if len(skeletons[i])==1:\n",
    "        new_skeleton2.append(list(skeletons[i].items())[0][1])\n",
    "        frames_2.append(i+1)\n",
    "        if list(skeletons[i].items())[0][0] == 'skeleton2':\n",
    "            skeletons[i].pop('skeleton2')\n",
    "        else:\n",
    "            skeletons[i].pop('skeleton1')\n",
    "\n",
    "    elif len(skeletons[i])==2 and len(skeletons[i-1])==1:\n",
    "        if new_skeleton2[-1][0][main_kpt] and new_skeleton2[-1][1][main_kpt] and \\\n",
    "         skeletons[i][0][1][0][main_kpt] and skeletons[i][0][1][1][main_kpt] and \\\n",
    "         skeletons[i][1][1][0][main_kpt] and skeletons[i][1][1][1][main_kpt] > 0.0:\n",
    "            neigh.fit([[new_skeleton2[-1][0][main_kpt],  new_skeleton2[-1][1][main_kpt]]])\n",
    "            dist_0, nn_0 = neigh.kneighbors([[skeletons[i][0][1][0][main_kpt],  skeletons[i][0][1][1][main_kpt]]], \n",
    "                                    return_distance = True)\n",
    "            dist_1, nn_1 = neigh.kneighbors([[skeletons[i][1][1][0][main_kpt],  skeletons[i][1][1][1][main_kpt]]], \n",
    "                                    return_distance = True)\n",
    "            if dist_0 < dist_1 and dist_0 <50:\n",
    "                new_skeleton2.append(list(skeletons[i].items())[0][1])\n",
    "                frames_2.append(i+1)\n",
    "                if list(skeletons[i].items())[0][0] == 'skeleton2':\n",
    "                    skeletons[i].pop('skeleton2')\n",
    "                else:\n",
    "                    skeletons[i].pop('skeleton1')\n",
    "            elif dist_0 > dist_1 and dist_1 <50:\n",
    "                new_skeleton2.append(list(skeletons[i].items())[1][1])\n",
    "                frames_2.append(i+1)\n",
    "                if list(skeletons[i].items())[0][0] == 'skeleton2':\n",
    "                    skeletons[i].pop('skeleton2')\n",
    "                else:\n",
    "                    skeletons[i].pop('skeleton1')\n",
    "        else: \n",
    "            neigh.fit([[new_skeleton2[-1][0][fallback],  new_skeleton2[-1][1][fallback]]])\n",
    "            dist_0, nn_0 = neigh.kneighbors([[skeletons[i][0][1][0][fallback],  skeletons[i][0][1][1][fallback]]], \n",
    "                                    return_distance = True)\n",
    "            dist_1, nn_1 = neigh.kneighbors([[skeletons[i][1][1][0][fallback],  skeletons[i][1][1][1][fallback]]], \n",
    "                                    return_distance = True)\n",
    "            if dist_0 < dist_1 and dist_0 <50:\n",
    "                new_skeleton2.append(list(skeletons[i].items())[0][1])\n",
    "                frames_2.append(i+1)\n",
    "                if list(skeletons[i].items())[0][0] == 'skeleton2':\n",
    "                    skeletons[i].pop('skeleton2')\n",
    "                else:\n",
    "                    skeletons[i].pop('skeleton1')\n",
    "            elif dist_0 > dist_1 and dist_1 <50:\n",
    "                new_skeleton2.append(list(skeletons[i].items())[1][1])\n",
    "                frames_2.append(i+1)\n",
    "                if list(skeletons[i].items())[0][0] == 'skeleton2':\n",
    "                    skeletons[i].pop('skeleton2')\n",
    "                else:\n",
    "                    skeletons[i].pop('skeleton1')\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b39ae957-d970-4c37-9ffe-cd3a43c4f072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skel 3 is what should be left \n",
    "new_skeleton3 = []\n",
    "hooman1 = []\n",
    "counter=0\n",
    "frames_3 = []\n",
    "for i in range(len(skeletons)): \n",
    "    if skeletons[i] == {}:\n",
    "        continue\n",
    "    if len(skeletons[i]) != {}:\n",
    "        new_skeleton3.append(list(skeletons[i].items())[0][1])\n",
    "        frames_3.append(i-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36338e9c-daa4-4b5d-a2ef-4263599a9b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_skeleton3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fef2640b-9e50-4699-8ab7-96ddad9284d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24148"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(skeletons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc345339-02fa-4ea1-aa8b-76e641f87626",
   "metadata": {},
   "outputs": [],
   "source": [
    "skeletons[20].keys() == 'skeleton2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f20690-6f11-462e-afae-137ca7e348fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "skeletons[20].keys() == (['skeleton2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5e721f-4606-4ab0-bdd1-1c0dcd238ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(skeletons[20].items())[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea087a30-650c-46d4-9ad9-72295144a947",
   "metadata": {},
   "outputs": [],
   "source": [
    "skeletons[20][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7eb59fc-2db7-4df1-b13d-b6de9e2ef654",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('test.csv', np.transpose(new_skeleton1[0]), delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a933a5-a878-4e74-8149-26764d5552b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_skeleton1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c2f1f7-1c8d-471b-9bf4-f94a4e4ff772",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save skeleton to separate csv \n",
    "for skeleton, frame in zip(new_skeletonx, frames_x):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bee12926-a413-4659-acbd-cd5b34c03e6a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_skeleton1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/02/tbtgqj615xgfmzqw5gqf0mm80000gn/T/ipykernel_7534/391102930.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_skeleton1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'p'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'new_skeleton1' is not defined"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(np.transpose(new_skeleton1[0]),  columns=['x', 'y', 'p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba471a9c-a2a0-4710-8a86-3cedededdd1a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_skeleton1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/02/tbtgqj615xgfmzqw5gqf0mm80000gn/T/ipykernel_7534/513146932.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_skeleton1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'new_skeleton1' is not defined"
     ]
    }
   ],
   "source": [
    "np.transpose(new_skeleton1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b19c5dd8-4cfb-4b5d-bd69-7aca354e0393",
   "metadata": {},
   "outputs": [],
   "source": [
    "### from here it starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bda2f847-cf75-4155-a4da-69df06eb7a4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1043_meal', '1047_meal', '1049_meal', '1049_meal_1', '1053_meal', '1059_meal', '1059_meal_1', '1062_meal', '1069_meal', '1073_meal', '1073_meal_1', '1079_meal', '1079_meal_1', '1080_meal', '1082_meal', '1082_meal_1', '1089_meal', '1089_meal_1', '1089_meal_2', '1091_meal', '1092_meal', '1093_meal', '1097_meal', '1099_meal', '1104_meal', '1104_meal_1', '1105_meal', '1107_meal', '1108_meal', '1108_meal_1', '1108_meal_2', '1112_meal', '1112_meal_1', '1112_meal_2', '1117_meal', '1118_meal', '1118_meal_1', '1122_meal', '1124_meal', '1125_meal', '1129_meal', '1130_meal', '1131_meal', '1132_meal', '1148_meal', '1161_meal', '1161_meal_1', '1170_meal', '1180_meal', '1181_meal', '1184_meal', '1186_meal', '1190_meal', '1190_meal_1', '1195_meal', '1195_meal_1', '1206_meal', '1206_meal_1', '1210_meal', '1217_meal', '1217_meal_1', '1230_meal', '1234_meal', '1241_meal', '1245_meal', '1246_meal', '1250_meal', '1263_meal', '1264_meal', '1282_meal', '2009_meal', '2025_meal', '2025_meal_1', '2027_meal']\n"
     ]
    }
   ],
   "source": [
    "path_openpose = '/Users/andreibirladeanu/Documents/Data/meal_openpose/'\n",
    "\n",
    "coords = [file for file in sorted(os.listdir(path_openpose)) if file[0] !=\".\"]\n",
    "print(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96013244-3867-46ae-81e7-1548064f0572",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 74/74 [1:32:51<00:00, 75.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for coord in tqdm(coords):\n",
    "    new_path = path_openpose+coord\n",
    "    os.chdir(new_path)\n",
    "    skeletons = []\n",
    "    frames = []\n",
    "    for frame in sorted_alphanumeric(os.listdir(new_path)):\n",
    "        if frame[0] != \".\":\n",
    "            data = pd.read_csv(frame)\n",
    "            data = data.fillna(0)\n",
    "        else:\n",
    "            continue\n",
    "        if (len(data.columns)-1)/3 == 1:\n",
    "            skeletons.append({'skeleton1':[np.array(data['x_1']), np.array(data['y_1']), np.array(data['prob_1'])]})\n",
    "            frames.append(int(str(frame.split('.')[0]).split(\"_\")[1]))\n",
    "        elif (len(data.columns)-1)/3 == 2:\n",
    "            skeletons.append({'skeleton1':[np.array(data['x_1']), np.array(data['y_1']),  np.array(data['prob_1'])],'skeleton2':[np.array(data['x_2']), np.array(data['y_2']),\n",
    "                                                                                                                             np.array(data['prob_2'])]})\n",
    "            frames.append(int(str(frame.split('.')[0]).split(\"_\")[1]))\n",
    "        elif (len(data.columns)-1)/3 == 3:\n",
    "            skeletons.append({'skeleton1':[np.array(data['x_1']), np.array(data['y_1']),  np.array(data['prob_1'])],'skeleton2':[np.array(data['x_2']), np.array(data['y_2']),\n",
    "                             np.array(data['prob_2'])],\n",
    "                          'skeleton3':[np.array(data['x_3']), np.array(data['y_3']),  np.array(data['prob_3'])]}) \n",
    "            frames.append(int(str(frame.split('.')[0]).split(\"_\")[1]))\n",
    "    ###extracting person 1 \n",
    "    joint = 1\n",
    "    thr = 180\n",
    "    neigh = NearestNeighbors(n_neighbors=1, algorithm = 'brute', metric='euclidean')\n",
    "    new_skeleton1 = []\n",
    "    frame_no = []\n",
    "    for i, frm in zip(range(len(skeletons)), frames): \n",
    "        if check_missing(skeletons[i])==True: ### checks if the joint was detected in all the skeletons\n",
    "            continue\n",
    "        elif new_skeleton1 == []:\n",
    "            new_skeleton1.append(skeletons[i]['skeleton1'])\n",
    "            skeletons[i].pop('skeleton1')\n",
    "            frame_no.append(frm)\n",
    "        elif len(skeletons[i])==1:\n",
    "            dist = nearest_neighbour(new_skeleton1[-1], skeletons[i])\n",
    "            #print(dist[0][0][0], frm)\n",
    "            if dist[0][0][0] < thr:\n",
    "                new_skeleton1.append(list(skeletons[i].values())[0])\n",
    "                frame_no.append(frm)\n",
    "                skeletons[i].pop(list(skeletons[i].keys())[0])\n",
    "            else:\n",
    "                continue                  \n",
    "        elif len(skeletons[i])==2:\n",
    "            dist = nearest_neighbour(new_skeleton1[-1], skeletons[i])\n",
    "            distance_1 = dist[0][0][0]; distance_2 = dist[1][0][0]\n",
    "            if distance_1 < distance_2 and distance_1< thr:\n",
    "                new_skeleton1.append(skeletons[i]['skeleton1'])\n",
    "                frame_no.append(frm)\n",
    "                skeletons[i].pop('skeleton1') \n",
    "            elif distance_1 > distance_2 and distance_2<thr:\n",
    "                new_skeleton1.append(skeletons[i]['skeleton2'])\n",
    "                frame_no.append(frm)\n",
    "                skeletons[i].pop('skeleton2')  \n",
    "            else:\n",
    "                continue\n",
    "        elif len(skeletons[i])==3:\n",
    "            dist = nearest_neighbour(new_skeleton1[-1], skeletons[i])\n",
    "            distance_1 = dist[0][0][0]; distance_2 = dist[1][0][0]; distance_3 = dist[2][0][0]\n",
    "            if distance_1 < distance_2 < distance_3 and distance_1 < thr:\n",
    "                new_skeleton1.append(skeletons[i]['skeleton1'])\n",
    "                frame_no.append(frm)\n",
    "                skeletons[i].pop('skeleton1')  \n",
    "            elif distance_2 < distance_1 < distance_3 and distance_2 < thr:\n",
    "                new_skeleton1.append(skeletons[i]['skeleton2'])\n",
    "                frame_no.append(frm)\n",
    "                skeletons[i].pop('skeleton2')\n",
    "            elif distance_3 < distance_1 < distance_2 and distance_3 < thr:\n",
    "                new_skeleton1.append(skeletons[i]['skeleton3'])\n",
    "                frame_no.append(frm)\n",
    "                skeletons[i].pop('skeleton3')\n",
    "            else:\n",
    "                continue\n",
    "    for skeleton, f_no in zip(new_skeleton1, frame_no):\n",
    "        out = pd.DataFrame(np.transpose(skeleton),  columns=['x', 'y', 'p'])\n",
    "        filepath = Path('/Users/andreibirladeanu/Documents/Data/tracked_meal_openpose/' +coord +'/' + 'skel1/' +str(f_no) +'.csv')\n",
    "        filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "        out.to_csv(filepath)\n",
    "        \n",
    "    ### tracking second skeleton \n",
    "    thr = 150\n",
    "    neigh = NearestNeighbors(n_neighbors=1, algorithm = 'brute', metric='euclidean')\n",
    "    new_skeleton2 = []\n",
    "    frame_no = []\n",
    "    for i, frm in zip(range(len(skeletons)), frames): \n",
    "        if skeletons[i] == {}:\n",
    "            continue\n",
    "        elif check_missing(skeletons[i])==True: ### checks if the joint was detected in all the skeletons\n",
    "            continue\n",
    "        elif new_skeleton2 == []:\n",
    "            new_skeleton2.append(list(skeletons[i].values())[0])\n",
    "            skeletons[i].pop(list(skeletons[i].keys())[0])\n",
    "            frame_no.append(frm)\n",
    "        elif len(skeletons[i])==1:\n",
    "            dist = nearest_neighbour(new_skeleton1[-1], skeletons[i])\n",
    "            distance = dist[0][0][0]\n",
    "            if distance < thr:\n",
    "                new_skeleton2.append(list(skeletons[i].values())[0])\n",
    "                frame_no.append(frm)\n",
    "                skeletons[i].pop(list(skeletons[i].keys())[0])\n",
    "            else:\n",
    "                continue                  \n",
    "        elif len(skeletons[i]) ==2:\n",
    "            dist = nearest_neighbour(new_skeleton1[-1], skeletons[i])\n",
    "            distance_1 = dist[0][0][0]; distance_2 = dist[1][0][0]\n",
    "            if distance_1 < distance_2 and distance_1< thr:\n",
    "                new_skeleton2.append(list(skeletons[i].values())[0])\n",
    "                frame_no.append(frm)\n",
    "                skeletons[i].pop(list(skeletons[i].keys())[0])\n",
    "            elif distance_1 > distance_2 and distance_2<thr:\n",
    "                new_skeleton2.append(list(skeletons[i].values())[1])\n",
    "                frame_no.append(frm)\n",
    "                skeletons[i].pop(list(skeletons[i].keys())[1])\n",
    "            else:\n",
    "                continue\n",
    "    for skeleton, f_no in zip(new_skeleton2, frame_no):\n",
    "        out = pd.DataFrame(np.transpose(skeleton),  columns=['x', 'y', 'p'])\n",
    "        filepath = Path('/Users/andreibirladeanu/Documents/Data/tracked_meal_openpose/' +coord +'/' + 'skel2/' +str(f_no) +'.csv')\n",
    "        filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "        out.to_csv(filepath)\n",
    "        \n",
    "        \n",
    "    ### extracting skeleton 3\n",
    "    new_skeleton3 = []\n",
    "    frame_no = []\n",
    "    for i, frm in zip(range(len(skeletons)), frames): \n",
    "        if skeletons[i] == {}:\n",
    "            continue\n",
    "        elif check_missing(skeletons[i])==True: ### checks if the joint was detected in all the skeletons\n",
    "            continue\n",
    "        if len(skeletons[i]) != {}:\n",
    "            new_skeleton3.append(list(skeletons[i].items())[0][1])\n",
    "            frame_no.append(frm)\n",
    "    for skeleton, f_no in zip(new_skeleton3, frame_no):\n",
    "        out = pd.DataFrame(np.transpose(skeleton),  columns=['x', 'y', 'p'])\n",
    "        filepath = Path('/Users/andreibirladeanu/Documents/Data/tracked_meal_openpose/' +coord +'/' + 'skel3/' +str(f_no) +'.csv')\n",
    "        filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "        out.to_csv(filepath)\n",
    "print('success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51c7f44-5436-4895-bb98-297294d2fef5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
