{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9745b826-25e3-4fb9-9da8-eb5377393aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tf_pose import common\n",
    "import tf_slim as slim\n",
    "from tf_pose.estimator import TfPoseEstimator\n",
    "from tf_pose.networks import get_graph_path, model_wh\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d43f381-5a16-450c-8fa0-53f1b3e9d362",
   "metadata": {},
   "outputs": [],
   "source": [
    "model='mobilenet_thin'\n",
    "resize='432x368'\n",
    "w, h = model_wh(resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c8c027-e2dd-4af3-9b02-ad3bcf06a1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = TfPoseEstimator(get_graph_path(model), target_size=(w, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825ec674-0b47-4f20-bd62-a60f54cd3909",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = '/Users/andrei-macpro/Documents/Data/Play/1043_play.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e97b95-16b6-4f29-9000-f1954d9305fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(human):\n",
    "    \"\"\"takes a human openpose object and returns parsed skeleton coordinates and probabilities \"\"\"\n",
    "    all_points = [x for x in range(18)]\n",
    "    skeleton =[]\n",
    "    probs = []\n",
    "    kpts = []\n",
    "    coords_x= []\n",
    "    coords_y= []\n",
    "    subscriptable = str(human).split(\"BodyPart:\")[1:]\n",
    "    for x in subscriptable:\n",
    "        kpts.append(int((x.split('-')[0])))\n",
    "        coords_x.append(float((str(x.split('-')[1]).split(\" score=\")[0][1:5]))*image.shape[1])\n",
    "        coords_y.append(float((str(x.split('-')[1]).split(\" score=\")[0][6:11]))*image.shape[0])\n",
    "        probs.append(float(str(x.split('-')[1]).split(\" score=\")[1]))\n",
    "    \n",
    "    for point in range(len(all_points)): # this ensures that undetected kpoints still have a value (nan) \n",
    "        if all_points[point] not in kpts:\n",
    "            kpts.insert(all_points[point], point)\n",
    "            coords_x.insert(all_points[point], \"nan\")\n",
    "            coords_y.insert(all_points[point], \"nan\")\n",
    "            probs.insert(all_points[point], 'nan')\n",
    "    \n",
    "    for k,cox, coy, prob in zip(kpts, coords_x, coords_y, probs): \n",
    "        if type(cox) == str:\n",
    "            skeleton.append([cox,coy,prob])\n",
    "        else:\n",
    "            skeleton.append([round(cox,2),round(coy,2), prob])\n",
    "    return(np.array(skeleton))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf568b8-d90c-4e67-a2d7-3a3e9245f817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_keypoints(image, hum, human=2, color='orange', showBG = True):\n",
    "    if human == 0: human = 1\n",
    "    num_hum = len(hum)\n",
    "    keypoints = str(str(str(hum[human-1]).split('BodyPart:')[1:]).split('-')).split(' score=')\n",
    "    keypoints_list=[]\n",
    "    for i in range (len(keypoints)-1): \n",
    "        pnt = keypoints[i][-11:-1]\n",
    "        pnt = tuple(map(float, pnt.split(', ')))\n",
    "        keypoints_list.append(pnt)\n",
    "\n",
    "    keypts_array = np.array(keypoints_list)\n",
    "    keypts_array = keypts_array*(image.shape[1],image.shape[0])\n",
    "    keypts_array = keypts_array.astype(int)\n",
    "    keypts_array\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.axis([0, image.shape[1], 0, image.shape[0]])  \n",
    "    plt.scatter(*zip(*keypts_array), s=200, color=color, alpha=0.6)\n",
    "    if showBG:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)      \n",
    "    plt.imshow(image)\n",
    "    ax=plt.gca() \n",
    "    ax.set_ylim(ax.get_ylim()[::-1]) \n",
    "    ax.xaxis.tick_top() \n",
    "    plt.title('Keypoints Person [{}] from {} humans detected\\n'.format(human, num_hum))\n",
    "    plt.grid();\n",
    "\n",
    "    for i, txt in enumerate(keypts_array):\n",
    "        ax.annotate(i, (keypts_array[i][0]-5, keypts_array[i][1]+5))\n",
    "            \n",
    "    return keypts_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2020a8c-48a7-49e7-bfa0-ddbccb9c77a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(video_path)\n",
    "frame_no = 0\n",
    "frames_list = []\n",
    "while(cap.isOpened()):\n",
    "    ret_val, image = cap.read()\n",
    "    cv2.imshow('image',image)\n",
    "    cv2.waitKey(0)\n",
    "    if ret_val == False:\n",
    "        break\n",
    "    frames_list.append(image)\n",
    "    print(frames)\n",
    "    frame_no+=1\n",
    "    if frame_no >10:\n",
    "        break\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3946b687-d18c-46af-b4ae-eeb2c4534be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('something')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d8d971-1d89-4887-9956-6094ec90fa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = '/Users/andrei-macpro/Documents/Data/Meal/1053_meal.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fps_time = 0\n",
    "while True:\n",
    "    ret_val, image = cap.read()\n",
    "    humans = e.inference(image,\n",
    "                         resize_to_default=(w > 0 and h > 0),\n",
    "                         upsample_size=4.0)\n",
    "\n",
    "\n",
    "    image = TfPoseEstimator.draw_humans(image, humans, imgcopy=False)\n",
    "    cv2.putText(image, \"FPS: %f\" % (1.0 / (time.time() - fps_time)), (10, 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    cv2.imshow('tf-pose-estimation result', image)\n",
    "    fps_time = time.time()\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3e78a8-4e4d-44b2-8f77-f0b4f62f42d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "humans = e.inference(frames_list[5], resize_to_default=(w > 0 and h > 0), upsample_size=4.0)\n",
    "black_background = np.zeros(image.shape)\n",
    "skeleton = TfPoseEstimator.draw_humans(black_background, humans, imgcopy=False)\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.imshow(skeleton);\n",
    "plt.grid();      \n",
    "#plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083e3928-59ee-44e6-a899-f8b6efed1fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoints = show_keypoints(frames_list[5], humans, showBG=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a47ae44-dca8-4545-bb20-fac1bc089110",
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81d3266-7e3f-4f14-9f5b-c7ce7a7f0592",
   "metadata": {},
   "outputs": [],
   "source": [
    "humans[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4460ac5c-56be-44cf-92d2-8d6e99deb860",
   "metadata": {},
   "outputs": [],
   "source": [
    "skeleton_1 = extract(humans[0])\n",
    "skeleton_2 = extract(humans[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240c86a9-0852-45d8-91f6-3f191f148f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "skeleton_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b18159c-86c1-4479-bc90-791ce4488db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "cap.set(1,9246)\n",
    "    \n",
    "ret_val, image = cap.read()\n",
    "humans = e.inference(image,\n",
    "                         resize_to_default=(w > 0 and h > 0),\n",
    "                         upsample_size=4.0)\n",
    "print(len(humans))\n",
    "print(show_keypoints(image, humans, human=1))\n",
    "image = TfPoseEstimator.draw_humans(image, humans, imgcopy=False)\n",
    "\n",
    "#cv2.imshow('tf-pose-estimation result', image)\n",
    "#\n",
    "#cv2.waitKey(0)\n",
    "#\n",
    "#cap.release()\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89dec35-0342-466a-8797-047aa3d2d344",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets extract this fucking video again and see if the results are similar ffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d535debe-bdd3-4b48-ac3f-8f275bd7e849",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(video_path)\n",
    "frame_no = 0\n",
    "os.makedirs('/Users/andreibirladeanu/Documents/Data/1117_meal_v2/', exist_ok=True)  \n",
    "folder_path = '/Users/andreibirladeanu/Documents/Data/1117_meal_v2/'\n",
    "while(cap.isOpened()):\n",
    "    ret_val, image = cap.read()\n",
    "    if ret_val == False:\n",
    "        break\n",
    "    frame_no+=1\n",
    "    humans = e.inference(image,\n",
    "                         resize_to_default=(w > 0 and h > 0),\n",
    "                         upsample_size=4.0)\n",
    "\n",
    "\n",
    "    if len(humans)==4:\n",
    "        skeleton_4 = extract(humans[3])\n",
    "        skeleton_3 = extract(humans[2])\n",
    "        skeleton_2 = extract(humans[1])\n",
    "        skeleton_1 = extract(humans[0])\n",
    "        data = pd.DataFrame((np.concatenate((skeleton_1,skeleton_2, skeleton_3, skeleton_4), axis=1)),\n",
    "                            columns = ['x_1', 'y_1', 'prob_1', 'x_2', 'y_2', 'prob_2', 'x_3', 'y_3', 'prob_3', \n",
    "                                      'x_4', 'y_4', 'prob_4'])\n",
    "        data.to_csv(folder_path + 'frame_' + str(frame_no) + '.csv')  \n",
    "\n",
    "\n",
    "    elif len(humans)==3:\n",
    "        skeleton_3 = extract(humans[2])\n",
    "        skeleton_2 = extract(humans[1])\n",
    "        skeleton_1 = extract(humans[0])\n",
    "        data = pd.DataFrame((np.concatenate((skeleton_1,skeleton_2, skeleton_3), axis=1)),\n",
    "                            columns = ['x_1', 'y_1', 'prob_1', 'x_2', 'y_2', 'prob_2', 'x_3', 'y_3', 'prob_3'])\n",
    "        data.to_csv(folder_path + 'frame_' +str(frame_no) + '.csv') \n",
    "\n",
    "\n",
    "    elif len(humans)==2:\n",
    "        skeleton_2 = extract(humans[1])\n",
    "        skeleton_1 = extract(humans[0])\n",
    "        data = pd.DataFrame((np.concatenate((skeleton_1, skeleton_2), axis=1)),\n",
    "                            columns = ['x_1', 'y_1', 'prob_1', 'x_2', 'y_2', 'prob_2'])\n",
    "        data.to_csv(folder_path + 'frame_' +str(frame_no) + '.csv') \n",
    "\n",
    "\n",
    "    elif len(humans) == 1:\n",
    "        skeleton_1 = extract(humans[0])\n",
    "        data = pd.DataFrame(skeleton_1,\n",
    "                            columns = ['x_1', 'y_1', 'prob_1'])\n",
    "        data.to_csv(folder_path + 'frame_' + str(frame_no) + '.csv') \n",
    "\n",
    "\n",
    "    else:\n",
    "        failed_frame.append(frame_no)\n",
    "        print(frame_no)\n",
    "        ## output failed frame file to keep consistency\n",
    "        ## output video resolution\n",
    "failed_frames.append({video.split(\".\")[0]:failed_frame})\n",
    "frame_count.append({video.split(\".\")[0]:frame_no})\n",
    "width.append({video.split(\".\")[0]:(int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)))})\n",
    "height.append({video.split(\".\")[0]:int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))})\n",
    "cap.release()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
